+ echo 'Beginning trial 03 of 10'
Beginning trial 03 of 10
+ echo ':::DLPAL dockerd://mlperf-dell:ssd 3945 4 xe9680node[30,70,90,100] '\''unknown'\'' 4xXE9680x8H100-SXM-80GB'
:::DLPAL dockerd://mlperf-dell:ssd 3945 4 xe9680node[30,70,90,100] 'unknown' 4xXE9680x8H100-SXM-80GB
++ srun --ntasks=1 --container-name=single_stage_detector_3945 mlperf-sysjson.sh
srun: warning: can't run 1 processes on 4 nodes, setting nnodes to 1
+ echo ':::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"4","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8470","host_processor_core_count":"52","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H100 80GB HBM3","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"81559 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-122-generic","nvidia_kernel_driver":"550.90.12"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"4","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8470","host_processor_core_count":"52","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H100 80GB HBM3","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"81559 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-122-generic","nvidia_kernel_driver":"550.90.12"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ srun --ntasks=1 --container-name=single_stage_detector_3945 bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
srun: warning: can't run 1 processes on 4 nodes, setting nnodes to 1
:::GITCOMMITID  
+ srun -N1 -n1 --container-name=single_stage_detector_3945 python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=4 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on xe9680node90
Clearing cache on xe9680node70
sudo: /etc/sudoers.d is world writable
Clearing cache on xe9680node100
Clearing cache on xe9680node30
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=4 --container-name=single_stage_detector_3945 python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1728601797990, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1728601797986, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1728601798167, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1728601798474, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ sleep 30
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1728601828'
RUNANDTIME_START 1728601828
+ srun --ntasks=32 --ntasks-per-node=8 --time=UNLIMITED --container-name=single_stage_detector_3945 --container-mounts=/xe9680_md0/training_datasets_v4.1/ssd:/datasets/open-images-v6,/xe9680_nvme0n1/training_results_v4.1/ssd/results:/results,/xe9680_md0/training_datasets_v4.1/ssd/train:/root/.cache/torch --container-workdir=/workspace/ssd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 19: LOCAL_RANK 3, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 19, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 23: LOCAL_RANK 7, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 23, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 17: LOCAL_RANK 1, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 17, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 3: LOCAL_RANK 3, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 3, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 7: LOCAL_RANK 7, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 7, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 20: LOCAL_RANK 4, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 20, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 21: LOCAL_RANK 5, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 21, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
RANK 14: LOCAL_RANK 6, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 14, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 13: LOCAL_RANK 5, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 13, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 18: LOCAL_RANK 2, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 18, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 8: LOCAL_RANK 0, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 8, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 9: LOCAL_RANK 1, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 9, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 1: LOCAL_RANK 1, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 1, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 5: LOCAL_RANK 5, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 5, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
RANK 22: LOCAL_RANK 6, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 22, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
RANK 29: LOCAL_RANK 5, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 29, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 27: LOCAL_RANK 3, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 27, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:33 PM
RANK 26: LOCAL_RANK 2, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 26, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
RANK 24: LOCAL_RANK 0, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 24, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
RANK 2: LOCAL_RANK 2, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 2, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
RANK 12: LOCAL_RANK 4, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 12, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
RANK 6: LOCAL_RANK 6, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 6, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
RANK 25: LOCAL_RANK 1, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 25, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
RANK 30: LOCAL_RANK 6, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 30, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
RANK 10: LOCAL_RANK 2, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 10, SLURM_LOCALID 2, OMP_NUM_THREADS 1
RANK 11: LOCAL_RANK 3, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 11, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
RANK 15: LOCAL_RANK 7, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 15, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
RANK 0: LOCAL_RANK 0, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 0, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
RANK 28: LOCAL_RANK 4, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 28, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
RANK 4: LOCAL_RANK 4, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 4, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
RANK 31: LOCAL_RANK 7, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 31, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 11:10:34 PM
RANK 16: LOCAL_RANK 0, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 16, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
| distributed init (rank 13): env://
| distributed init (rank 0): env://
| distributed init (rank 7): env://
| distributed init (rank 3): env://
| distributed init (rank 16): env://
| distributed init (rank 24): env://
| distributed init (rank 8): env://
| distributed init (rank 29): env://
| distributed init (rank 17): env://
| distributed init (rank 5): env://
| distributed init (rank 26): env://
| distributed init (rank 10): env://
| distributed init (rank 4): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 6): env://
| distributed init (rank 9): env://
| distributed init (rank 11): env://
| distributed init (rank 15): env://
| distributed init (rank 14): env://
| distributed init (rank 12): env://
| distributed init (rank 27): env://
| distributed init (rank 22): env://
| distributed init (rank 18): env://
| distributed init (rank 30): env://
| distributed init (rank 20): env://
| distributed init (rank 19): env://
| distributed init (rank 25): env://
| distributed init (rank 21): env://
| distributed init (rank 23): env://
| distributed init (rank 28): env://
| distributed init (rank 31): env://
:::MLLOG {"namespace": "", "time_ms": 1728601845920, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1728601845921, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1728601845921, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1728601845921, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1728601845921, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "4xDELL", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1728601845921, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 353}}
:::MLLOG {"namespace": "", "time_ms": 1728601846009, "event_type": "POINT_IN_TIME", "key": "seed", "value": 610562757, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1728601846009, "event_type": "POINT_IN_TIME", "key": "local_batch_size", "value": 16, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 371}}
:::MLLOG {"namespace": "", "time_ms": 1728601846009, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 512, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 372}}
:::MLLOG {"namespace": "", "time_ms": 1728601846009, "event_type": "POINT_IN_TIME", "key": "epoch_count", "value": 6, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 373}}
:::MLLOG {"namespace": "", "time_ms": 1728601846009, "event_type": "POINT_IN_TIME", "key": "first_epoch_num", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 374}}
Namespace(backbone='resnext50_32x4d', trainable_backbone_layers=3, sync_bn=False, data_layout='channels_last', amp=True, async_coco=True, async_coco_check_freq=20, num_eval_ranks=32, dataset='openimages-mlperf', dataset_path='/datasets/open-images-v6', num_classes=None, train_data_path=None, train_annotations_file=None, val_data_path=None, val_annotations_file=None, image_size=[800, 800], data_augmentation='hflip', epochs=6, max_iters_per_epoch=None, max_eval_iters_per_epoch=None, start_epoch=0, output_dir=None, target_map=0.34, resume='', pretrained=False, batch_size=16, eval_batch_size=32, lr=8.5e-05, warmup_epochs=0, warmup_factor=0.001, workers=4, print_freq=20, eval_print_freq=20, test_only=False, seed=610562757, device='cuda', cocoeval='nvidia', coco_threads=8, world_size=32, dist_url='env://', frozen_bn_opt=True, frozen_bn_fp16=True, jit=True, cuda_graphs=True, cuda_graphs_eval=False, cls_head_pad=True, reg_head_pad=True, cuda_graphs_syn=True, model_warmup_epochs=16, master_weights=True, dali=True, dali_matched_idxs=True, dali_eval=True, dali_eval_cache=False, dali_prefetch_queue_depth=2, dali_cpu_decode=True, dali_pinned_memory_size=268435456, dali_cmn=0, dali_cmn_hint=0, dali_decoder_hint_height=7360, dali_decoder_hint_width=7360, dali_decoder_hw_load=0.65, dali_input_batch_multiplier=1, dali_eval_cmn_hint=0, dali_eval_decoder_hint_height=0, dali_eval_decoder_hint_width=0, dali_eval_decoder_hw_load=0.65, dali_eval_input_batch_multiplier=1, dali_sync=False, dali_resize_first=False, apex_adam=True, apex_focal_loss=True, apex_backbone_fusion=True, apex_head_fusion=True, broadcast_buffers=False, fp16_allreduce=False, ddp_bucket_sz=25, ddp_first_bucket_sz=None, no_gradient_as_bucket_view=False, max_boxes=1000, cudnn_bench=False, deterministic=False, not_graphed_prologues=False, metric_loss=False, syn_dataset=0, sync_after_graph_replay=False, allreduce_barrier=False, skip_eval=False, cuda_profiler=False, cuda_profiler_eval=False, cuda_profiler_start=-1, cuda_profiler_stop=-1, power_benchmark=False, power_sustain_time=600, rank=0, gpu=0, distributed=True, dist_backend='nccl', ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], num_train_ranks=32, train_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], eval_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], train_rank=0, eval_rank=0)
Getting dataset information
Creating model
:::MLLOG {"namespace": "", "time_ms": 1728601846017, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846036, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846036, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p7.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846039, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p7.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846169, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846170, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846170, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846170, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846170, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846170, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846171, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846171, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846171, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846171, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846171, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846171, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846172, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846172, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846173, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846173, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846174, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846174, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846175, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846175, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846176, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846176, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846177, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846177, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846178, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846179, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846179, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846182, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846184, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846186, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846187, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846189, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846191, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846192, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846194, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846197, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846197, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846199, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846202, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846202, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846204, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846207, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846207, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846210, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846214, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846215, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846224, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846263, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846264, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846379, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846380, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846380, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846381, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846381, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846384, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846384, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846386, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846386, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846389, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846389, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846391, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846405, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846408, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846408, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846410, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846410, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846413, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846413, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846416, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846437, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 148, "tensor": "module.head.classification_head.cls_logits.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846461, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 150, "tensor": "module.head.classification_head.cls_logits.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846471, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 317, "tensor": "module.head.regression_head.bbox_reg.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846472, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 319, "tensor": "module.head.regression_head.bbox_reg.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846472, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846474, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846474, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846477, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846477, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846479, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846480, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728601846482, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.6.bias"}}
Casting convolutional layers to half
:::MLLOG {"namespace": "", "time_ms": 1728601846557, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 450}}
:::MLLOG {"namespace": "", "time_ms": 1728601846557, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 8.5e-05, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 451}}
:::MLLOG {"namespace": "", "time_ms": 1728601846557, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 452}}
:::MLLOG {"namespace": "", "time_ms": 1728601846558, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 453}}
:::MLLOG {"namespace": "", "time_ms": 1728601846558, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 454}}
:::MLLOG {"namespace": "", "time_ms": 1728601846558, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 455}}
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model eval warmup
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Time: 46.49643540382385 sec
Creating Dali training dataloader
Creating Dali eval dataloader
CUDA graph capture for training
CUDA graphs: data preprocessing complete
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
CUDA graphs: warmup iterations complete
CUDA graphs: capture complete
CUDA graph capture for training complete
:::MLLOG {"namespace": "", "time_ms": 1728601933587, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 575}}
:::MLLOG {"namespace": "", "time_ms": 1728601933589, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 579}}
:::MLLOG {"namespace": "", "time_ms": 1728601933589, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 2286, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1728601933589, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 25, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 636}}
Running ...
:::MLLOG {"namespace": "", "time_ms": 1728601933590, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 0}}
Epoch: [0]  [   0/2286]  eta: 0:02:12    time: 0.0581  data: 0.0003  max mem: 13791
Epoch: [0]  [  20/2286]  eta: 0:02:15    time: 0.0599  data: 0.0533  max mem: 13791
Epoch: [0]  [  40/2286]  eta: 0:02:15    time: 0.0612  data: 0.0547  max mem: 13791
Epoch: [0]  [  60/2286]  eta: 0:02:13    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [0]  [  80/2286]  eta: 0:02:12    time: 0.0601  data: 0.0535  max mem: 13791
Epoch: [0]  [ 100/2286]  eta: 0:02:11    time: 0.0599  data: 0.0533  max mem: 13791
Epoch: [0]  [ 120/2286]  eta: 0:02:09    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [ 140/2286]  eta: 0:02:08    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [0]  [ 160/2286]  eta: 0:02:07    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [0]  [ 180/2286]  eta: 0:02:06    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [0]  [ 200/2286]  eta: 0:02:04    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [0]  [ 220/2286]  eta: 0:02:03    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [0]  [ 240/2286]  eta: 0:02:02    time: 0.0594  data: 0.0530  max mem: 13791
Epoch: [0]  [ 260/2286]  eta: 0:02:01    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [ 280/2286]  eta: 0:01:59    time: 0.0593  data: 0.0530  max mem: 13791
Epoch: [0]  [ 300/2286]  eta: 0:01:58    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [0]  [ 320/2286]  eta: 0:01:57    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [0]  [ 340/2286]  eta: 0:01:56    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [ 360/2286]  eta: 0:01:54    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [ 380/2286]  eta: 0:01:53    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [ 400/2286]  eta: 0:01:52    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [0]  [ 420/2286]  eta: 0:01:51    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [0]  [ 440/2286]  eta: 0:01:50    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [0]  [ 460/2286]  eta: 0:01:49    time: 0.0613  data: 0.0529  max mem: 13791
Epoch: [0]  [ 480/2286]  eta: 0:01:47    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [0]  [ 500/2286]  eta: 0:01:46    time: 0.0594  data: 0.0530  max mem: 13791
Epoch: [0]  [ 520/2286]  eta: 0:01:45    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [0]  [ 540/2286]  eta: 0:01:44    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [ 560/2286]  eta: 0:01:43    time: 0.0646  data: 0.0581  max mem: 13791
Epoch: [0]  [ 580/2286]  eta: 0:01:42    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [ 600/2286]  eta: 0:01:41    time: 0.0645  data: 0.0575  max mem: 13791
Epoch: [0]  [ 620/2286]  eta: 0:01:39    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [0]  [ 640/2286]  eta: 0:01:38    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [0]  [ 660/2286]  eta: 0:01:37    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [ 680/2286]  eta: 0:01:36    time: 0.0608  data: 0.0532  max mem: 13791
Epoch: [0]  [ 700/2286]  eta: 0:01:35    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [0]  [ 720/2286]  eta: 0:01:33    time: 0.0599  data: 0.0534  max mem: 13791
Epoch: [0]  [ 740/2286]  eta: 0:01:32    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [ 760/2286]  eta: 0:01:31    time: 0.0595  data: 0.0528  max mem: 13791
Epoch: [0]  [ 780/2286]  eta: 0:01:30    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [0]  [ 800/2286]  eta: 0:01:29    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [0]  [ 820/2286]  eta: 0:01:27    time: 0.0601  data: 0.0535  max mem: 13791
Epoch: [0]  [ 840/2286]  eta: 0:01:26    time: 0.0627  data: 0.0560  max mem: 13791
Epoch: [0]  [ 860/2286]  eta: 0:01:25    time: 0.0620  data: 0.0551  max mem: 13791
Epoch: [0]  [ 880/2286]  eta: 0:01:24    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [0]  [ 900/2286]  eta: 0:01:23    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [0]  [ 920/2286]  eta: 0:01:21    time: 0.0611  data: 0.0546  max mem: 13791
Epoch: [0]  [ 940/2286]  eta: 0:01:20    time: 0.0614  data: 0.0548  max mem: 13791
Epoch: [0]  [ 960/2286]  eta: 0:01:19    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [0]  [ 980/2286]  eta: 0:01:18    time: 0.0601  data: 0.0535  max mem: 13791
Epoch: [0]  [1000/2286]  eta: 0:01:17    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [0]  [1020/2286]  eta: 0:01:15    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [1040/2286]  eta: 0:01:14    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [1060/2286]  eta: 0:01:13    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [0]  [1080/2286]  eta: 0:01:12    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [0]  [1100/2286]  eta: 0:01:11    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [0]  [1120/2286]  eta: 0:01:09    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [1140/2286]  eta: 0:01:08    time: 0.0620  data: 0.0555  max mem: 13791
Epoch: [0]  [1160/2286]  eta: 0:01:07    time: 0.0615  data: 0.0530  max mem: 13791
Epoch: [0]  [1180/2286]  eta: 0:01:06    time: 0.0610  data: 0.0544  max mem: 13791
Epoch: [0]  [1200/2286]  eta: 0:01:05    time: 0.0605  data: 0.0539  max mem: 13791
Epoch: [0]  [1220/2286]  eta: 0:01:04    time: 0.0594  data: 0.0530  max mem: 13791
Epoch: [0]  [1240/2286]  eta: 0:01:02    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [0]  [1260/2286]  eta: 0:01:01    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [0]  [1280/2286]  eta: 0:01:00    time: 0.0600  data: 0.0534  max mem: 13791
Epoch: [0]  [1300/2286]  eta: 0:00:59    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [0]  [1320/2286]  eta: 0:00:57    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [0]  [1340/2286]  eta: 0:00:56    time: 0.0611  data: 0.0545  max mem: 13791
Epoch: [0]  [1360/2286]  eta: 0:00:55    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [0]  [1380/2286]  eta: 0:00:54    time: 0.0596  data: 0.0529  max mem: 13791
Epoch: [0]  [1400/2286]  eta: 0:00:53    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [0]  [1420/2286]  eta: 0:00:51    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [0]  [1440/2286]  eta: 0:00:50    time: 0.0597  data: 0.0531  max mem: 13791
Corrupt JPEG data: premature end of data segment
Epoch: [0]  [1460/2286]  eta: 0:00:49    time: 0.0603  data: 0.0538  max mem: 13791
Epoch: [0]  [1480/2286]  eta: 0:00:48    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [0]  [1500/2286]  eta: 0:00:47    time: 0.0595  data: 0.0528  max mem: 13791
Epoch: [0]  [1520/2286]  eta: 0:00:45    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [0]  [1540/2286]  eta: 0:00:44    time: 0.0604  data: 0.0536  max mem: 13791
Epoch: [0]  [1560/2286]  eta: 0:00:43    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [0]  [1580/2286]  eta: 0:00:42    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [0]  [1600/2286]  eta: 0:00:41    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [0]  [1620/2286]  eta: 0:00:39    time: 0.0601  data: 0.0535  max mem: 13791
Epoch: [0]  [1640/2286]  eta: 0:00:38    time: 0.0606  data: 0.0541  max mem: 13791
Epoch: [0]  [1660/2286]  eta: 0:00:37    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [0]  [1680/2286]  eta: 0:00:36    time: 0.0614  data: 0.0549  max mem: 13791
Epoch: [0]  [1700/2286]  eta: 0:00:35    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [0]  [1720/2286]  eta: 0:00:33    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [0]  [1740/2286]  eta: 0:00:32    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [1760/2286]  eta: 0:00:31    time: 0.0595  data: 0.0528  max mem: 13791
Epoch: [0]  [1780/2286]  eta: 0:00:30    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [1800/2286]  eta: 0:00:29    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [0]  [1820/2286]  eta: 0:00:27    time: 0.0625  data: 0.0561  max mem: 13791
Epoch: [0]  [1840/2286]  eta: 0:00:26    time: 0.0630  data: 0.0565  max mem: 13791
Epoch: [0]  [1860/2286]  eta: 0:00:25    time: 0.0594  data: 0.0530  max mem: 13791
Epoch: [0]  [1880/2286]  eta: 0:00:24    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [1900/2286]  eta: 0:00:23    time: 0.0603  data: 0.0539  max mem: 13791
Epoch: [0]  [1920/2286]  eta: 0:00:21    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [0]  [1940/2286]  eta: 0:00:20    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [0]  [1960/2286]  eta: 0:00:19    time: 0.0616  data: 0.0552  max mem: 13791
Epoch: [0]  [1980/2286]  eta: 0:00:18    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [0]  [2000/2286]  eta: 0:00:17    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [2020/2286]  eta: 0:00:15    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [0]  [2040/2286]  eta: 0:00:14    time: 0.0602  data: 0.0536  max mem: 13791
Epoch: [0]  [2060/2286]  eta: 0:00:13    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [0]  [2080/2286]  eta: 0:00:12    time: 0.0644  data: 0.0579  max mem: 13791
Epoch: [0]  [2100/2286]  eta: 0:00:11    time: 0.0593  data: 0.0529  max mem: 13791
Epoch: [0]  [2120/2286]  eta: 0:00:09    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [0]  [2140/2286]  eta: 0:00:08    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [0]  [2160/2286]  eta: 0:00:07    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [0]  [2180/2286]  eta: 0:00:06    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [0]  [2200/2286]  eta: 0:00:05    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [0]  [2220/2286]  eta: 0:00:03    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [2240/2286]  eta: 0:00:02    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [0]  [2260/2286]  eta: 0:00:01    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [2280/2286]  eta: 0:00:00    time: 0.0631  data: 0.0564  max mem: 13791
Epoch: [0]  [2285/2286]  eta: 0:00:00    time: 0.0592  data: 0.0525  max mem: 13791
Epoch: [0] Total time: 0:02:17 (0.0600 s / it)
:::MLLOG {"namespace": "", "time_ms": 1728602070857, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1728602070857, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 266.6756371064763}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1728602070857, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 1}}
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [ 0/25]  eta: 0:00:09  model_time: 0.3871 (0.3871)  evaluator_time: 0.0038 (0.0038)  time: 0.3922  data: 0.0005  max mem: 13791
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [20/25]  eta: 0:00:01  model_time: 0.3155 (0.3200)  evaluator_time: 0.0042 (0.0042)  time: 0.3219  data: 0.0009  max mem: 13791
Test:  [24/25]  eta: 0:00:00  model_time: 0.3218 (0.3095)  evaluator_time: 0.0042 (0.0041)  time: 0.3115  data: 0.0008  max mem: 13791
Test: Total time: 0:00:07 (0.3147 s / it)
Averaged stats: model_time: 0.3218 (0.3124)  evaluator_time: 0.0042 (0.0042)
:::MLLOG {"namespace": "", "time_ms": 1728602079388, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 1}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [1]  [   0/2286]  eta: 0:02:17    time: 0.0601  data: 0.0010  max mem: 13791
Epoch: [1]  [  20/2286]  eta: 0:02:13    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [1]  [  40/2286]  eta: 0:02:12    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [  60/2286]  eta: 0:02:12    time: 0.0600  data: 0.0533  max mem: 13791
Epoch: [1]  [  80/2286]  eta: 0:02:10    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [1]  [ 100/2286]  eta: 0:02:09    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [1]  [ 120/2286]  eta: 0:02:08    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [1]  [ 140/2286]  eta: 0:02:07    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [1]  [ 160/2286]  eta: 0:02:06    time: 0.0601  data: 0.0535  max mem: 13791
:::MLLOG {"namespace": "", "time_ms": 1728602089221, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.20893429004722305, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1728602089222, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 1}}
Epoch: [1]  [ 180/2286]  eta: 0:02:05    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [ 200/2286]  eta: 0:02:04    time: 0.0602  data: 0.0535  max mem: 13791
Epoch: [1]  [ 220/2286]  eta: 0:02:02    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [1]  [ 240/2286]  eta: 0:02:01    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [ 260/2286]  eta: 0:02:00    time: 0.0601  data: 0.0537  max mem: 13791
Epoch: [1]  [ 280/2286]  eta: 0:01:59    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [1]  [ 300/2286]  eta: 0:01:58    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [1]  [ 320/2286]  eta: 0:01:57    time: 0.0610  data: 0.0532  max mem: 13791
Epoch: [1]  [ 340/2286]  eta: 0:01:55    time: 0.0601  data: 0.0535  max mem: 13791
Epoch: [1]  [ 360/2286]  eta: 0:01:54    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [1]  [ 380/2286]  eta: 0:01:53    time: 0.0605  data: 0.0539  max mem: 13791
Epoch: [1]  [ 400/2286]  eta: 0:01:52    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [ 420/2286]  eta: 0:01:51    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [ 440/2286]  eta: 0:01:50    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [1]  [ 460/2286]  eta: 0:01:48    time: 0.0594  data: 0.0527  max mem: 13791
Epoch: [1]  [ 480/2286]  eta: 0:01:47    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [1]  [ 500/2286]  eta: 0:01:46    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [ 520/2286]  eta: 0:01:45    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [ 540/2286]  eta: 0:01:43    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [ 560/2286]  eta: 0:01:42    time: 0.0594  data: 0.0527  max mem: 13791
Epoch: [1]  [ 580/2286]  eta: 0:01:41    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [1]  [ 600/2286]  eta: 0:01:40    time: 0.0609  data: 0.0542  max mem: 13791
Epoch: [1]  [ 620/2286]  eta: 0:01:39    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [1]  [ 640/2286]  eta: 0:01:38    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [1]  [ 660/2286]  eta: 0:01:36    time: 0.0598  data: 0.0533  max mem: 13791
Epoch: [1]  [ 680/2286]  eta: 0:01:35    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [1]  [ 700/2286]  eta: 0:01:34    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [ 720/2286]  eta: 0:01:33    time: 0.0606  data: 0.0540  max mem: 13791
Epoch: [1]  [ 740/2286]  eta: 0:01:32    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [1]  [ 760/2286]  eta: 0:01:31    time: 0.0633  data: 0.0568  max mem: 13791
Epoch: [1]  [ 780/2286]  eta: 0:01:29    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [1]  [ 800/2286]  eta: 0:01:28    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [1]  [ 820/2286]  eta: 0:01:27    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [ 840/2286]  eta: 0:01:26    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [1]  [ 860/2286]  eta: 0:01:25    time: 0.0595  data: 0.0528  max mem: 13791
Epoch: [1]  [ 880/2286]  eta: 0:01:23    time: 0.0593  data: 0.0529  max mem: 13791
Epoch: [1]  [ 900/2286]  eta: 0:01:22    time: 0.0631  data: 0.0567  max mem: 13791
Epoch: [1]  [ 920/2286]  eta: 0:01:21    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [ 940/2286]  eta: 0:01:20    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [ 960/2286]  eta: 0:01:19    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [1]  [ 980/2286]  eta: 0:01:17    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [1000/2286]  eta: 0:01:16    time: 0.0594  data: 0.0530  max mem: 13791
Epoch: [1]  [1020/2286]  eta: 0:01:15    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [1040/2286]  eta: 0:01:14    time: 0.0604  data: 0.0538  max mem: 13791
Epoch: [1]  [1060/2286]  eta: 0:01:13    time: 0.0603  data: 0.0538  max mem: 13791
Epoch: [1]  [1080/2286]  eta: 0:01:12    time: 0.0600  data: 0.0535  max mem: 13791
Epoch: [1]  [1100/2286]  eta: 0:01:10    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [1120/2286]  eta: 0:01:09    time: 0.0594  data: 0.0529  max mem: 13791
Corrupt JPEG data: premature end of data segment
Epoch: [1]  [1140/2286]  eta: 0:01:08    time: 0.0615  data: 0.0528  max mem: 13791
Epoch: [1]  [1160/2286]  eta: 0:01:07    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [1]  [1180/2286]  eta: 0:01:06    time: 0.0609  data: 0.0545  max mem: 13791
Epoch: [1]  [1200/2286]  eta: 0:01:04    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [1]  [1220/2286]  eta: 0:01:03    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [1]  [1240/2286]  eta: 0:01:02    time: 0.0613  data: 0.0547  max mem: 13791
Epoch: [1]  [1260/2286]  eta: 0:01:01    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [1]  [1280/2286]  eta: 0:01:00    time: 0.0609  data: 0.0543  max mem: 13791
Epoch: [1]  [1300/2286]  eta: 0:00:58    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [1]  [1320/2286]  eta: 0:00:57    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [1]  [1340/2286]  eta: 0:00:56    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [1360/2286]  eta: 0:00:55    time: 0.0615  data: 0.0551  max mem: 13791
Epoch: [1]  [1380/2286]  eta: 0:00:54    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [1]  [1400/2286]  eta: 0:00:52    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [1]  [1420/2286]  eta: 0:00:51    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [1]  [1440/2286]  eta: 0:00:50    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [1460/2286]  eta: 0:00:49    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [1480/2286]  eta: 0:00:48    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [1500/2286]  eta: 0:00:46    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [1]  [1520/2286]  eta: 0:00:45    time: 0.0596  data: 0.0529  max mem: 13791
Epoch: [1]  [1540/2286]  eta: 0:00:44    time: 0.0593  data: 0.0526  max mem: 13791
Epoch: [1]  [1560/2286]  eta: 0:00:43    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [1]  [1580/2286]  eta: 0:00:42    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [1]  [1600/2286]  eta: 0:00:40    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [1620/2286]  eta: 0:00:39    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [1640/2286]  eta: 0:00:38    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [1]  [1660/2286]  eta: 0:00:37    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [1]  [1680/2286]  eta: 0:00:36    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [1700/2286]  eta: 0:00:34    time: 0.0610  data: 0.0545  max mem: 13791
Epoch: [1]  [1720/2286]  eta: 0:00:33    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [1]  [1740/2286]  eta: 0:00:32    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [1]  [1760/2286]  eta: 0:00:31    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [1780/2286]  eta: 0:00:30    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [1]  [1800/2286]  eta: 0:00:29    time: 0.0608  data: 0.0526  max mem: 13791
Epoch: [1]  [1820/2286]  eta: 0:00:27    time: 0.0598  data: 0.0534  max mem: 13791
Epoch: [1]  [1840/2286]  eta: 0:00:26    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [1]  [1860/2286]  eta: 0:00:25    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [1880/2286]  eta: 0:00:24    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [1]  [1900/2286]  eta: 0:00:23    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [1]  [1920/2286]  eta: 0:00:21    time: 0.0600  data: 0.0533  max mem: 13791
Epoch: [1]  [1940/2286]  eta: 0:00:20    time: 0.0607  data: 0.0541  max mem: 13791
Epoch: [1]  [1960/2286]  eta: 0:00:19    time: 0.0614  data: 0.0548  max mem: 13791
Epoch: [1]  [1980/2286]  eta: 0:00:18    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [2000/2286]  eta: 0:00:17    time: 0.0612  data: 0.0546  max mem: 13791
Epoch: [1]  [2020/2286]  eta: 0:00:15    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [1]  [2040/2286]  eta: 0:00:14    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [2060/2286]  eta: 0:00:13    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [2080/2286]  eta: 0:00:12    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [1]  [2100/2286]  eta: 0:00:11    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [2120/2286]  eta: 0:00:09    time: 0.0592  data: 0.0528  max mem: 13791
Epoch: [1]  [2140/2286]  eta: 0:00:08    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [2160/2286]  eta: 0:00:07    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [1]  [2180/2286]  eta: 0:00:06    time: 0.0650  data: 0.0584  max mem: 13791
Epoch: [1]  [2200/2286]  eta: 0:00:05    time: 0.0602  data: 0.0536  max mem: 13791
Epoch: [1]  [2220/2286]  eta: 0:00:03    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [1]  [2240/2286]  eta: 0:00:02    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [1]  [2260/2286]  eta: 0:00:01    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [2280/2286]  eta: 0:00:00    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [1]  [2285/2286]  eta: 0:00:00    time: 0.0617  data: 0.0552  max mem: 13791
Epoch: [1] Total time: 0:02:16 (0.0597 s / it)
:::MLLOG {"namespace": "", "time_ms": 1728602216083, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1728602216084, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 267.7889787310049}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1728602216084, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 2}}
Test:  [ 0/25]  eta: 0:00:07  model_time: 0.2863 (0.2863)  evaluator_time: 0.0035 (0.0035)  time: 0.2908  data: 0.0009  max mem: 13791
Test:  [20/25]  eta: 0:00:01  model_time: 0.2783 (0.2854)  evaluator_time: 0.0040 (0.0076)  time: 0.2942  data: 0.0009  max mem: 13791
Test:  [24/25]  eta: 0:00:00  model_time: 0.2791 (0.2753)  evaluator_time: 0.0040 (0.0069)  time: 0.2842  data: 0.0009  max mem: 13791
Test: Total time: 0:00:07 (0.2833 s / it)
Averaged stats: model_time: 0.2791 (0.2802)  evaluator_time: 0.0040 (0.0070)
:::MLLOG {"namespace": "", "time_ms": 1728602223790, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 2}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [2]  [   0/2286]  eta: 0:02:17    time: 0.0599  data: 0.0009  max mem: 13791
Epoch: [2]  [  20/2286]  eta: 0:02:12    time: 0.0586  data: 0.0520  max mem: 13791
Epoch: [2]  [  40/2286]  eta: 0:02:12    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [2]  [  60/2286]  eta: 0:02:11    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [2]  [  80/2286]  eta: 0:02:10    time: 0.0591  data: 0.0525  max mem: 13791
:::MLLOG {"namespace": "", "time_ms": 1728602229315, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.28456698900971095, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1728602229315, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 2}}
Epoch: [2]  [ 100/2286]  eta: 0:02:08    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [2]  [ 120/2286]  eta: 0:02:08    time: 0.0610  data: 0.0545  max mem: 13791
Epoch: [2]  [ 140/2286]  eta: 0:02:08    time: 0.0626  data: 0.0561  max mem: 13791
Epoch: [2]  [ 160/2286]  eta: 0:02:06    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [2]  [ 180/2286]  eta: 0:02:05    time: 0.0593  data: 0.0540  max mem: 13791
Epoch: [2]  [ 200/2286]  eta: 0:02:04    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [ 220/2286]  eta: 0:02:03    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [ 240/2286]  eta: 0:02:02    time: 0.0629  data: 0.0563  max mem: 13791
Epoch: [2]  [ 260/2286]  eta: 0:02:01    time: 0.0601  data: 0.0536  max mem: 13791
Epoch: [2]  [ 280/2286]  eta: 0:01:59    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [2]  [ 300/2286]  eta: 0:01:58    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [ 320/2286]  eta: 0:01:57    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [ 340/2286]  eta: 0:01:56    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [2]  [ 360/2286]  eta: 0:01:54    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [2]  [ 380/2286]  eta: 0:01:53    time: 0.0617  data: 0.0553  max mem: 13791
Epoch: [2]  [ 400/2286]  eta: 0:01:52    time: 0.0617  data: 0.0552  max mem: 13791
Epoch: [2]  [ 420/2286]  eta: 0:01:51    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [2]  [ 440/2286]  eta: 0:01:50    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [ 460/2286]  eta: 0:01:49    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [ 480/2286]  eta: 0:01:47    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [ 500/2286]  eta: 0:01:46    time: 0.0612  data: 0.0547  max mem: 13791
Epoch: [2]  [ 520/2286]  eta: 0:01:45    time: 0.0619  data: 0.0555  max mem: 13791
Epoch: [2]  [ 540/2286]  eta: 0:01:44    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [2]  [ 560/2286]  eta: 0:01:43    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [ 580/2286]  eta: 0:01:42    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [2]  [ 600/2286]  eta: 0:01:40    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [ 620/2286]  eta: 0:01:39    time: 0.0615  data: 0.0550  max mem: 13791
Epoch: [2]  [ 640/2286]  eta: 0:01:38    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [2]  [ 660/2286]  eta: 0:01:37    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [2]  [ 680/2286]  eta: 0:01:36    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [ 700/2286]  eta: 0:01:34    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [ 720/2286]  eta: 0:01:33    time: 0.0602  data: 0.0538  max mem: 13791
Epoch: [2]  [ 740/2286]  eta: 0:01:32    time: 0.0595  data: 0.0531  max mem: 13791
Epoch: [2]  [ 760/2286]  eta: 0:01:31    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [2]  [ 780/2286]  eta: 0:01:29    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [ 800/2286]  eta: 0:01:28    time: 0.0616  data: 0.0551  max mem: 13791
Epoch: [2]  [ 820/2286]  eta: 0:01:27    time: 0.0645  data: 0.0579  max mem: 13791
Epoch: [2]  [ 840/2286]  eta: 0:01:26    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [ 860/2286]  eta: 0:01:25    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [2]  [ 880/2286]  eta: 0:01:24    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [ 900/2286]  eta: 0:01:22    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [ 920/2286]  eta: 0:01:21    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [2]  [ 940/2286]  eta: 0:01:20    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [ 960/2286]  eta: 0:01:19    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [ 980/2286]  eta: 0:01:18    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [1000/2286]  eta: 0:01:16    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [1020/2286]  eta: 0:01:15    time: 0.0592  data: 0.0528  max mem: 13791
Epoch: [2]  [1040/2286]  eta: 0:01:14    time: 0.0595  data: 0.0531  max mem: 13791
Epoch: [2]  [1060/2286]  eta: 0:01:13    time: 0.0607  data: 0.0543  max mem: 13791
Epoch: [2]  [1080/2286]  eta: 0:01:12    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [2]  [1100/2286]  eta: 0:01:10    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [1120/2286]  eta: 0:01:09    time: 0.0635  data: 0.0570  max mem: 13791
Epoch: [2]  [1140/2286]  eta: 0:01:08    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [2]  [1160/2286]  eta: 0:01:07    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [2]  [1180/2286]  eta: 0:01:06    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [1200/2286]  eta: 0:01:04    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [2]  [1220/2286]  eta: 0:01:03    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [1240/2286]  eta: 0:01:02    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [1260/2286]  eta: 0:01:01    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [1280/2286]  eta: 0:01:00    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [1300/2286]  eta: 0:00:58    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [1320/2286]  eta: 0:00:57    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [2]  [1340/2286]  eta: 0:00:56    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [1360/2286]  eta: 0:00:55    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [1380/2286]  eta: 0:00:54    time: 0.0605  data: 0.0541  max mem: 13791
Epoch: [2]  [1400/2286]  eta: 0:00:52    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [2]  [1420/2286]  eta: 0:00:51    time: 0.0593  data: 0.0529  max mem: 13791
Epoch: [2]  [1440/2286]  eta: 0:00:50    time: 0.0604  data: 0.0537  max mem: 13791
Epoch: [2]  [1460/2286]  eta: 0:00:49    time: 0.0608  data: 0.0543  max mem: 13791
Epoch: [2]  [1480/2286]  eta: 0:00:48    time: 0.0591  data: 0.0524  max mem: 13791
Epoch: [2]  [1500/2286]  eta: 0:00:46    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [1520/2286]  eta: 0:00:45    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [2]  [1540/2286]  eta: 0:00:44    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [2]  [1560/2286]  eta: 0:00:43    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [2]  [1580/2286]  eta: 0:00:42    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [1600/2286]  eta: 0:00:40    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [1620/2286]  eta: 0:00:39    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [1640/2286]  eta: 0:00:38    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [2]  [1660/2286]  eta: 0:00:37    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [2]  [1680/2286]  eta: 0:00:36    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [2]  [1700/2286]  eta: 0:00:34    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [2]  [1720/2286]  eta: 0:00:33    time: 0.0600  data: 0.0533  max mem: 13791
Epoch: [2]  [1740/2286]  eta: 0:00:32    time: 0.0610  data: 0.0545  max mem: 13791
Epoch: [2]  [1760/2286]  eta: 0:00:31    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [1780/2286]  eta: 0:00:30    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [1800/2286]  eta: 0:00:28    time: 0.0608  data: 0.0543  max mem: 13791
Epoch: [2]  [1820/2286]  eta: 0:00:27    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [1840/2286]  eta: 0:00:26    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [2]  [1860/2286]  eta: 0:00:25    time: 0.0604  data: 0.0540  max mem: 13791
Epoch: [2]  [1880/2286]  eta: 0:00:24    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [2]  [1900/2286]  eta: 0:00:23    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [1920/2286]  eta: 0:00:21    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [2]  [1940/2286]  eta: 0:00:20    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [2]  [1960/2286]  eta: 0:00:19    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [1980/2286]  eta: 0:00:18    time: 0.0616  data: 0.0534  max mem: 13791
Epoch: [2]  [2000/2286]  eta: 0:00:17    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [2]  [2020/2286]  eta: 0:00:15    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [2]  [2040/2286]  eta: 0:00:14    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [2]  [2060/2286]  eta: 0:00:13    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [2]  [2080/2286]  eta: 0:00:12    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [2100/2286]  eta: 0:00:11    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [2120/2286]  eta: 0:00:09    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [2]  [2140/2286]  eta: 0:00:08    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [2]  [2160/2286]  eta: 0:00:07    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [2180/2286]  eta: 0:00:06    time: 0.0591  data: 0.0526  max mem: 13791
Corrupt JPEG data: premature end of data segment
Epoch: [2]  [2200/2286]  eta: 0:00:05    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [2]  [2220/2286]  eta: 0:00:03    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [2]  [2240/2286]  eta: 0:00:02    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [2]  [2260/2286]  eta: 0:00:01    time: 0.0606  data: 0.0542  max mem: 13791
Epoch: [2]  [2280/2286]  eta: 0:00:00    time: 0.0589  data: 0.0525  max mem: 13791
Epoch: [2]  [2285/2286]  eta: 0:00:00    time: 0.0589  data: 0.0525  max mem: 13791
Epoch: [2] Total time: 0:02:16 (0.0596 s / it)
:::MLLOG {"namespace": "", "time_ms": 1728602360078, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1728602360078, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 268.5913372005798}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1728602360078, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 3}}
Test:  [ 0/25]  eta: 0:00:06  model_time: 0.2568 (0.2568)  evaluator_time: 0.0032 (0.0032)  time: 0.2611  data: 0.0009  max mem: 13791
Test:  [20/25]  eta: 0:00:01  model_time: 0.2680 (0.2684)  evaluator_time: 0.0037 (0.0037)  time: 0.2738  data: 0.0009  max mem: 13791
Test:  [24/25]  eta: 0:00:00  model_time: 0.2664 (0.2596)  evaluator_time: 0.0037 (0.0036)  time: 0.2634  data: 0.0009  max mem: 13791
Test: Total time: 0:00:06 (0.2643 s / it)
Averaged stats: model_time: 0.2664 (0.2639)  evaluator_time: 0.0037 (0.0036)
:::MLLOG {"namespace": "", "time_ms": 1728602367183, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 3}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [3]  [   0/2285]  eta: 0:02:16    time: 0.0598  data: 0.0011  max mem: 13791
Epoch: [3]  [  20/2285]  eta: 0:02:16    time: 0.0601  data: 0.0522  max mem: 13791
Epoch: [3]  [  40/2285]  eta: 0:02:14    time: 0.0597  data: 0.0533  max mem: 13791
Epoch: [3]  [  60/2285]  eta: 0:02:12    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [3]  [  80/2285]  eta: 0:02:10    time: 0.0589  data: 0.0525  max mem: 13791
:::MLLOG {"namespace": "", "time_ms": 1728602372006, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.31806165588568114, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1728602372006, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 3}}
Epoch: [3]  [ 100/2285]  eta: 0:02:10    time: 0.0601  data: 0.0537  max mem: 13791
Epoch: [3]  [ 120/2285]  eta: 0:02:08    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [3]  [ 140/2285]  eta: 0:02:07    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [ 160/2285]  eta: 0:02:06    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [ 180/2285]  eta: 0:02:05    time: 0.0603  data: 0.0537  max mem: 13791
Epoch: [3]  [ 200/2285]  eta: 0:02:04    time: 0.0601  data: 0.0536  max mem: 13791
Epoch: [3]  [ 220/2285]  eta: 0:02:02    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [3]  [ 240/2285]  eta: 0:02:01    time: 0.0588  data: 0.0524  max mem: 13791
Epoch: [3]  [ 260/2285]  eta: 0:02:00    time: 0.0597  data: 0.0533  max mem: 13791
Epoch: [3]  [ 280/2285]  eta: 0:01:59    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [3]  [ 300/2285]  eta: 0:01:57    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [3]  [ 320/2285]  eta: 0:01:56    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [ 340/2285]  eta: 0:01:55    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [ 360/2285]  eta: 0:01:54    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [ 380/2285]  eta: 0:01:52    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [3]  [ 400/2285]  eta: 0:01:51    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [ 420/2285]  eta: 0:01:50    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [3]  [ 440/2285]  eta: 0:01:49    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [ 460/2285]  eta: 0:01:48    time: 0.0589  data: 0.0523  max mem: 13791
Epoch: [3]  [ 480/2285]  eta: 0:01:47    time: 0.0628  data: 0.0564  max mem: 13791
Epoch: [3]  [ 500/2285]  eta: 0:01:46    time: 0.0619  data: 0.0554  max mem: 13791
Epoch: [3]  [ 520/2285]  eta: 0:01:44    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [3]  [ 540/2285]  eta: 0:01:43    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [3]  [ 560/2285]  eta: 0:01:42    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [3]  [ 580/2285]  eta: 0:01:41    time: 0.0603  data: 0.0538  max mem: 13791
Epoch: [3]  [ 600/2285]  eta: 0:01:40    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [ 620/2285]  eta: 0:01:38    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [ 640/2285]  eta: 0:01:37    time: 0.0589  data: 0.0525  max mem: 13791
Epoch: [3]  [ 660/2285]  eta: 0:01:36    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [ 680/2285]  eta: 0:01:35    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [3]  [ 700/2285]  eta: 0:01:34    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [ 720/2285]  eta: 0:01:32    time: 0.0601  data: 0.0537  max mem: 13791
Epoch: [3]  [ 740/2285]  eta: 0:01:31    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [3]  [ 760/2285]  eta: 0:01:30    time: 0.0589  data: 0.0523  max mem: 13791
Epoch: [3]  [ 780/2285]  eta: 0:01:29    time: 0.0599  data: 0.0524  max mem: 13791
Epoch: [3]  [ 800/2285]  eta: 0:01:28    time: 0.0586  data: 0.0522  max mem: 13791
Epoch: [3]  [ 820/2285]  eta: 0:01:26    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [ 840/2285]  eta: 0:01:25    time: 0.0589  data: 0.0525  max mem: 13791
Epoch: [3]  [ 860/2285]  eta: 0:01:24    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [3]  [ 880/2285]  eta: 0:01:23    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [ 900/2285]  eta: 0:01:22    time: 0.0588  data: 0.0524  max mem: 13791
Epoch: [3]  [ 920/2285]  eta: 0:01:21    time: 0.0610  data: 0.0545  max mem: 13791
Epoch: [3]  [ 940/2285]  eta: 0:01:19    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [3]  [ 960/2285]  eta: 0:01:18    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [ 980/2285]  eta: 0:01:17    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [1000/2285]  eta: 0:01:16    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [1020/2285]  eta: 0:01:15    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [3]  [1040/2285]  eta: 0:01:13    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [1060/2285]  eta: 0:01:12    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [3]  [1080/2285]  eta: 0:01:11    time: 0.0644  data: 0.0578  max mem: 13791
Epoch: [3]  [1100/2285]  eta: 0:01:10    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [3]  [1120/2285]  eta: 0:01:09    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [3]  [1140/2285]  eta: 0:01:07    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [1160/2285]  eta: 0:01:06    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [3]  [1180/2285]  eta: 0:01:05    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [3]  [1200/2285]  eta: 0:01:04    time: 0.0588  data: 0.0522  max mem: 13791
Epoch: [3]  [1220/2285]  eta: 0:01:03    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [1240/2285]  eta: 0:01:02    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [3]  [1260/2285]  eta: 0:01:00    time: 0.0610  data: 0.0544  max mem: 13791
Epoch: [3]  [1280/2285]  eta: 0:00:59    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [1300/2285]  eta: 0:00:58    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [1320/2285]  eta: 0:00:57    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [3]  [1340/2285]  eta: 0:00:56    time: 0.0589  data: 0.0525  max mem: 13791
Epoch: [3]  [1360/2285]  eta: 0:00:54    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [3]  [1380/2285]  eta: 0:00:53    time: 0.0587  data: 0.0523  max mem: 13791
Epoch: [3]  [1400/2285]  eta: 0:00:52    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [1420/2285]  eta: 0:00:51    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [3]  [1440/2285]  eta: 0:00:50    time: 0.0592  data: 0.0525  max mem: 13791
Epoch: [3]  [1460/2285]  eta: 0:00:48    time: 0.0589  data: 0.0538  max mem: 13791
Epoch: [3]  [1480/2285]  eta: 0:00:47    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [1500/2285]  eta: 0:00:46    time: 0.0588  data: 0.0524  max mem: 13791
Epoch: [3]  [1520/2285]  eta: 0:00:45    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [1540/2285]  eta: 0:00:44    time: 0.0608  data: 0.0544  max mem: 13791
Epoch: [3]  [1560/2285]  eta: 0:00:43    time: 0.0592  data: 0.0528  max mem: 13791
Epoch: [3]  [1580/2285]  eta: 0:00:41    time: 0.0589  data: 0.0523  max mem: 13791
Epoch: [3]  [1600/2285]  eta: 0:00:40    time: 0.0597  data: 0.0533  max mem: 13791
Epoch: [3]  [1620/2285]  eta: 0:00:39    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [1640/2285]  eta: 0:00:38    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [1660/2285]  eta: 0:00:37    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [3]  [1680/2285]  eta: 0:00:35    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [1700/2285]  eta: 0:00:34    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [1720/2285]  eta: 0:00:33    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [1740/2285]  eta: 0:00:32    time: 0.0613  data: 0.0546  max mem: 13791
Epoch: [3]  [1760/2285]  eta: 0:00:31    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [1780/2285]  eta: 0:00:29    time: 0.0609  data: 0.0525  max mem: 13791
Epoch: [3]  [1800/2285]  eta: 0:00:28    time: 0.0639  data: 0.0573  max mem: 13791
Epoch: [3]  [1820/2285]  eta: 0:00:27    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [1840/2285]  eta: 0:00:26    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [1860/2285]  eta: 0:00:25    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [3]  [1880/2285]  eta: 0:00:24    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [1900/2285]  eta: 0:00:22    time: 0.0592  data: 0.0528  max mem: 13791
Epoch: [3]  [1920/2285]  eta: 0:00:21    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [3]  [1940/2285]  eta: 0:00:20    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [3]  [1960/2285]  eta: 0:00:19    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [3]  [1980/2285]  eta: 0:00:18    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [2000/2285]  eta: 0:00:16    time: 0.0587  data: 0.0522  max mem: 13791
Epoch: [3]  [2020/2285]  eta: 0:00:15    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [3]  [2040/2285]  eta: 0:00:14    time: 0.0620  data: 0.0555  max mem: 13791
Epoch: [3]  [2060/2285]  eta: 0:00:13    time: 0.0588  data: 0.0523  max mem: 13791
Corrupt JPEG data: premature end of data segment
Epoch: [3]  [2080/2285]  eta: 0:00:12    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [3]  [2100/2285]  eta: 0:00:10    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [3]  [2120/2285]  eta: 0:00:09    time: 0.0665  data: 0.0600  max mem: 13791
Epoch: [3]  [2140/2285]  eta: 0:00:08    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [3]  [2160/2285]  eta: 0:00:07    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [3]  [2180/2285]  eta: 0:00:06    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [3]  [2200/2285]  eta: 0:00:05    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [2220/2285]  eta: 0:00:03    time: 0.0589  data: 0.0525  max mem: 13791
Epoch: [3]  [2240/2285]  eta: 0:00:02    time: 0.0624  data: 0.0560  max mem: 13791
Epoch: [3]  [2260/2285]  eta: 0:00:01    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [3]  [2280/2285]  eta: 0:00:00    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [3]  [2284/2285]  eta: 0:00:00    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [3] Total time: 0:02:15 (0.0594 s / it)
:::MLLOG {"namespace": "", "time_ms": 1728602503032, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1728602503032, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 269.34305226582694}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1728602503032, "event_type": "INTERVAL_START", "key": "eval_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 4}}
Test:  [ 0/25]  eta: 0:00:06  model_time: 0.2664 (0.2664)  evaluator_time: 0.0032 (0.0032)  time: 0.2709  data: 0.0012  max mem: 13791
Test:  [20/25]  eta: 0:00:01  model_time: 0.2689 (0.2744)  evaluator_time: 0.0037 (0.0071)  time: 0.2832  data: 0.0009  max mem: 13791
Test:  [24/25]  eta: 0:00:00  model_time: 0.2689 (0.2655)  evaluator_time: 0.0037 (0.0065)  time: 0.2738  data: 0.0009  max mem: 13791
Test: Total time: 0:00:06 (0.2731 s / it)
Averaged stats: model_time: 0.2689 (0.2696)  evaluator_time: 0.0037 (0.0056)
:::MLLOG {"namespace": "", "time_ms": 1728602510381, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 4}}
Epoch: [4]  [   0/2286]  eta: 0:02:16    time: 0.0596  data: 0.0009  max mem: 13791
Epoch: [4]  [  20/2286]  eta: 0:02:14    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [4]  [  40/2286]  eta: 0:02:12    time: 0.0586  data: 0.0521  max mem: 13791
Epoch: [4]  [  60/2286]  eta: 0:02:10    time: 0.0586  data: 0.0522  max mem: 13791
Epoch: [4]  [  80/2286]  eta: 0:02:09    time: 0.0593  data: 0.0527  max mem: 13791
:::MLLOG {"namespace": "", "time_ms": 1728602515159, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3368967415198853, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1728602515159, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 4}}
Epoch: [4]  [ 100/2286]  eta: 0:02:08    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [ 120/2286]  eta: 0:02:07    time: 0.0587  data: 0.0522  max mem: 13791
Epoch: [4]  [ 140/2286]  eta: 0:02:06    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [4]  [ 160/2286]  eta: 0:02:05    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [ 180/2286]  eta: 0:02:03    time: 0.0586  data: 0.0520  max mem: 13791
Epoch: [4]  [ 200/2286]  eta: 0:02:02    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [ 220/2286]  eta: 0:02:01    time: 0.0588  data: 0.0522  max mem: 13791
Epoch: [4]  [ 240/2286]  eta: 0:02:00    time: 0.0587  data: 0.0522  max mem: 13791
Epoch: [4]  [ 260/2286]  eta: 0:01:59    time: 0.0600  data: 0.0535  max mem: 13791
Epoch: [4]  [ 280/2286]  eta: 0:01:58    time: 0.0593  data: 0.0529  max mem: 13791
Epoch: [4]  [ 300/2286]  eta: 0:01:57    time: 0.0588  data: 0.0522  max mem: 13791
Epoch: [4]  [ 320/2286]  eta: 0:01:56    time: 0.0637  data: 0.0572  max mem: 13791
Epoch: [4]  [ 340/2286]  eta: 0:01:55    time: 0.0587  data: 0.0522  max mem: 13791
Epoch: [4]  [ 360/2286]  eta: 0:01:54    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [4]  [ 380/2286]  eta: 0:01:52    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [4]  [ 400/2286]  eta: 0:01:51    time: 0.0587  data: 0.0522  max mem: 13791
Epoch: [4]  [ 420/2286]  eta: 0:01:50    time: 0.0586  data: 0.0521  max mem: 13791
Epoch: [4]  [ 440/2286]  eta: 0:01:49    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [ 460/2286]  eta: 0:01:47    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [4]  [ 480/2286]  eta: 0:01:46    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [4]  [ 500/2286]  eta: 0:01:45    time: 0.0613  data: 0.0529  max mem: 13791
Epoch: [4]  [ 520/2286]  eta: 0:01:44    time: 0.0610  data: 0.0546  max mem: 13791
Epoch: [4]  [ 540/2286]  eta: 0:01:43    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [4]  [ 560/2286]  eta: 0:01:42    time: 0.0587  data: 0.0523  max mem: 13791
Epoch: [4]  [ 580/2286]  eta: 0:01:41    time: 0.0607  data: 0.0542  max mem: 13791
Epoch: [4]  [ 600/2286]  eta: 0:01:40    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [4]  [ 620/2286]  eta: 0:01:38    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [ 640/2286]  eta: 0:01:37    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [ 660/2286]  eta: 0:01:36    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [ 680/2286]  eta: 0:01:35    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [ 700/2286]  eta: 0:01:34    time: 0.0588  data: 0.0524  max mem: 13791
Epoch: [4]  [ 720/2286]  eta: 0:01:32    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [ 740/2286]  eta: 0:01:31    time: 0.0603  data: 0.0538  max mem: 13791
Epoch: [4]  [ 760/2286]  eta: 0:01:30    time: 0.0640  data: 0.0574  max mem: 13791
Epoch: [4]  [ 780/2286]  eta: 0:01:29    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [ 800/2286]  eta: 0:01:28    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [ 820/2286]  eta: 0:01:27    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [4]  [ 840/2286]  eta: 0:01:25    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [4]  [ 860/2286]  eta: 0:01:24    time: 0.0587  data: 0.0523  max mem: 13791
Epoch: [4]  [ 880/2286]  eta: 0:01:23    time: 0.0588  data: 0.0524  max mem: 13791
Epoch: [4]  [ 900/2286]  eta: 0:01:22    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [4]  [ 920/2286]  eta: 0:01:21    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [ 940/2286]  eta: 0:01:19    time: 0.0603  data: 0.0539  max mem: 13791
Epoch: [4]  [ 960/2286]  eta: 0:01:18    time: 0.0607  data: 0.0543  max mem: 13791
Epoch: [4]  [ 980/2286]  eta: 0:01:17    time: 0.0590  data: 0.0525  max mem: 13791
Corrupt JPEG data: premature end of data segment
Epoch: [4]  [1000/2286]  eta: 0:01:16    time: 0.0587  data: 0.0523  max mem: 13791
Epoch: [4]  [1020/2286]  eta: 0:01:15    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [4]  [1040/2286]  eta: 0:01:13    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [4]  [1060/2286]  eta: 0:01:12    time: 0.0588  data: 0.0524  max mem: 13791
Epoch: [4]  [1080/2286]  eta: 0:01:11    time: 0.0589  data: 0.0525  max mem: 13791
Epoch: [4]  [1100/2286]  eta: 0:01:10    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [1120/2286]  eta: 0:01:09    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [1140/2286]  eta: 0:01:07    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [1160/2286]  eta: 0:01:06    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [4]  [1180/2286]  eta: 0:01:05    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [4]  [1200/2286]  eta: 0:01:04    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [4]  [1220/2286]  eta: 0:01:03    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [4]  [1240/2286]  eta: 0:01:02    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [4]  [1260/2286]  eta: 0:01:00    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [4]  [1280/2286]  eta: 0:00:59    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [1300/2286]  eta: 0:00:58    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [1320/2286]  eta: 0:00:57    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [4]  [1340/2286]  eta: 0:00:56    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [4]  [1360/2286]  eta: 0:00:54    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [4]  [1380/2286]  eta: 0:00:53    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [4]  [1400/2286]  eta: 0:00:52    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [4]  [1420/2286]  eta: 0:00:51    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [4]  [1440/2286]  eta: 0:00:50    time: 0.0601  data: 0.0525  max mem: 13791
Epoch: [4]  [1460/2286]  eta: 0:00:48    time: 0.0588  data: 0.0522  max mem: 13791
Epoch: [4]  [1480/2286]  eta: 0:00:47    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [1500/2286]  eta: 0:00:46    time: 0.0589  data: 0.0525  max mem: 13791
Epoch: [4]  [1520/2286]  eta: 0:00:45    time: 0.0588  data: 0.0524  max mem: 13791
Epoch: [4]  [1540/2286]  eta: 0:00:44    time: 0.0589  data: 0.0523  max mem: 13791
Epoch: [4]  [1560/2286]  eta: 0:00:43    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [4]  [1580/2286]  eta: 0:00:41    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [1600/2286]  eta: 0:00:40    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [4]  [1620/2286]  eta: 0:00:39    time: 0.0612  data: 0.0547  max mem: 13791
Epoch: [4]  [1640/2286]  eta: 0:00:38    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [1660/2286]  eta: 0:00:37    time: 0.0590  data: 0.0527  max mem: 13791
Epoch: [4]  [1680/2286]  eta: 0:00:35    time: 0.0623  data: 0.0558  max mem: 13791
Epoch: [4]  [1700/2286]  eta: 0:00:34    time: 0.0619  data: 0.0554  max mem: 13791
Epoch: [4]  [1720/2286]  eta: 0:00:33    time: 0.0606  data: 0.0522  max mem: 13791
Epoch: [4]  [1740/2286]  eta: 0:00:32    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [1760/2286]  eta: 0:00:31    time: 0.0588  data: 0.0522  max mem: 13791
Epoch: [4]  [1780/2286]  eta: 0:00:30    time: 0.0587  data: 0.0522  max mem: 13791
Epoch: [4]  [1800/2286]  eta: 0:00:28    time: 0.0589  data: 0.0523  max mem: 13791
Epoch: [4]  [1820/2286]  eta: 0:00:27    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [4]  [1840/2286]  eta: 0:00:26    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [4]  [1860/2286]  eta: 0:00:25    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [4]  [1880/2286]  eta: 0:00:24    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [1900/2286]  eta: 0:00:22    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [1920/2286]  eta: 0:00:21    time: 0.0621  data: 0.0556  max mem: 13791
Epoch: [4]  [1940/2286]  eta: 0:00:20    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [1960/2286]  eta: 0:00:19    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [4]  [1980/2286]  eta: 0:00:18    time: 0.0590  data: 0.0523  max mem: 13791
Epoch: [4]  [2000/2286]  eta: 0:00:16    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [2020/2286]  eta: 0:00:15    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [4]  [2040/2286]  eta: 0:00:14    time: 0.0588  data: 0.0522  max mem: 13791
Epoch: [4]  [2060/2286]  eta: 0:00:13    time: 0.0589  data: 0.0525  max mem: 13791
Epoch: [4]  [2080/2286]  eta: 0:00:12    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [4]  [2100/2286]  eta: 0:00:11    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [2120/2286]  eta: 0:00:09    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [4]  [2140/2286]  eta: 0:00:08    time: 0.0615  data: 0.0551  max mem: 13791
Epoch: [4]  [2160/2286]  eta: 0:00:07    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [4]  [2180/2286]  eta: 0:00:06    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [2200/2286]  eta: 0:00:05    time: 0.0587  data: 0.0523  max mem: 13791
Epoch: [4]  [2220/2286]  eta: 0:00:03    time: 0.0624  data: 0.0559  max mem: 13791
Epoch: [4]  [2240/2286]  eta: 0:00:02    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [2260/2286]  eta: 0:00:01    time: 0.0618  data: 0.0553  max mem: 13791
Epoch: [4]  [2280/2286]  eta: 0:00:00    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [4]  [2285/2286]  eta: 0:00:00    time: 0.0597  data: 0.0533  max mem: 13791
Epoch: [4] Total time: 0:02:15 (0.0593 s / it)
:::MLLOG {"namespace": "", "time_ms": 1728602646154, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1728602646154, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 269.6118292583427}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 5}}
:::MLLOG {"namespace": "", "time_ms": 1728602646154, "event_type": "INTERVAL_START", "key": "eval_start", "value": 5, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 5}}
Test:  [ 0/25]  eta: 0:00:06  model_time: 0.2672 (0.2672)  evaluator_time: 0.0030 (0.0030)  time: 0.2711  data: 0.0009  max mem: 13791
Test:  [20/25]  eta: 0:00:01  model_time: 0.2631 (0.2654)  evaluator_time: 0.0035 (0.0037)  time: 0.2702  data: 0.0009  max mem: 13791
Test:  [24/25]  eta: 0:00:00  model_time: 0.2618 (0.2568)  evaluator_time: 0.0035 (0.0036)  time: 0.2600  data: 0.0009  max mem: 13791
Test: Total time: 0:00:06 (0.2614 s / it)
Averaged stats: model_time: 0.2618 (0.2593)  evaluator_time: 0.0035 (0.0039)
:::MLLOG {"namespace": "", "time_ms": 1728602653158, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 5, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 5}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [5]  [   0/2286]  eta: 0:02:16    time: 0.0596  data: 0.0009  max mem: 13791
Epoch: [5]  [  20/2286]  eta: 0:02:12    time: 0.0584  data: 0.0519  max mem: 13791
Epoch: [5]  [  40/2286]  eta: 0:02:11    time: 0.0587  data: 0.0522  max mem: 13791
Epoch: [5]  [  60/2286]  eta: 0:02:12    time: 0.0617  data: 0.0550  max mem: 13791
:::MLLOG {"namespace": "", "time_ms": 1728602657595, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.35452486020887564, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1728602657595, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 5, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1728602657981, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 315, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1728602657981, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 5, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1728602657981, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 275.0005862455274}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 6}}
Run time 0:12:04
:::MLLOG {"namespace": "", "time_ms": 1728602657981, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 783}}
Loading annotations into memory...
Done (t=0.78s)
Creating index...
Done (t=1.17s)
Loading and preparing results...
DONE (t=3.13s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.32s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.20893
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.33286
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.22121
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00442
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.05002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.23050
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.34191
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.49086
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.51195
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.01980
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18074
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.56011
Loading and preparing results...
DONE (t=2.85s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.46s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28457
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.42977
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.30449
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00518
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.07678
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.31473
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.37446
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.53644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.56206
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.02957
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.21593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.61307
Loading and preparing results...
DONE (t=2.46s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.21s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.31806
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.46772
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.34203
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00733
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.08690
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.35222
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.39187
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.55795
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.58596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03053
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23837
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.63749
Loading and preparing results...
DONE (t=2.38s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.24s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33690
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.48402
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.36195
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00927
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09078
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37315
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.40313
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.57291
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.60087
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03447
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24879
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.65241
Loading and preparing results...
DONE (t=2.23s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.04s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.35452
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.50723
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.38085
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00885
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09619
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.39253
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.40939
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.57938
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.60837
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.25577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.66040
[rank16]:[W1010 23:24:18.233742454 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank8]:[W1010 23:24:18.420122995 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank24]:[W1010 23:24:18.407332875 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank0]:[W1010 23:24:19.675046211 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
ENDING TIMING RUN AT 2024-10-10 11:24:22 PM
RESULT,SINGLE_STAGE_DETECTOR,,828,nvidia,2024-10-10 11:10:34 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:34 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,829,nvidia,2024-10-10 11:10:34 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,829,nvidia,2024-10-10 11:10:34 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,829,nvidia,2024-10-10 11:10:34 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,829,nvidia,2024-10-10 11:10:34 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,829,nvidia,2024-10-10 11:10:34 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,829,nvidia,2024-10-10 11:10:34 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,829,nvidia,2024-10-10 11:10:34 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,829,nvidia,2024-10-10 11:10:34 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,829,nvidia,2024-10-10 11:10:34 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,829,nvidia,2024-10-10 11:10:34 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,829,nvidia,2024-10-10 11:10:34 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:34 PM
ENDING TIMING RUN AT 2024-10-10 11:24:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 11:10:33 PM
ENDING TIMING RUN AT 2024-10-10 11:24:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 11:10:34 PM
++ date +%s
+ echo 'RUNANDTIME_STOP 1728602664'
RUNANDTIME_STOP 1728602664
+ set -e
