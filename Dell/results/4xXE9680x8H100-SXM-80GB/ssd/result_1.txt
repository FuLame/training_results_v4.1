+ echo 'Beginning trial 02 of 10'
Beginning trial 02 of 10
+ echo ':::DLPAL dockerd://mlperf-dell:ssd 3945 4 xe9680node[30,70,90,100] '\''unknown'\'' 4xXE9680x8H100-SXM-80GB'
:::DLPAL dockerd://mlperf-dell:ssd 3945 4 xe9680node[30,70,90,100] 'unknown' 4xXE9680x8H100-SXM-80GB
++ srun --ntasks=1 --container-name=single_stage_detector_3945 mlperf-sysjson.sh
srun: warning: can't run 1 processes on 4 nodes, setting nnodes to 1
+ echo ':::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"4","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8470","host_processor_core_count":"52","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H100 80GB HBM3","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"81559 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-122-generic","nvidia_kernel_driver":"550.90.12"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"4","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8470","host_processor_core_count":"52","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H100 80GB HBM3","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"81559 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-122-generic","nvidia_kernel_driver":"550.90.12"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ srun --ntasks=1 --container-name=single_stage_detector_3945 bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
srun: warning: can't run 1 processes on 4 nodes, setting nnodes to 1
:::GITCOMMITID  
+ srun -N1 -n1 --container-name=single_stage_detector_3945 python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=4 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on xe9680node100
Clearing cache on xe9680node70
sudo: /etc/sudoers.d is world writable
Clearing cache on xe9680node90
Clearing cache on xe9680node30
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=4 --container-name=single_stage_detector_3945 python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1728600858163, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1728600858269, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1728600858301, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1728600858666, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ sleep 30
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1728600889'
RUNANDTIME_START 1728600889
+ srun --ntasks=32 --ntasks-per-node=8 --time=UNLIMITED --container-name=single_stage_detector_3945 --container-mounts=/xe9680_md0/training_datasets_v4.1/ssd:/datasets/open-images-v6,/xe9680_nvme0n1/training_results_v4.1/ssd/results:/results,/xe9680_md0/training_datasets_v4.1/ssd/train:/root/.cache/torch --container-workdir=/workspace/ssd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 13: LOCAL_RANK 5, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 13, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 10: LOCAL_RANK 2, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 10, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 11: LOCAL_RANK 3, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 11, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 8: LOCAL_RANK 0, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 8, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 9: LOCAL_RANK 1, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 9, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
RANK 14: LOCAL_RANK 6, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 14, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
RANK 5: LOCAL_RANK 5, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 5, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 1: LOCAL_RANK 1, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 1, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 3: LOCAL_RANK 3, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 3, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
RANK 28: LOCAL_RANK 4, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 28, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 26: LOCAL_RANK 2, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 26, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
RANK 16: LOCAL_RANK 0, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 16, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 19: LOCAL_RANK 3, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 19, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
RANK 22: LOCAL_RANK 6, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 22, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 21: LOCAL_RANK 5, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 21, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 20: LOCAL_RANK 4, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 20, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 0: LOCAL_RANK 0, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 0, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 31: LOCAL_RANK 7, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 31, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 7: LOCAL_RANK 7, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 7, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
RANK 24: LOCAL_RANK 0, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 24, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 25: LOCAL_RANK 1, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 25, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 27: LOCAL_RANK 3, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 27, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 30: LOCAL_RANK 6, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 30, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 17: LOCAL_RANK 1, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 17, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 4: LOCAL_RANK 4, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 4, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 6: LOCAL_RANK 6, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 6, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 23: LOCAL_RANK 7, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 23, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 18: LOCAL_RANK 2, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 18, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 15: LOCAL_RANK 7, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 15, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 29: LOCAL_RANK 5, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 29, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 2: LOCAL_RANK 2, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 2, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-10-10 10:54:54 PM
RANK 12: LOCAL_RANK 4, MASTER_ADDR xe9680node30, MASTER_PORT 29500, WORLD_SIZE 32, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 3945, SLURM_NTASKS 32, SLURM_PROCID 12, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
| distributed init (rank 16): env://
| distributed init (rank 8): env://
| distributed init (rank 19): env://
| distributed init (rank 5): env://
| distributed init (rank 4): env://
| distributed init (rank 1): env://
| distributed init (rank 0): env://
| distributed init (rank 7): env://
| distributed init (rank 24): env://
| distributed init (rank 10): env://
| distributed init (rank 20): env://
| distributed init (rank 17): env://
| distributed init (rank 12): env://
| distributed init (rank 2): env://
| distributed init (rank 3): env://
| distributed init (rank 6): env://
| distributed init (rank 30): env://
| distributed init (rank 13): env://
| distributed init (rank 22): env://
| distributed init (rank 27): env://
| distributed init (rank 21): env://
| distributed init (rank 14): env://
| distributed init (rank 18): env://
| distributed init (rank 23): env://
| distributed init (rank 28): env://
| distributed init (rank 11): env://
| distributed init (rank 15): env://
| distributed init (rank 9): env://
| distributed init (rank 26): env://
| distributed init (rank 29): env://
| distributed init (rank 31): env://
| distributed init (rank 25): env://
:::MLLOG {"namespace": "", "time_ms": 1728600906416, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1728600906417, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1728600906417, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1728600906417, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1728600906417, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "4xDELL", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1728600906417, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 353}}
:::MLLOG {"namespace": "", "time_ms": 1728600906505, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3493622616, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1728600906505, "event_type": "POINT_IN_TIME", "key": "local_batch_size", "value": 16, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 371}}
:::MLLOG {"namespace": "", "time_ms": 1728600906505, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 512, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 372}}
:::MLLOG {"namespace": "", "time_ms": 1728600906505, "event_type": "POINT_IN_TIME", "key": "epoch_count", "value": 6, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 373}}
:::MLLOG {"namespace": "", "time_ms": 1728600906505, "event_type": "POINT_IN_TIME", "key": "first_epoch_num", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 374}}
Namespace(backbone='resnext50_32x4d', trainable_backbone_layers=3, sync_bn=False, data_layout='channels_last', amp=True, async_coco=True, async_coco_check_freq=20, num_eval_ranks=32, dataset='openimages-mlperf', dataset_path='/datasets/open-images-v6', num_classes=None, train_data_path=None, train_annotations_file=None, val_data_path=None, val_annotations_file=None, image_size=[800, 800], data_augmentation='hflip', epochs=6, max_iters_per_epoch=None, max_eval_iters_per_epoch=None, start_epoch=0, output_dir=None, target_map=0.34, resume='', pretrained=False, batch_size=16, eval_batch_size=32, lr=8.5e-05, warmup_epochs=0, warmup_factor=0.001, workers=4, print_freq=20, eval_print_freq=20, test_only=False, seed=3493622616, device='cuda', cocoeval='nvidia', coco_threads=8, world_size=32, dist_url='env://', frozen_bn_opt=True, frozen_bn_fp16=True, jit=True, cuda_graphs=True, cuda_graphs_eval=False, cls_head_pad=True, reg_head_pad=True, cuda_graphs_syn=True, model_warmup_epochs=16, master_weights=True, dali=True, dali_matched_idxs=True, dali_eval=True, dali_eval_cache=False, dali_prefetch_queue_depth=2, dali_cpu_decode=True, dali_pinned_memory_size=268435456, dali_cmn=0, dali_cmn_hint=0, dali_decoder_hint_height=7360, dali_decoder_hint_width=7360, dali_decoder_hw_load=0.65, dali_input_batch_multiplier=1, dali_eval_cmn_hint=0, dali_eval_decoder_hint_height=0, dali_eval_decoder_hint_width=0, dali_eval_decoder_hw_load=0.65, dali_eval_input_batch_multiplier=1, dali_sync=False, dali_resize_first=False, apex_adam=True, apex_focal_loss=True, apex_backbone_fusion=True, apex_head_fusion=True, broadcast_buffers=False, fp16_allreduce=False, ddp_bucket_sz=25, ddp_first_bucket_sz=None, no_gradient_as_bucket_view=False, max_boxes=1000, cudnn_bench=False, deterministic=False, not_graphed_prologues=False, metric_loss=False, syn_dataset=0, sync_after_graph_replay=False, allreduce_barrier=False, skip_eval=False, cuda_profiler=False, cuda_profiler_eval=False, cuda_profiler_start=-1, cuda_profiler_stop=-1, power_benchmark=False, power_sustain_time=600, rank=0, gpu=0, distributed=True, dist_backend='nccl', ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], num_train_ranks=32, train_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], eval_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], train_rank=0, eval_rank=0)
Getting dataset information
Creating model
:::MLLOG {"namespace": "", "time_ms": 1728600906533, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906551, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906552, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p7.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906554, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p7.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906685, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906685, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906686, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906686, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906686, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906686, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906686, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906686, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906687, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906687, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906687, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906687, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906687, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906688, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906688, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906689, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906690, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906690, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906690, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906691, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906691, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906692, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906692, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906693, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906693, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906694, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906695, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906697, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906700, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906702, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906702, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906705, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906707, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906708, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906710, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906712, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906713, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906715, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906730, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906749, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906758, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906759, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906768, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906777, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906779, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906877, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906878, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906878, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906880, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906880, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906882, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906882, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906884, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906885, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906887, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906887, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906889, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906902, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906905, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906905, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906907, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906907, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906910, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906910, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906912, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906934, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 148, "tensor": "module.head.classification_head.cls_logits.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906957, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 150, "tensor": "module.head.classification_head.cls_logits.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906968, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 317, "tensor": "module.head.regression_head.bbox_reg.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906968, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 319, "tensor": "module.head.regression_head.bbox_reg.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906968, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906971, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906971, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906973, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906974, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906976, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906976, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1728600906979, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.6.bias"}}
Casting convolutional layers to half
:::MLLOG {"namespace": "", "time_ms": 1728600907047, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 450}}
:::MLLOG {"namespace": "", "time_ms": 1728600907047, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 8.5e-05, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 451}}
:::MLLOG {"namespace": "", "time_ms": 1728600907047, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 452}}
:::MLLOG {"namespace": "", "time_ms": 1728600907047, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 453}}
:::MLLOG {"namespace": "", "time_ms": 1728600907047, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 454}}
:::MLLOG {"namespace": "", "time_ms": 1728600907047, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 455}}
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model eval warmup
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Time: 46.459677934646606 sec
Creating Dali training dataloader
Creating Dali eval dataloader
CUDA graph capture for training
CUDA graphs: data preprocessing complete
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
CUDA graphs: warmup iterations complete
CUDA graphs: capture complete
CUDA graph capture for training complete
:::MLLOG {"namespace": "", "time_ms": 1728600993995, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 575}}
:::MLLOG {"namespace": "", "time_ms": 1728600993997, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 579}}
:::MLLOG {"namespace": "", "time_ms": 1728600993997, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 2286, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1728600993997, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 25, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 636}}
Running ...
:::MLLOG {"namespace": "", "time_ms": 1728600993998, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 0}}
Epoch: [0]  [   0/2286]  eta: 0:02:12    time: 0.0582  data: 0.0003  max mem: 13791
Epoch: [0]  [  20/2286]  eta: 0:02:15    time: 0.0600  data: 0.0533  max mem: 13791
Epoch: [0]  [  40/2286]  eta: 0:02:16    time: 0.0615  data: 0.0548  max mem: 13791
Epoch: [0]  [  60/2286]  eta: 0:02:14    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [0]  [  80/2286]  eta: 0:02:13    time: 0.0605  data: 0.0539  max mem: 13791
Epoch: [0]  [ 100/2286]  eta: 0:02:11    time: 0.0601  data: 0.0535  max mem: 13791
Epoch: [0]  [ 120/2286]  eta: 0:02:10    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [0]  [ 140/2286]  eta: 0:02:08    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [ 160/2286]  eta: 0:02:07    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [0]  [ 180/2286]  eta: 0:02:06    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [0]  [ 200/2286]  eta: 0:02:05    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [0]  [ 220/2286]  eta: 0:02:03    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [0]  [ 240/2286]  eta: 0:02:02    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [ 260/2286]  eta: 0:02:01    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [ 280/2286]  eta: 0:01:59    time: 0.0594  data: 0.0530  max mem: 13791
Epoch: [0]  [ 300/2286]  eta: 0:01:58    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [0]  [ 320/2286]  eta: 0:01:57    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [0]  [ 340/2286]  eta: 0:01:56    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [ 360/2286]  eta: 0:01:55    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [ 380/2286]  eta: 0:01:53    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [ 400/2286]  eta: 0:01:52    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [0]  [ 420/2286]  eta: 0:01:51    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [0]  [ 440/2286]  eta: 0:01:50    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [0]  [ 460/2286]  eta: 0:01:49    time: 0.0612  data: 0.0530  max mem: 13791
Epoch: [0]  [ 480/2286]  eta: 0:01:47    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [0]  [ 500/2286]  eta: 0:01:46    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [0]  [ 520/2286]  eta: 0:01:45    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [ 540/2286]  eta: 0:01:44    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [0]  [ 560/2286]  eta: 0:01:43    time: 0.0647  data: 0.0580  max mem: 13791
Epoch: [0]  [ 580/2286]  eta: 0:01:42    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [ 600/2286]  eta: 0:01:41    time: 0.0643  data: 0.0573  max mem: 13791
Epoch: [0]  [ 620/2286]  eta: 0:01:40    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [ 640/2286]  eta: 0:01:38    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [ 660/2286]  eta: 0:01:37    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [0]  [ 680/2286]  eta: 0:01:36    time: 0.0607  data: 0.0530  max mem: 13791
Epoch: [0]  [ 700/2286]  eta: 0:01:35    time: 0.0595  data: 0.0528  max mem: 13791
Epoch: [0]  [ 720/2286]  eta: 0:01:33    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [ 740/2286]  eta: 0:01:32    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [0]  [ 760/2286]  eta: 0:01:31    time: 0.0596  data: 0.0529  max mem: 13791
Epoch: [0]  [ 780/2286]  eta: 0:01:30    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [ 800/2286]  eta: 0:01:29    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [0]  [ 820/2286]  eta: 0:01:27    time: 0.0603  data: 0.0536  max mem: 13791
Epoch: [0]  [ 840/2286]  eta: 0:01:26    time: 0.0628  data: 0.0563  max mem: 13791
Epoch: [0]  [ 860/2286]  eta: 0:01:25    time: 0.0629  data: 0.0562  max mem: 13791
Epoch: [0]  [ 880/2286]  eta: 0:01:24    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [0]  [ 900/2286]  eta: 0:01:23    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [0]  [ 920/2286]  eta: 0:01:22    time: 0.0613  data: 0.0547  max mem: 13791
Epoch: [0]  [ 940/2286]  eta: 0:01:20    time: 0.0615  data: 0.0548  max mem: 13791
Epoch: [0]  [ 960/2286]  eta: 0:01:19    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [ 980/2286]  eta: 0:01:18    time: 0.0603  data: 0.0536  max mem: 13791
Epoch: [0]  [1000/2286]  eta: 0:01:17    time: 0.0598  data: 0.0533  max mem: 13791
Epoch: [0]  [1020/2286]  eta: 0:01:16    time: 0.0599  data: 0.0533  max mem: 13791
Epoch: [0]  [1040/2286]  eta: 0:01:14    time: 0.0600  data: 0.0534  max mem: 13791
Epoch: [0]  [1060/2286]  eta: 0:01:13    time: 0.0599  data: 0.0533  max mem: 13791
Epoch: [0]  [1080/2286]  eta: 0:01:12    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [1100/2286]  eta: 0:01:11    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [0]  [1120/2286]  eta: 0:01:10    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [0]  [1140/2286]  eta: 0:01:08    time: 0.0622  data: 0.0557  max mem: 13791
Epoch: [0]  [1160/2286]  eta: 0:01:07    time: 0.0620  data: 0.0532  max mem: 13791
Epoch: [0]  [1180/2286]  eta: 0:01:06    time: 0.0609  data: 0.0544  max mem: 13791
Epoch: [0]  [1200/2286]  eta: 0:01:05    time: 0.0608  data: 0.0541  max mem: 13791
Epoch: [0]  [1220/2286]  eta: 0:01:04    time: 0.0599  data: 0.0533  max mem: 13791
Epoch: [0]  [1240/2286]  eta: 0:01:02    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [0]  [1260/2286]  eta: 0:01:01    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [1280/2286]  eta: 0:01:00    time: 0.0600  data: 0.0535  max mem: 13791
Epoch: [0]  [1300/2286]  eta: 0:00:59    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [1320/2286]  eta: 0:00:58    time: 0.0599  data: 0.0533  max mem: 13791
Epoch: [0]  [1340/2286]  eta: 0:00:56    time: 0.0614  data: 0.0546  max mem: 13791
Epoch: [0]  [1360/2286]  eta: 0:00:55    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [1380/2286]  eta: 0:00:54    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [1400/2286]  eta: 0:00:53    time: 0.0597  data: 0.0530  max mem: 13791
Epoch: [0]  [1420/2286]  eta: 0:00:52    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [1440/2286]  eta: 0:00:50    time: 0.0598  data: 0.0532  max mem: 13791
Corrupt JPEG data: premature end of data segment
Epoch: [0]  [1460/2286]  eta: 0:00:49    time: 0.0606  data: 0.0541  max mem: 13791
Epoch: [0]  [1480/2286]  eta: 0:00:48    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [1500/2286]  eta: 0:00:47    time: 0.0599  data: 0.0533  max mem: 13791
Epoch: [0]  [1520/2286]  eta: 0:00:46    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [1540/2286]  eta: 0:00:44    time: 0.0605  data: 0.0537  max mem: 13791
Epoch: [0]  [1560/2286]  eta: 0:00:43    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [0]  [1580/2286]  eta: 0:00:42    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [1600/2286]  eta: 0:00:41    time: 0.0599  data: 0.0532  max mem: 13791
Epoch: [0]  [1620/2286]  eta: 0:00:40    time: 0.0603  data: 0.0537  max mem: 13791
Epoch: [0]  [1640/2286]  eta: 0:00:38    time: 0.0608  data: 0.0542  max mem: 13791
Epoch: [0]  [1660/2286]  eta: 0:00:37    time: 0.0598  data: 0.0531  max mem: 13791
Epoch: [0]  [1680/2286]  eta: 0:00:36    time: 0.0617  data: 0.0552  max mem: 13791
Epoch: [0]  [1700/2286]  eta: 0:00:35    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [0]  [1720/2286]  eta: 0:00:34    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [1740/2286]  eta: 0:00:32    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [1760/2286]  eta: 0:00:31    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [1780/2286]  eta: 0:00:30    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [1800/2286]  eta: 0:00:29    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [0]  [1820/2286]  eta: 0:00:28    time: 0.0625  data: 0.0560  max mem: 13791
Epoch: [0]  [1840/2286]  eta: 0:00:26    time: 0.0629  data: 0.0563  max mem: 13791
Epoch: [0]  [1860/2286]  eta: 0:00:25    time: 0.0598  data: 0.0533  max mem: 13791
Epoch: [0]  [1880/2286]  eta: 0:00:24    time: 0.0599  data: 0.0533  max mem: 13791
Epoch: [0]  [1900/2286]  eta: 0:00:23    time: 0.0607  data: 0.0541  max mem: 13791
Epoch: [0]  [1920/2286]  eta: 0:00:22    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [1940/2286]  eta: 0:00:20    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [1960/2286]  eta: 0:00:19    time: 0.0622  data: 0.0557  max mem: 13791
Epoch: [0]  [1980/2286]  eta: 0:00:18    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [0]  [2000/2286]  eta: 0:00:17    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [0]  [2020/2286]  eta: 0:00:16    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [0]  [2040/2286]  eta: 0:00:14    time: 0.0606  data: 0.0539  max mem: 13791
Epoch: [0]  [2060/2286]  eta: 0:00:13    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [0]  [2080/2286]  eta: 0:00:12    time: 0.0644  data: 0.0578  max mem: 13791
Epoch: [0]  [2100/2286]  eta: 0:00:11    time: 0.0595  data: 0.0528  max mem: 13791
Epoch: [0]  [2120/2286]  eta: 0:00:09    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [2140/2286]  eta: 0:00:08    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [0]  [2160/2286]  eta: 0:00:07    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [0]  [2180/2286]  eta: 0:00:06    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [2200/2286]  eta: 0:00:05    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [0]  [2220/2286]  eta: 0:00:03    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [0]  [2240/2286]  eta: 0:00:02    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [0]  [2260/2286]  eta: 0:00:01    time: 0.0598  data: 0.0532  max mem: 13791
Epoch: [0]  [2280/2286]  eta: 0:00:00    time: 0.0632  data: 0.0564  max mem: 13791
Epoch: [0]  [2285/2286]  eta: 0:00:00    time: 0.0594  data: 0.0526  max mem: 13791
Epoch: [0] Total time: 0:02:17 (0.0602 s / it)
:::MLLOG {"namespace": "", "time_ms": 1728601131648, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1728601131648, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 265.93208673557194}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1728601131649, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 1}}
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [ 0/25]  eta: 0:00:10  model_time: 0.3995 (0.3995)  evaluator_time: 0.0041 (0.0041)  time: 0.4049  data: 0.0005  max mem: 13791
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [20/25]  eta: 0:00:01  model_time: 0.3183 (0.3251)  evaluator_time: 0.0045 (0.0049)  time: 0.3275  data: 0.0009  max mem: 13791
Test:  [24/25]  eta: 0:00:00  model_time: 0.3233 (0.3150)  evaluator_time: 0.0045 (0.0048)  time: 0.3188  data: 0.0009  max mem: 13791
Test: Total time: 0:00:08 (0.3209 s / it)
Averaged stats: model_time: 0.3233 (0.3189)  evaluator_time: 0.0045 (0.0044)
:::MLLOG {"namespace": "", "time_ms": 1728601140354, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 1}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [1]  [   0/2286]  eta: 0:02:16    time: 0.0599  data: 0.0010  max mem: 13791
Epoch: [1]  [  20/2286]  eta: 0:02:13    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [1]  [  40/2286]  eta: 0:02:13    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [1]  [  60/2286]  eta: 0:02:12    time: 0.0600  data: 0.0534  max mem: 13791
Epoch: [1]  [  80/2286]  eta: 0:02:11    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [1]  [ 100/2286]  eta: 0:02:09    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [1]  [ 120/2286]  eta: 0:02:08    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [ 140/2286]  eta: 0:02:07    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [1]  [ 160/2286]  eta: 0:02:06    time: 0.0602  data: 0.0535  max mem: 13791
:::MLLOG {"namespace": "", "time_ms": 1728601150467, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.20983571934964743, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1728601150467, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 1}}
Epoch: [1]  [ 180/2286]  eta: 0:02:05    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [1]  [ 200/2286]  eta: 0:02:04    time: 0.0605  data: 0.0539  max mem: 13791
Epoch: [1]  [ 220/2286]  eta: 0:02:03    time: 0.0599  data: 0.0534  max mem: 13791
Epoch: [1]  [ 240/2286]  eta: 0:02:02    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [1]  [ 260/2286]  eta: 0:02:00    time: 0.0604  data: 0.0538  max mem: 13791
Epoch: [1]  [ 280/2286]  eta: 0:01:59    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [ 300/2286]  eta: 0:01:58    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [1]  [ 320/2286]  eta: 0:01:57    time: 0.0609  data: 0.0530  max mem: 13791
Epoch: [1]  [ 340/2286]  eta: 0:01:56    time: 0.0602  data: 0.0534  max mem: 13791
Epoch: [1]  [ 360/2286]  eta: 0:01:55    time: 0.0596  data: 0.0529  max mem: 13791
Epoch: [1]  [ 380/2286]  eta: 0:01:53    time: 0.0605  data: 0.0539  max mem: 13791
Epoch: [1]  [ 400/2286]  eta: 0:01:52    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [1]  [ 420/2286]  eta: 0:01:51    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [ 440/2286]  eta: 0:01:50    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [1]  [ 460/2286]  eta: 0:01:49    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [1]  [ 480/2286]  eta: 0:01:47    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [1]  [ 500/2286]  eta: 0:01:46    time: 0.0595  data: 0.0531  max mem: 13791
Epoch: [1]  [ 520/2286]  eta: 0:01:45    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [ 540/2286]  eta: 0:01:44    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [1]  [ 560/2286]  eta: 0:01:43    time: 0.0596  data: 0.0529  max mem: 13791
Epoch: [1]  [ 580/2286]  eta: 0:01:41    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [ 600/2286]  eta: 0:01:40    time: 0.0610  data: 0.0544  max mem: 13791
Epoch: [1]  [ 620/2286]  eta: 0:01:39    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [ 640/2286]  eta: 0:01:38    time: 0.0593  data: 0.0529  max mem: 13791
Epoch: [1]  [ 660/2286]  eta: 0:01:37    time: 0.0603  data: 0.0538  max mem: 13791
Epoch: [1]  [ 680/2286]  eta: 0:01:35    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [ 700/2286]  eta: 0:01:34    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [1]  [ 720/2286]  eta: 0:01:33    time: 0.0609  data: 0.0543  max mem: 13791
Epoch: [1]  [ 740/2286]  eta: 0:01:32    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [1]  [ 760/2286]  eta: 0:01:31    time: 0.0633  data: 0.0568  max mem: 13791
Epoch: [1]  [ 780/2286]  eta: 0:01:30    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [ 800/2286]  eta: 0:01:28    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [ 820/2286]  eta: 0:01:27    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [1]  [ 840/2286]  eta: 0:01:26    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [ 860/2286]  eta: 0:01:25    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [1]  [ 880/2286]  eta: 0:01:24    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [1]  [ 900/2286]  eta: 0:01:22    time: 0.0633  data: 0.0569  max mem: 13791
Epoch: [1]  [ 920/2286]  eta: 0:01:21    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [ 940/2286]  eta: 0:01:20    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [1]  [ 960/2286]  eta: 0:01:19    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [1]  [ 980/2286]  eta: 0:01:18    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [1000/2286]  eta: 0:01:16    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [1]  [1020/2286]  eta: 0:01:15    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [1040/2286]  eta: 0:01:14    time: 0.0603  data: 0.0538  max mem: 13791
Epoch: [1]  [1060/2286]  eta: 0:01:13    time: 0.0602  data: 0.0537  max mem: 13791
Epoch: [1]  [1080/2286]  eta: 0:01:12    time: 0.0601  data: 0.0536  max mem: 13791
Epoch: [1]  [1100/2286]  eta: 0:01:10    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [1]  [1120/2286]  eta: 0:01:09    time: 0.0593  data: 0.0528  max mem: 13791
Corrupt JPEG data: premature end of data segment
Epoch: [1]  [1140/2286]  eta: 0:01:08    time: 0.0616  data: 0.0527  max mem: 13791
Epoch: [1]  [1160/2286]  eta: 0:01:07    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [1]  [1180/2286]  eta: 0:01:06    time: 0.0610  data: 0.0546  max mem: 13791
Epoch: [1]  [1200/2286]  eta: 0:01:04    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [1220/2286]  eta: 0:01:03    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [1240/2286]  eta: 0:01:02    time: 0.0617  data: 0.0549  max mem: 13791
Epoch: [1]  [1260/2286]  eta: 0:01:01    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [1]  [1280/2286]  eta: 0:01:00    time: 0.0609  data: 0.0544  max mem: 13791
Epoch: [1]  [1300/2286]  eta: 0:00:59    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [1320/2286]  eta: 0:00:57    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [1]  [1340/2286]  eta: 0:00:56    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [1]  [1360/2286]  eta: 0:00:55    time: 0.0614  data: 0.0549  max mem: 13791
Epoch: [1]  [1380/2286]  eta: 0:00:54    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [1]  [1400/2286]  eta: 0:00:53    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [1]  [1420/2286]  eta: 0:00:51    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [1]  [1440/2286]  eta: 0:00:50    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [1]  [1460/2286]  eta: 0:00:49    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [1480/2286]  eta: 0:00:48    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [1]  [1500/2286]  eta: 0:00:47    time: 0.0592  data: 0.0525  max mem: 13791
Epoch: [1]  [1520/2286]  eta: 0:00:45    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [1]  [1540/2286]  eta: 0:00:44    time: 0.0594  data: 0.0527  max mem: 13791
Epoch: [1]  [1560/2286]  eta: 0:00:43    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [1]  [1580/2286]  eta: 0:00:42    time: 0.0595  data: 0.0528  max mem: 13791
Epoch: [1]  [1600/2286]  eta: 0:00:41    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [1620/2286]  eta: 0:00:39    time: 0.0593  data: 0.0529  max mem: 13791
Epoch: [1]  [1640/2286]  eta: 0:00:38    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [1]  [1660/2286]  eta: 0:00:37    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [1]  [1680/2286]  eta: 0:00:36    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [1700/2286]  eta: 0:00:35    time: 0.0613  data: 0.0548  max mem: 13791
Epoch: [1]  [1720/2286]  eta: 0:00:33    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [1]  [1740/2286]  eta: 0:00:32    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [1760/2286]  eta: 0:00:31    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [1780/2286]  eta: 0:00:30    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [1]  [1800/2286]  eta: 0:00:29    time: 0.0608  data: 0.0526  max mem: 13791
Epoch: [1]  [1820/2286]  eta: 0:00:27    time: 0.0599  data: 0.0534  max mem: 13791
Epoch: [1]  [1840/2286]  eta: 0:00:26    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [1]  [1860/2286]  eta: 0:00:25    time: 0.0596  data: 0.0530  max mem: 13791
Epoch: [1]  [1880/2286]  eta: 0:00:24    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [1900/2286]  eta: 0:00:23    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [1]  [1920/2286]  eta: 0:00:21    time: 0.0600  data: 0.0534  max mem: 13791
Epoch: [1]  [1940/2286]  eta: 0:00:20    time: 0.0607  data: 0.0541  max mem: 13791
Epoch: [1]  [1960/2286]  eta: 0:00:19    time: 0.0613  data: 0.0548  max mem: 13791
Epoch: [1]  [1980/2286]  eta: 0:00:18    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [1]  [2000/2286]  eta: 0:00:17    time: 0.0612  data: 0.0546  max mem: 13791
Epoch: [1]  [2020/2286]  eta: 0:00:15    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [1]  [2040/2286]  eta: 0:00:14    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [1]  [2060/2286]  eta: 0:00:13    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [1]  [2080/2286]  eta: 0:00:12    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [1]  [2100/2286]  eta: 0:00:11    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [1]  [2120/2286]  eta: 0:00:09    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [2140/2286]  eta: 0:00:08    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [2160/2286]  eta: 0:00:07    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [1]  [2180/2286]  eta: 0:00:06    time: 0.0654  data: 0.0589  max mem: 13791
Epoch: [1]  [2200/2286]  eta: 0:00:05    time: 0.0604  data: 0.0536  max mem: 13791
Epoch: [1]  [2220/2286]  eta: 0:00:03    time: 0.0600  data: 0.0534  max mem: 13791
Epoch: [1]  [2240/2286]  eta: 0:00:02    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [1]  [2260/2286]  eta: 0:00:01    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [1]  [2280/2286]  eta: 0:00:00    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [1]  [2285/2286]  eta: 0:00:00    time: 0.0621  data: 0.0556  max mem: 13791
Epoch: [1] Total time: 0:02:16 (0.0598 s / it)
:::MLLOG {"namespace": "", "time_ms": 1728601277220, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1728601277220, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 267.4560231514182}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1728601277220, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 2}}
Test:  [ 0/25]  eta: 0:00:07  model_time: 0.2910 (0.2910)  evaluator_time: 0.0036 (0.0036)  time: 0.2956  data: 0.0008  max mem: 13791
Test:  [20/25]  eta: 0:00:01  model_time: 0.2809 (0.2849)  evaluator_time: 0.0041 (0.0077)  time: 0.2935  data: 0.0009  max mem: 13791
Test:  [24/25]  eta: 0:00:00  model_time: 0.2809 (0.2749)  evaluator_time: 0.0041 (0.0070)  time: 0.2822  data: 0.0009  max mem: 13791
Test: Total time: 0:00:07 (0.2829 s / it)
Averaged stats: model_time: 0.2809 (0.2802)  evaluator_time: 0.0041 (0.0070)
:::MLLOG {"namespace": "", "time_ms": 1728601284881, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 2}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [2]  [   0/2286]  eta: 0:02:16    time: 0.0597  data: 0.0009  max mem: 13791
Epoch: [2]  [  20/2286]  eta: 0:02:13    time: 0.0587  data: 0.0523  max mem: 13791
Epoch: [2]  [  40/2286]  eta: 0:02:12    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [  60/2286]  eta: 0:02:11    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [2]  [  80/2286]  eta: 0:02:10    time: 0.0592  data: 0.0526  max mem: 13791
:::MLLOG {"namespace": "", "time_ms": 1728601290445, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.28279521479571657, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1728601290445, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 2}}
Epoch: [2]  [ 100/2286]  eta: 0:02:09    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [ 120/2286]  eta: 0:02:08    time: 0.0614  data: 0.0548  max mem: 13791
Epoch: [2]  [ 140/2286]  eta: 0:02:08    time: 0.0628  data: 0.0562  max mem: 13791
Epoch: [2]  [ 160/2286]  eta: 0:02:07    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [ 180/2286]  eta: 0:02:05    time: 0.0591  data: 0.0539  max mem: 13791
Epoch: [2]  [ 200/2286]  eta: 0:02:04    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [2]  [ 220/2286]  eta: 0:02:03    time: 0.0589  data: 0.0525  max mem: 13791
Epoch: [2]  [ 240/2286]  eta: 0:02:02    time: 0.0630  data: 0.0564  max mem: 13791
Epoch: [2]  [ 260/2286]  eta: 0:02:01    time: 0.0602  data: 0.0538  max mem: 13791
Epoch: [2]  [ 280/2286]  eta: 0:02:00    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [2]  [ 300/2286]  eta: 0:01:58    time: 0.0592  data: 0.0528  max mem: 13791
Epoch: [2]  [ 320/2286]  eta: 0:01:57    time: 0.0595  data: 0.0528  max mem: 13791
Epoch: [2]  [ 340/2286]  eta: 0:01:56    time: 0.0599  data: 0.0534  max mem: 13791
Epoch: [2]  [ 360/2286]  eta: 0:01:55    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [2]  [ 380/2286]  eta: 0:01:54    time: 0.0620  data: 0.0556  max mem: 13791
Epoch: [2]  [ 400/2286]  eta: 0:01:53    time: 0.0617  data: 0.0552  max mem: 13791
Epoch: [2]  [ 420/2286]  eta: 0:01:51    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [2]  [ 440/2286]  eta: 0:01:50    time: 0.0592  data: 0.0528  max mem: 13791
Epoch: [2]  [ 460/2286]  eta: 0:01:49    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [ 480/2286]  eta: 0:01:48    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [ 500/2286]  eta: 0:01:47    time: 0.0613  data: 0.0548  max mem: 13791
Epoch: [2]  [ 520/2286]  eta: 0:01:45    time: 0.0620  data: 0.0556  max mem: 13791
Epoch: [2]  [ 540/2286]  eta: 0:01:44    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [2]  [ 560/2286]  eta: 0:01:43    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [2]  [ 580/2286]  eta: 0:01:42    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [2]  [ 600/2286]  eta: 0:01:40    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [ 620/2286]  eta: 0:01:39    time: 0.0616  data: 0.0550  max mem: 13791
Epoch: [2]  [ 640/2286]  eta: 0:01:38    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [ 660/2286]  eta: 0:01:37    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [ 680/2286]  eta: 0:01:36    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [ 700/2286]  eta: 0:01:34    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [ 720/2286]  eta: 0:01:33    time: 0.0601  data: 0.0537  max mem: 13791
Epoch: [2]  [ 740/2286]  eta: 0:01:32    time: 0.0598  data: 0.0533  max mem: 13791
Epoch: [2]  [ 760/2286]  eta: 0:01:31    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [ 780/2286]  eta: 0:01:30    time: 0.0592  data: 0.0528  max mem: 13791
Epoch: [2]  [ 800/2286]  eta: 0:01:28    time: 0.0615  data: 0.0550  max mem: 13791
Epoch: [2]  [ 820/2286]  eta: 0:01:27    time: 0.0645  data: 0.0579  max mem: 13791
Epoch: [2]  [ 840/2286]  eta: 0:01:26    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [2]  [ 860/2286]  eta: 0:01:25    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [ 880/2286]  eta: 0:01:24    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [2]  [ 900/2286]  eta: 0:01:23    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [ 920/2286]  eta: 0:01:21    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [ 940/2286]  eta: 0:01:20    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [2]  [ 960/2286]  eta: 0:01:19    time: 0.0592  data: 0.0528  max mem: 13791
Epoch: [2]  [ 980/2286]  eta: 0:01:18    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [1000/2286]  eta: 0:01:16    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [2]  [1020/2286]  eta: 0:01:15    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [2]  [1040/2286]  eta: 0:01:14    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [2]  [1060/2286]  eta: 0:01:13    time: 0.0598  data: 0.0533  max mem: 13791
Epoch: [2]  [1080/2286]  eta: 0:01:12    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [1100/2286]  eta: 0:01:10    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [1120/2286]  eta: 0:01:09    time: 0.0636  data: 0.0571  max mem: 13791
Epoch: [2]  [1140/2286]  eta: 0:01:08    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [1160/2286]  eta: 0:01:07    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [1180/2286]  eta: 0:01:06    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [1200/2286]  eta: 0:01:04    time: 0.0594  data: 0.0527  max mem: 13791
Epoch: [2]  [1220/2286]  eta: 0:01:03    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [1240/2286]  eta: 0:01:02    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [2]  [1260/2286]  eta: 0:01:01    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [2]  [1280/2286]  eta: 0:01:00    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [1300/2286]  eta: 0:00:58    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [1320/2286]  eta: 0:00:57    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [2]  [1340/2286]  eta: 0:00:56    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [1360/2286]  eta: 0:00:55    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [1380/2286]  eta: 0:00:54    time: 0.0607  data: 0.0541  max mem: 13791
Epoch: [2]  [1400/2286]  eta: 0:00:52    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [1420/2286]  eta: 0:00:51    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [2]  [1440/2286]  eta: 0:00:50    time: 0.0604  data: 0.0538  max mem: 13791
Epoch: [2]  [1460/2286]  eta: 0:00:49    time: 0.0608  data: 0.0544  max mem: 13791
Epoch: [2]  [1480/2286]  eta: 0:00:48    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [1500/2286]  eta: 0:00:46    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [2]  [1520/2286]  eta: 0:00:45    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [2]  [1540/2286]  eta: 0:00:44    time: 0.0592  data: 0.0528  max mem: 13791
Epoch: [2]  [1560/2286]  eta: 0:00:43    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [2]  [1580/2286]  eta: 0:00:42    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [1600/2286]  eta: 0:00:40    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [1620/2286]  eta: 0:00:39    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [1640/2286]  eta: 0:00:38    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [2]  [1660/2286]  eta: 0:00:37    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [1680/2286]  eta: 0:00:36    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [2]  [1700/2286]  eta: 0:00:35    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [2]  [1720/2286]  eta: 0:00:33    time: 0.0599  data: 0.0533  max mem: 13791
Epoch: [2]  [1740/2286]  eta: 0:00:32    time: 0.0611  data: 0.0546  max mem: 13791
Epoch: [2]  [1760/2286]  eta: 0:00:31    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [2]  [1780/2286]  eta: 0:00:30    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [1800/2286]  eta: 0:00:29    time: 0.0610  data: 0.0545  max mem: 13791
Epoch: [2]  [1820/2286]  eta: 0:00:27    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [1840/2286]  eta: 0:00:26    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [2]  [1860/2286]  eta: 0:00:25    time: 0.0604  data: 0.0539  max mem: 13791
Epoch: [2]  [1880/2286]  eta: 0:00:24    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [2]  [1900/2286]  eta: 0:00:23    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [1920/2286]  eta: 0:00:21    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [1940/2286]  eta: 0:00:20    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [2]  [1960/2286]  eta: 0:00:19    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [2]  [1980/2286]  eta: 0:00:18    time: 0.0617  data: 0.0536  max mem: 13791
Epoch: [2]  [2000/2286]  eta: 0:00:17    time: 0.0598  data: 0.0534  max mem: 13791
Epoch: [2]  [2020/2286]  eta: 0:00:15    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [2040/2286]  eta: 0:00:14    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [2060/2286]  eta: 0:00:13    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [2080/2286]  eta: 0:00:12    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [2100/2286]  eta: 0:00:11    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [2]  [2120/2286]  eta: 0:00:09    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [2140/2286]  eta: 0:00:08    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [2]  [2160/2286]  eta: 0:00:07    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [2]  [2180/2286]  eta: 0:00:06    time: 0.0594  data: 0.0529  max mem: 13791
Corrupt JPEG data: premature end of data segment
Epoch: [2]  [2200/2286]  eta: 0:00:05    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [2]  [2220/2286]  eta: 0:00:03    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [2]  [2240/2286]  eta: 0:00:02    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2]  [2260/2286]  eta: 0:00:01    time: 0.0610  data: 0.0545  max mem: 13791
Epoch: [2]  [2280/2286]  eta: 0:00:00    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [2]  [2285/2286]  eta: 0:00:00    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [2] Total time: 0:02:16 (0.0597 s / it)
:::MLLOG {"namespace": "", "time_ms": 1728601421392, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1728601421392, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 268.15263403272075}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1728601421393, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 3}}
Test:  [ 0/25]  eta: 0:00:06  model_time: 0.2581 (0.2581)  evaluator_time: 0.0032 (0.0032)  time: 0.2623  data: 0.0009  max mem: 13791
Test:  [20/25]  eta: 0:00:01  model_time: 0.2654 (0.2693)  evaluator_time: 0.0036 (0.0036)  time: 0.2745  data: 0.0009  max mem: 13791
Test:  [24/25]  eta: 0:00:00  model_time: 0.2663 (0.2608)  evaluator_time: 0.0036 (0.0035)  time: 0.2652  data: 0.0008  max mem: 13791
Test: Total time: 0:00:06 (0.2654 s / it)
Averaged stats: model_time: 0.2663 (0.2636)  evaluator_time: 0.0036 (0.0035)
:::MLLOG {"namespace": "", "time_ms": 1728601428578, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 3}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [3]  [   0/2285]  eta: 0:02:16    time: 0.0596  data: 0.0011  max mem: 13791
Epoch: [3]  [  20/2285]  eta: 0:02:16    time: 0.0601  data: 0.0522  max mem: 13791
Epoch: [3]  [  40/2285]  eta: 0:02:14    time: 0.0596  data: 0.0532  max mem: 13791
Epoch: [3]  [  60/2285]  eta: 0:02:12    time: 0.0589  data: 0.0524  max mem: 13791
:::MLLOG {"namespace": "", "time_ms": 1728601433340, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3216304776322774, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1728601433340, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 3}}
Epoch: [3]  [  80/2285]  eta: 0:02:10    time: 0.0589  data: 0.0525  max mem: 13791
Epoch: [3]  [ 100/2285]  eta: 0:02:10    time: 0.0602  data: 0.0536  max mem: 13791
Epoch: [3]  [ 120/2285]  eta: 0:02:08    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [ 140/2285]  eta: 0:02:07    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [3]  [ 160/2285]  eta: 0:02:06    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [3]  [ 180/2285]  eta: 0:02:05    time: 0.0601  data: 0.0536  max mem: 13791
Epoch: [3]  [ 200/2285]  eta: 0:02:04    time: 0.0601  data: 0.0536  max mem: 13791
Epoch: [3]  [ 220/2285]  eta: 0:02:02    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [3]  [ 240/2285]  eta: 0:02:01    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [3]  [ 260/2285]  eta: 0:02:00    time: 0.0598  data: 0.0534  max mem: 13791
Epoch: [3]  [ 280/2285]  eta: 0:01:59    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [3]  [ 300/2285]  eta: 0:01:58    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [3]  [ 320/2285]  eta: 0:01:56    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [3]  [ 340/2285]  eta: 0:01:55    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [ 360/2285]  eta: 0:01:54    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [ 380/2285]  eta: 0:01:53    time: 0.0592  data: 0.0524  max mem: 13791
Epoch: [3]  [ 400/2285]  eta: 0:01:51    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [3]  [ 420/2285]  eta: 0:01:50    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [ 440/2285]  eta: 0:01:49    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [3]  [ 460/2285]  eta: 0:01:48    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [ 480/2285]  eta: 0:01:47    time: 0.0630  data: 0.0566  max mem: 13791
Epoch: [3]  [ 500/2285]  eta: 0:01:46    time: 0.0622  data: 0.0556  max mem: 13791
Epoch: [3]  [ 520/2285]  eta: 0:01:45    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [ 540/2285]  eta: 0:01:43    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [3]  [ 560/2285]  eta: 0:01:42    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [3]  [ 580/2285]  eta: 0:01:41    time: 0.0605  data: 0.0540  max mem: 13791
Epoch: [3]  [ 600/2285]  eta: 0:01:40    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [ 620/2285]  eta: 0:01:39    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [3]  [ 640/2285]  eta: 0:01:38    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [ 660/2285]  eta: 0:01:36    time: 0.0593  data: 0.0526  max mem: 13791
Epoch: [3]  [ 680/2285]  eta: 0:01:35    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [3]  [ 700/2285]  eta: 0:01:34    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [ 720/2285]  eta: 0:01:33    time: 0.0603  data: 0.0538  max mem: 13791
Epoch: [3]  [ 740/2285]  eta: 0:01:32    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [ 760/2285]  eta: 0:01:30    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [3]  [ 780/2285]  eta: 0:01:29    time: 0.0601  data: 0.0526  max mem: 13791
Epoch: [3]  [ 800/2285]  eta: 0:01:28    time: 0.0589  data: 0.0522  max mem: 13791
Epoch: [3]  [ 820/2285]  eta: 0:01:27    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [3]  [ 840/2285]  eta: 0:01:26    time: 0.0592  data: 0.0525  max mem: 13791
Epoch: [3]  [ 860/2285]  eta: 0:01:24    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [ 880/2285]  eta: 0:01:23    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [3]  [ 900/2285]  eta: 0:01:22    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [ 920/2285]  eta: 0:01:21    time: 0.0611  data: 0.0546  max mem: 13791
Epoch: [3]  [ 940/2285]  eta: 0:01:20    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [ 960/2285]  eta: 0:01:18    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [ 980/2285]  eta: 0:01:17    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [3]  [1000/2285]  eta: 0:01:16    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [1020/2285]  eta: 0:01:15    time: 0.0594  data: 0.0527  max mem: 13791
Epoch: [3]  [1040/2285]  eta: 0:01:14    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [3]  [1060/2285]  eta: 0:01:12    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [3]  [1080/2285]  eta: 0:01:11    time: 0.0651  data: 0.0585  max mem: 13791
Epoch: [3]  [1100/2285]  eta: 0:01:10    time: 0.0592  data: 0.0525  max mem: 13791
Epoch: [3]  [1120/2285]  eta: 0:01:09    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [1140/2285]  eta: 0:01:08    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [1160/2285]  eta: 0:01:07    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [1180/2285]  eta: 0:01:05    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [3]  [1200/2285]  eta: 0:01:04    time: 0.0595  data: 0.0528  max mem: 13791
Epoch: [3]  [1220/2285]  eta: 0:01:03    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [1240/2285]  eta: 0:01:02    time: 0.0596  data: 0.0531  max mem: 13791
Epoch: [3]  [1260/2285]  eta: 0:01:01    time: 0.0610  data: 0.0544  max mem: 13791
Epoch: [3]  [1280/2285]  eta: 0:00:59    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [1300/2285]  eta: 0:00:58    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [1320/2285]  eta: 0:00:57    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [1340/2285]  eta: 0:00:56    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [3]  [1360/2285]  eta: 0:00:55    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [3]  [1380/2285]  eta: 0:00:53    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [3]  [1400/2285]  eta: 0:00:52    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [3]  [1420/2285]  eta: 0:00:51    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [3]  [1440/2285]  eta: 0:00:50    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [3]  [1460/2285]  eta: 0:00:49    time: 0.0591  data: 0.0539  max mem: 13791
Epoch: [3]  [1480/2285]  eta: 0:00:47    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [3]  [1500/2285]  eta: 0:00:46    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [3]  [1520/2285]  eta: 0:00:45    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [1540/2285]  eta: 0:00:44    time: 0.0609  data: 0.0544  max mem: 13791
Epoch: [3]  [1560/2285]  eta: 0:00:43    time: 0.0592  data: 0.0528  max mem: 13791
Epoch: [3]  [1580/2285]  eta: 0:00:41    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [3]  [1600/2285]  eta: 0:00:40    time: 0.0599  data: 0.0534  max mem: 13791
Epoch: [3]  [1620/2285]  eta: 0:00:39    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [1640/2285]  eta: 0:00:38    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [3]  [1660/2285]  eta: 0:00:37    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [1680/2285]  eta: 0:00:36    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [3]  [1700/2285]  eta: 0:00:34    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [3]  [1720/2285]  eta: 0:00:33    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [1740/2285]  eta: 0:00:32    time: 0.0613  data: 0.0547  max mem: 13791
Epoch: [3]  [1760/2285]  eta: 0:00:31    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [1780/2285]  eta: 0:00:30    time: 0.0608  data: 0.0527  max mem: 13791
Epoch: [3]  [1800/2285]  eta: 0:00:28    time: 0.0639  data: 0.0572  max mem: 13791
Epoch: [3]  [1820/2285]  eta: 0:00:27    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [3]  [1840/2285]  eta: 0:00:26    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [1860/2285]  eta: 0:00:25    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [3]  [1880/2285]  eta: 0:00:24    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [3]  [1900/2285]  eta: 0:00:22    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [1920/2285]  eta: 0:00:21    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [3]  [1940/2285]  eta: 0:00:20    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [3]  [1960/2285]  eta: 0:00:19    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [3]  [1980/2285]  eta: 0:00:18    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [3]  [2000/2285]  eta: 0:00:16    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [3]  [2020/2285]  eta: 0:00:15    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [3]  [2040/2285]  eta: 0:00:14    time: 0.0621  data: 0.0555  max mem: 13791
Epoch: [3]  [2060/2285]  eta: 0:00:13    time: 0.0588  data: 0.0523  max mem: 13791
Corrupt JPEG data: premature end of data segment
Epoch: [3]  [2080/2285]  eta: 0:00:12    time: 0.0593  data: 0.0529  max mem: 13791
Epoch: [3]  [2100/2285]  eta: 0:00:11    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [3]  [2120/2285]  eta: 0:00:09    time: 0.0664  data: 0.0599  max mem: 13791
Epoch: [3]  [2140/2285]  eta: 0:00:08    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [3]  [2160/2285]  eta: 0:00:07    time: 0.0591  data: 0.0524  max mem: 13791
Epoch: [3]  [2180/2285]  eta: 0:00:06    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [2200/2285]  eta: 0:00:05    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [3]  [2220/2285]  eta: 0:00:03    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [3]  [2240/2285]  eta: 0:00:02    time: 0.0624  data: 0.0558  max mem: 13791
Epoch: [3]  [2260/2285]  eta: 0:00:01    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [3]  [2280/2285]  eta: 0:00:00    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [3]  [2284/2285]  eta: 0:00:00    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [3] Total time: 0:02:16 (0.0596 s / it)
:::MLLOG {"namespace": "", "time_ms": 1728601564841, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1728601564841, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 268.52071279524415}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1728601564842, "event_type": "INTERVAL_START", "key": "eval_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 4}}
Test:  [ 0/25]  eta: 0:00:06  model_time: 0.2725 (0.2725)  evaluator_time: 0.0033 (0.0033)  time: 0.2771  data: 0.0012  max mem: 13791
Test:  [20/25]  eta: 0:00:01  model_time: 0.2673 (0.2726)  evaluator_time: 0.0036 (0.0073)  time: 0.2811  data: 0.0009  max mem: 13791
Test:  [24/25]  eta: 0:00:00  model_time: 0.2719 (0.2639)  evaluator_time: 0.0036 (0.0066)  time: 0.2728  data: 0.0008  max mem: 13791
Test: Total time: 0:00:06 (0.2716 s / it)
Averaged stats: model_time: 0.2719 (0.2676)  evaluator_time: 0.0036 (0.0058)
:::MLLOG {"namespace": "", "time_ms": 1728601572123, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 4}}
Epoch: [4]  [   0/2286]  eta: 0:02:16    time: 0.0597  data: 0.0009  max mem: 13791
Epoch: [4]  [  20/2286]  eta: 0:02:12    time: 0.0585  data: 0.0520  max mem: 13791
Epoch: [4]  [  40/2286]  eta: 0:02:11    time: 0.0587  data: 0.0522  max mem: 13791
Epoch: [4]  [  60/2286]  eta: 0:02:10    time: 0.0586  data: 0.0521  max mem: 13791
:::MLLOG {"namespace": "", "time_ms": 1728601576881, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.33945612221769333, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1728601576882, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 4}}
Epoch: [4]  [  80/2286]  eta: 0:02:09    time: 0.0593  data: 0.0529  max mem: 13791
Epoch: [4]  [ 100/2286]  eta: 0:02:08    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [4]  [ 120/2286]  eta: 0:02:07    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [4]  [ 140/2286]  eta: 0:02:06    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [4]  [ 160/2286]  eta: 0:02:05    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [ 180/2286]  eta: 0:02:04    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [4]  [ 200/2286]  eta: 0:02:02    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [4]  [ 220/2286]  eta: 0:02:01    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [4]  [ 240/2286]  eta: 0:02:00    time: 0.0587  data: 0.0522  max mem: 13791
Epoch: [4]  [ 260/2286]  eta: 0:01:59    time: 0.0602  data: 0.0535  max mem: 13791
Epoch: [4]  [ 280/2286]  eta: 0:01:58    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [4]  [ 300/2286]  eta: 0:01:57    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [4]  [ 320/2286]  eta: 0:01:56    time: 0.0636  data: 0.0570  max mem: 13791
Epoch: [4]  [ 340/2286]  eta: 0:01:55    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [4]  [ 360/2286]  eta: 0:01:54    time: 0.0597  data: 0.0531  max mem: 13791
Epoch: [4]  [ 380/2286]  eta: 0:01:53    time: 0.0593  data: 0.0529  max mem: 13791
Epoch: [4]  [ 400/2286]  eta: 0:01:51    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [4]  [ 420/2286]  eta: 0:01:50    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [4]  [ 440/2286]  eta: 0:01:49    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [4]  [ 460/2286]  eta: 0:01:48    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [4]  [ 480/2286]  eta: 0:01:47    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [4]  [ 500/2286]  eta: 0:01:46    time: 0.0608  data: 0.0525  max mem: 13791
Epoch: [4]  [ 520/2286]  eta: 0:01:44    time: 0.0611  data: 0.0547  max mem: 13791
Epoch: [4]  [ 540/2286]  eta: 0:01:43    time: 0.0598  data: 0.0533  max mem: 13791
Epoch: [4]  [ 560/2286]  eta: 0:01:42    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [4]  [ 580/2286]  eta: 0:01:41    time: 0.0610  data: 0.0545  max mem: 13791
Epoch: [4]  [ 600/2286]  eta: 0:01:40    time: 0.0595  data: 0.0529  max mem: 13791
Epoch: [4]  [ 620/2286]  eta: 0:01:39    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [ 640/2286]  eta: 0:01:37    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [4]  [ 660/2286]  eta: 0:01:36    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [4]  [ 680/2286]  eta: 0:01:35    time: 0.0592  data: 0.0528  max mem: 13791
Epoch: [4]  [ 700/2286]  eta: 0:01:34    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [4]  [ 720/2286]  eta: 0:01:33    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [4]  [ 740/2286]  eta: 0:01:31    time: 0.0603  data: 0.0539  max mem: 13791
Epoch: [4]  [ 760/2286]  eta: 0:01:30    time: 0.0639  data: 0.0573  max mem: 13791
Epoch: [4]  [ 780/2286]  eta: 0:01:29    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [ 800/2286]  eta: 0:01:28    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [4]  [ 820/2286]  eta: 0:01:27    time: 0.0590  data: 0.0526  max mem: 13791
Epoch: [4]  [ 840/2286]  eta: 0:01:26    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [4]  [ 860/2286]  eta: 0:01:24    time: 0.0589  data: 0.0523  max mem: 13791
Epoch: [4]  [ 880/2286]  eta: 0:01:23    time: 0.0591  data: 0.0527  max mem: 13791
Epoch: [4]  [ 900/2286]  eta: 0:01:22    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [4]  [ 920/2286]  eta: 0:01:21    time: 0.0589  data: 0.0524  max mem: 13791
Epoch: [4]  [ 940/2286]  eta: 0:01:20    time: 0.0603  data: 0.0539  max mem: 13791
Epoch: [4]  [ 960/2286]  eta: 0:01:18    time: 0.0608  data: 0.0544  max mem: 13791
Epoch: [4]  [ 980/2286]  eta: 0:01:17    time: 0.0588  data: 0.0522  max mem: 13791
Corrupt JPEG data: premature end of data segment
Epoch: [4]  [1000/2286]  eta: 0:01:16    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [4]  [1020/2286]  eta: 0:01:15    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [4]  [1040/2286]  eta: 0:01:14    time: 0.0623  data: 0.0557  max mem: 13791
Epoch: [4]  [1060/2286]  eta: 0:01:12    time: 0.0588  data: 0.0524  max mem: 13791
Epoch: [4]  [1080/2286]  eta: 0:01:11    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [1100/2286]  eta: 0:01:10    time: 0.0590  data: 0.0525  max mem: 13791
Epoch: [4]  [1120/2286]  eta: 0:01:09    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [4]  [1140/2286]  eta: 0:01:08    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [4]  [1160/2286]  eta: 0:01:06    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [4]  [1180/2286]  eta: 0:01:05    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [4]  [1200/2286]  eta: 0:01:04    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [4]  [1220/2286]  eta: 0:01:03    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [4]  [1240/2286]  eta: 0:01:02    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [4]  [1260/2286]  eta: 0:01:01    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [4]  [1280/2286]  eta: 0:00:59    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [4]  [1300/2286]  eta: 0:00:58    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [4]  [1320/2286]  eta: 0:00:57    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [4]  [1340/2286]  eta: 0:00:56    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [4]  [1360/2286]  eta: 0:00:55    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [4]  [1380/2286]  eta: 0:00:53    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [4]  [1400/2286]  eta: 0:00:52    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [4]  [1420/2286]  eta: 0:00:51    time: 0.0596  data: 0.0532  max mem: 13791
Epoch: [4]  [1440/2286]  eta: 0:00:50    time: 0.0602  data: 0.0526  max mem: 13791
Epoch: [4]  [1460/2286]  eta: 0:00:49    time: 0.0587  data: 0.0522  max mem: 13791
Epoch: [4]  [1480/2286]  eta: 0:00:47    time: 0.0589  data: 0.0525  max mem: 13791
Epoch: [4]  [1500/2286]  eta: 0:00:46    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [4]  [1520/2286]  eta: 0:00:45    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [4]  [1540/2286]  eta: 0:00:44    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [4]  [1560/2286]  eta: 0:00:43    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [4]  [1580/2286]  eta: 0:00:41    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [4]  [1600/2286]  eta: 0:00:40    time: 0.0595  data: 0.0530  max mem: 13791
Epoch: [4]  [1620/2286]  eta: 0:00:39    time: 0.0613  data: 0.0548  max mem: 13791
Epoch: [4]  [1640/2286]  eta: 0:00:38    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [4]  [1660/2286]  eta: 0:00:37    time: 0.0589  data: 0.0526  max mem: 13791
Epoch: [4]  [1680/2286]  eta: 0:00:36    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [4]  [1700/2286]  eta: 0:00:34    time: 0.0622  data: 0.0558  max mem: 13791
Epoch: [4]  [1720/2286]  eta: 0:00:33    time: 0.0607  data: 0.0522  max mem: 13791
Epoch: [4]  [1740/2286]  eta: 0:00:32    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [1760/2286]  eta: 0:00:31    time: 0.0593  data: 0.0526  max mem: 13791
Epoch: [4]  [1780/2286]  eta: 0:00:30    time: 0.0594  data: 0.0529  max mem: 13791
Epoch: [4]  [1800/2286]  eta: 0:00:28    time: 0.0589  data: 0.0523  max mem: 13791
Epoch: [4]  [1820/2286]  eta: 0:00:27    time: 0.0598  data: 0.0533  max mem: 13791
Epoch: [4]  [1840/2286]  eta: 0:00:26    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [4]  [1860/2286]  eta: 0:00:25    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [4]  [1880/2286]  eta: 0:00:24    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [4]  [1900/2286]  eta: 0:00:22    time: 0.0593  data: 0.0527  max mem: 13791
Epoch: [4]  [1920/2286]  eta: 0:00:21    time: 0.0620  data: 0.0555  max mem: 13791
Epoch: [4]  [1940/2286]  eta: 0:00:20    time: 0.0588  data: 0.0523  max mem: 13791
Epoch: [4]  [1960/2286]  eta: 0:00:19    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [4]  [1980/2286]  eta: 0:00:18    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [4]  [2000/2286]  eta: 0:00:17    time: 0.0594  data: 0.0528  max mem: 13791
Epoch: [4]  [2020/2286]  eta: 0:00:15    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [4]  [2040/2286]  eta: 0:00:14    time: 0.0591  data: 0.0525  max mem: 13791
Epoch: [4]  [2060/2286]  eta: 0:00:13    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [4]  [2080/2286]  eta: 0:00:12    time: 0.0592  data: 0.0527  max mem: 13791
Epoch: [4]  [2100/2286]  eta: 0:00:11    time: 0.0591  data: 0.0526  max mem: 13791
Epoch: [4]  [2120/2286]  eta: 0:00:09    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [4]  [2140/2286]  eta: 0:00:08    time: 0.0615  data: 0.0551  max mem: 13791
Epoch: [4]  [2160/2286]  eta: 0:00:07    time: 0.0588  data: 0.0524  max mem: 13791
Epoch: [4]  [2180/2286]  eta: 0:00:06    time: 0.0592  data: 0.0526  max mem: 13791
Epoch: [4]  [2200/2286]  eta: 0:00:05    time: 0.0593  data: 0.0528  max mem: 13791
Epoch: [4]  [2220/2286]  eta: 0:00:03    time: 0.0624  data: 0.0559  max mem: 13791
Epoch: [4]  [2240/2286]  eta: 0:00:02    time: 0.0590  data: 0.0524  max mem: 13791
Epoch: [4]  [2260/2286]  eta: 0:00:01    time: 0.0619  data: 0.0554  max mem: 13791
Epoch: [4]  [2280/2286]  eta: 0:00:00    time: 0.0596  data: 0.0532  max mem: 13791
Epoch: [4]  [2285/2286]  eta: 0:00:00    time: 0.0597  data: 0.0532  max mem: 13791
Epoch: [4] Total time: 0:02:15 (0.0595 s / it)
:::MLLOG {"namespace": "", "time_ms": 1728601708200, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1728601708200, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 269.01048981047796}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 5}}
:::MLLOG {"namespace": "", "time_ms": 1728601708201, "event_type": "INTERVAL_START", "key": "eval_start", "value": 5, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 5}}
Test:  [ 0/25]  eta: 0:00:06  model_time: 0.2510 (0.2510)  evaluator_time: 0.0032 (0.0032)  time: 0.2552  data: 0.0009  max mem: 13791
Test:  [20/25]  eta: 0:00:01  model_time: 0.2640 (0.2627)  evaluator_time: 0.0036 (0.0036)  time: 0.2680  data: 0.0009  max mem: 13791
Test:  [24/25]  eta: 0:00:00  model_time: 0.2593 (0.2532)  evaluator_time: 0.0036 (0.0035)  time: 0.2565  data: 0.0009  max mem: 13791
Test: Total time: 0:00:06 (0.2578 s / it)
Averaged stats: model_time: 0.2593 (0.2556)  evaluator_time: 0.0036 (0.0041)
:::MLLOG {"namespace": "", "time_ms": 1728601715135, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 5, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 5}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [5]  [   0/2286]  eta: 0:02:16    time: 0.0597  data: 0.0010  max mem: 13791
Epoch: [5]  [  20/2286]  eta: 0:02:12    time: 0.0584  data: 0.0519  max mem: 13791
Epoch: [5]  [  40/2286]  eta: 0:02:11    time: 0.0585  data: 0.0520  max mem: 13791
Epoch: [5]  [  60/2286]  eta: 0:02:12    time: 0.0617  data: 0.0551  max mem: 13791
:::MLLOG {"namespace": "", "time_ms": 1728601719664, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.35476867151031805, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1728601719664, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 5, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1728601719955, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 315, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1728601719955, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 5, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1728601719955, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 275.20314157638995}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 6}}
Run time 0:12:05
:::MLLOG {"namespace": "", "time_ms": 1728601719955, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 783}}
Loading annotations into memory...
Done (t=0.78s)
Creating index...
Done (t=1.19s)
Loading and preparing results...
DONE (t=3.28s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.41s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.20984
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.33722
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.22036
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00597
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.05074
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.23291
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.33977
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.49035
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.51233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.01947
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18238
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.56030
Loading and preparing results...
DONE (t=2.93s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.46s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28280
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.42811
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.30444
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00496
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.07349
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.31292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.37329
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.53086
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.55656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.02801
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.21290
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.60653
Loading and preparing results...
DONE (t=2.40s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.22s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32163
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.47097
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.34645
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00830
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09353
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.35573
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.39444
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.56138
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.58977
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.02933
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.25539
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.64051
Loading and preparing results...
DONE (t=2.44s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.17s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33946
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.48639
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.36677
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00787
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09250
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37505
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.40344
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.57309
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.60241
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03443
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.25036
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.65497
Loading and preparing results...
DONE (t=2.29s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.10s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.35477
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.50493
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.38245
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00899
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09861
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.39252
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.40932
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.58125
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.61002
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03863
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.25384
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.66276
[rank8]:[W1010 23:08:40.389979888 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank16]:[W1010 23:08:40.221823615 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank24]:[W1010 23:08:40.382065737 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank0]:[W1010 23:08:41.700195411 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
ENDING TIMING RUN AT 2024-10-10 11:08:44 PM
RESULT,SINGLE_STAGE_DETECTOR,,830,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:45 PM
RESULT,SINGLE_STAGE_DETECTOR,,831,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:46 PM
RESULT,SINGLE_STAGE_DETECTOR,,832,nvidia,2024-10-10 10:54:54 PM
ENDING TIMING RUN AT 2024-10-10 11:08:46 PM
RESULT,SINGLE_STAGE_DETECTOR,,832,nvidia,2024-10-10 10:54:54 PM
++ date +%s
+ echo 'RUNANDTIME_STOP 1728601726'
RUNANDTIME_STOP 1728601726
+ set -e
