+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ echo ':::DLPAL /mnt/orangefs/mlperf/llama/cont/loraubuntu.sqsh 334 8 GPU-[993,130,338,234,245,186,792,332] BM.GPU.H100.8 Cluster DGXH100_8x8x1xtp4pp1cp2'
:::DLPAL /mnt/orangefs/mlperf/llama/cont/loraubuntu.sqsh 334 8 GPU-[993,130,338,234,245,186,792,332] BM.GPU.H100.8 Cluster DGXH100_8x8x1xtp4pp1cp2
++ srun --ntasks=1 --container-name=llama2_70b_lora_334 mlperf-sysjson.sh
srun: warning: can't run 1 processes on 8 nodes, setting nnodes to 1
+ echo ':::SYSJSON {"submitter":"Oracle","division":"closed","status":"Available cloud","system_name":"BM.GPU.H100.8","number_of_nodes":"8","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8480+","host_processor_core_count":"56","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H100 80GB HBM3","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"81559 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-122-generic","nvidia_kernel_driver":"550.90.12"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"Oracle","division":"closed","status":"Available cloud","system_name":"BM.GPU.H100.8","number_of_nodes":"8","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8480+","host_processor_core_count":"56","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H100 80GB HBM3","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"81559 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-122-generic","nvidia_kernel_driver":"550.90.12"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ srun --ntasks=1 --container-name=llama2_70b_lora_334 bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
srun: warning: can't run 1 processes on 8 nodes, setting nnodes to 1
:::GITCOMMITID  
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 --mpi=pmix bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on GPU-993
Clearing cache on GPU-332
Clearing cache on GPU-245
Clearing cache on GPU-186
Clearing cache on GPU-234
Clearing cache on GPU-338
Clearing cache on GPU-792
Clearing cache on GPU-130
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ export SEED=6979
+ SEED=6979
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1728672805'
RUNANDTIME_START 1728672805
+ srun -l --mpi=pmix --ntasks=64 --ntasks-per-node=8 --time=20 --container-name=llama2_70b_lora_334 --container-mounts=/mnt/orangefs/mlperf/llama/data_model/gov_report:/data:ro,/mnt/orangefs/mlperf/llama/data_model/model:/ckpt:ro,/mnt/orangefs/mlperf/llama/logs:/results:rw --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
 0: STARTING TIMING RUN AT 2024-10-11 06:53:33 PM
48: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
36: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
 9: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
14: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
49: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
25: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
43: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
50: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
 3: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
 4: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
53: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
40: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
41: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
39: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
42: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
51: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
28: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
37: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
54: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
52: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
55: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
11: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
58: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
30: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
16: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
38: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
59: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
22: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
 5: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
46: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
44: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
33: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
45: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
47: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
57: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
20: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
35: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
34: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
32: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
63: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
 8: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
10: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
13: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
15: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
12: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
26: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
19: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
29: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
 6: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
31: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
17: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
21: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
23: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
18: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
27: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
24: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
 1: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
 7: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
 2: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
 0: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
61: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
62: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
56: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
60: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
 0: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 1: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 6: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 5: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 3: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 2: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 4: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 7: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
48: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
49: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
50: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
52: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
53: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
54: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
55: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
51: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
40: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
41: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
42: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
43: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
45: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
46: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
47: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
44: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
35: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
36: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
37: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
38: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
39: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
32: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
33: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
34: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 9: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
10: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
11: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
12: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
15: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
13: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 8: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
14: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
24: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
25: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
30: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
28: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
31: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
26: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
27: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
29: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
17: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
19: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
16: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
20: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
23: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
18: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
22: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
58: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
59: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
63: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
62: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
57: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
56: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
60: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
21: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
61: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 0: 
 0: 
 0: ************** Experiment configuration ***********
 0: 
 0: model:
 0:   ub_tp_comm_overlap_cfg:
 0:     qkv_fprop:
 0:       method: ring_exchange
 0:       aggregate: 0
 0:     fc1_fprop:
 0:       method: ring_exchange
 0:       aggregate: 0
 0:     proj_dgrad:
 0:       method: ring_exchange
 0:       aggregate: 0
 0:     fc2_dgrad:
 0:       method: ring_exchange
 0:       aggregate: 0
 0:     proj_fprop:
 0:       method: pipeline
 0:       num_sm: 32
 0:       cga_size: 2
 0:       num_splits: 4
 0:       set_sm_margin: 1
 0:       atomic_gemm: 1
 0:       fp8_buf: 1
 0:     fc2_fprop:
 0:       method: pipeline
 0:       num_sm: 16
 0:       cga_size: 2
 0:       num_splits: 4
 0:       set_sm_margin: 1
 0:       atomic_gemm: 1
 0:       fp8_buf: 0
 0:     qkv_dgrad:
 0:       method: bulk
 0:       num_sm: 4
 0:       cga_size: 2
 0:       set_sm_margin: 0
 0:     fc1_dgrad:
 0:       method: ring_exchange
 0:       num_sm: 1
 0:       cga_size: 2
 0:       set_sm_margin: 1
 0:       atomic_gemm: 0
 0:       fp8_buf: 0
 0:   mcore_gpt: true
 0:   seed: 6979
 0:   tensor_model_parallel_size: 4
 0:   pipeline_model_parallel_size: 1
 0:   context_parallel_size: 2
 0:   cpu_offloading: false
 0:   dist_ckpt_load_strictness: log_all
 0:   global_batch_size: 8
 0:   micro_batch_size: 1
 0:   max_position_embeddings: 8192
 0:   encoder_seq_length: 8192
 0:   restore_from_path: /ckpt
 0:   resume_from_checkpoint: null
 0:   save_nemo_on_validation_end: false
 0:   sync_batch_comm: false
 0:   megatron_amp_O2: true
 0:   sequence_parallel: 1
 0:   activations_checkpoint_granularity: null
 0:   activations_checkpoint_method: null
 0:   activations_checkpoint_num_layers: null
 0:   activations_checkpoint_layers_per_pipeline: null
 0:   answer_only_loss: true
 0:   gradient_as_bucket_view: false
 0:   hidden_dropout: 0.0
 0:   attention_dropout: 0.0
 0:   ffn_dropout: 0.0
 0:   bias_activation_fusion: true
 0:   bias_dropout_add_fusion: false
 0:   transformer_engine: true
 0:   fp8: true
 0:   fp8_params: true
 0:   fp8_hybrid: true
 0:   fp8_amax_history_len: 32
 0:   fp8_amax_compute_algo: max
 0:   reduce_amax: false
 0:   fp8_e4m3: false
 0:   fp8_interval: 1
 0:   fp8_margin: 0
 0:   fp8_dot_product_attention: 0
 0:   activation_func_fp8_input_store: 0
 0:   apply_rope_fusion: true
 0:   disable_parameter_transpose_cache: true
 0:   ub_tp_comm_overlap: 1
 0:   tp_comm_overlap_ag: true
 0:   tp_comm_overlap_rs: true
 0:   tp_comm_overlap_rs_dgrad: false
 0:   tp_comm_overlap_disable_qkv: true
 0:   batch_p2p_comm: 'False'
 0:   virtual_pipeline_model_parallel_size: 1
 0:   sharp: true
 0:   nccl_communicator_config_path: null
 0:   peft:
 0:     peft_scheme: lora
 0:     restore_from_path: null
 0:     lora_tuning:
 0:       adapter_dim: 16
 0:       alpha: 32
 0:       adapter_dropout: 0.1
 0:       dropout_position: pre
 0:       target_modules:
 0:       - attention
 0:       column_init_method: kaiming
 0:       row_init_method: zero
 0:       layer_selection: null
 0:       weight_tying: false
 0:       position_embedding_strategy: null
 0:       a2a_experimental: 1
 0:   data:
 0:     multiprocessing_context: spawn
 0:     pin_memory: true
 0:     sample_weight: constant
 0:     validation_drop_last: false
 0:     train_ds:
 0:       file_names:
 0:       - /data/train.npy
 0:       packed_sequence: true
 0:       packed_sequence_return_cu_seqlen: false
 0:       index_mapping_dir: /results/data_index/train
 0:       global_batch_size: 8
 0:       micro_batch_size: 1
 0:       shuffle: true
 0:       num_workers: 1
 0:       memmap_workers: 2
 0:       pin_memory: true
 0:       max_seq_length: 8192
 0:       min_seq_length: 1
 0:       drop_last: true
 0:       concat_sampling_probabilities:
 0:       - 1.0
 0:       label_key: output
 0:       add_eos: true
 0:       add_sep: false
 0:       add_bos: false
 0:       truncation_field: input
 0:       prompt_template: '{input} {output}'
 0:       truncation_method: right
 0:       seed: 6979
 0:     validation_ds:
 0:       file_names:
 0:       - /data/validation.npy
 0:       packed_sequence: true
 0:       packed_sequence_return_cu_seqlen: false
 0:       index_mapping_dir: /results/data_index/val
 0:       names: null
 0:       global_batch_size: 8
 0:       micro_batch_size: 1
 0:       shuffle: false
 0:       num_workers: 1
 0:       memmap_workers: 2
 0:       pin_memory: true
 0:       max_seq_length: 8192
 0:       min_seq_length: 1
 0:       drop_last: false
 0:       label_key: output
 0:       add_eos: true
 0:       add_sep: false
 0:       add_bos: false
 0:       write_predictions_to_file: false
 0:       output_file_path_prefix: null
 0:       truncation_field: input
 0:       prompt_template: '{input} {output}'
 0:       tokens_to_generate: 32
 0:       truncation_method: right
 0:       metric:
 0:         name: loss
 0:         average: null
 0:         num_classes: null
 0:   optim:
 0:     name: mcore_distributed_optim
 0:     overlap_grad_sync: true
 0:     overlap_param_sync: true
 0:     delay_grad_reduce: true
 0:     delay_param_gather: true
 0:     average_in_collective: false
 0:     lr: 0.0004
 0:     min_lr: 0
 0:     weight_decay: 0.0001
 0:     betas:
 0:     - 0.9
 0:     - 0.999
 0:     eps: 1.0e-08
 0:     amsgrad: false
 0:     sched:
 0:       name: CosineAnnealing
 0:       warmup_ratio: 0.0
 0:       min_lr: 0.0
 0:       constant_steps: 0
 0:       monitor: val_loss
 0:       reduce_on_plateau: false
 0:   enable_cuda_graph: 1
 0:   enable_cg_fp8_weight_caching: true
 0:   custom:
 0:     warmup: true
 0:     warmup_train_steps: 5
 0:     warmup_validation_steps: 5
 0:     reset_fp8_stats_after_warmup: 1
 0: name: megatron_gpt_peft_lora_tuning
 0: trainer:
 0:   devices: 8
 0:   num_nodes: 8
 0:   accelerator: gpu
 0:   precision: bf16-mixed
 0:   max_steps: 1024
 0:   val_check_interval: 192
 0:   check_val_every_n_epoch: null
 0:   log_every_n_steps: 0
 0:   gradient_clip_val: 0.3
 0:   gradient_clip_algorithm: norm
 0:   num_sanity_val_steps: 0
 0:   max_epochs: 1000
 0:   limit_val_batches: 1.0
 0:   limit_train_batches: 1.0
 0:   limit_test_batches: 0
 0:   logger: false
 0:   enable_checkpointing: false
 0:   use_distributed_sampler: false
 0:   enable_progress_bar: false
 0: exp_manager:
 0:   log_tflops_per_sec_per_gpu: false
 0:   explicit_log_dir: null
 0:   exp_dir: /results
 0:   create_wandb_logger: false
 0:   resume_if_exists: false
 0:   resume_ignore_no_checkpoint: true
 0:   create_checkpoint_callback: false
 0:   log_global_rank_0_only: true
 0:   create_early_stopping_callback: false
 0:   create_tensorboard_logger: false
 0: 
 0: GPU available: True (cuda), used: True
 0: TPU available: False, using: 0 TPU cores
 0: HPU available: False, using: 0 HPUs
 0: `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
 0: `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
 0: setting number of microbatches to constant 1
 7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/64
 5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/64
 6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/64
 2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/64
44: Initializing distributed: GLOBAL_RANK: 44, MEMBER: 45/64
46: Initializing distributed: GLOBAL_RANK: 46, MEMBER: 47/64
40: Initializing distributed: GLOBAL_RANK: 40, MEMBER: 41/64
 0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/64
45: Initializing distributed: GLOBAL_RANK: 45, MEMBER: 46/64
 3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/64
 1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/64
41: Initializing distributed: GLOBAL_RANK: 41, MEMBER: 42/64
 4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/64
49: Initializing distributed: GLOBAL_RANK: 49, MEMBER: 50/64
53: Initializing distributed: GLOBAL_RANK: 53, MEMBER: 54/64
51: Initializing distributed: GLOBAL_RANK: 51, MEMBER: 52/64
43: Initializing distributed: GLOBAL_RANK: 43, MEMBER: 44/64
47: Initializing distributed: GLOBAL_RANK: 47, MEMBER: 48/64
54: Initializing distributed: GLOBAL_RANK: 54, MEMBER: 55/64
48: Initializing distributed: GLOBAL_RANK: 48, MEMBER: 49/64
42: Initializing distributed: GLOBAL_RANK: 42, MEMBER: 43/64
50: Initializing distributed: GLOBAL_RANK: 50, MEMBER: 51/64
55: Initializing distributed: GLOBAL_RANK: 55, MEMBER: 56/64
52: Initializing distributed: GLOBAL_RANK: 52, MEMBER: 53/64
15: Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/64
14: Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/64
 8: Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/64
13: Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/64
12: Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/64
25: Initializing distributed: GLOBAL_RANK: 25, MEMBER: 26/64
29: Initializing distributed: GLOBAL_RANK: 29, MEMBER: 30/64
31: Initializing distributed: GLOBAL_RANK: 31, MEMBER: 32/64
30: Initializing distributed: GLOBAL_RANK: 30, MEMBER: 31/64
11: Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/64
10: Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/64
24: Initializing distributed: GLOBAL_RANK: 24, MEMBER: 25/64
28: Initializing distributed: GLOBAL_RANK: 28, MEMBER: 29/64
 9: Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/64
27: Initializing distributed: GLOBAL_RANK: 27, MEMBER: 28/64
26: Initializing distributed: GLOBAL_RANK: 26, MEMBER: 27/64
62: Initializing distributed: GLOBAL_RANK: 62, MEMBER: 63/64
60: Initializing distributed: GLOBAL_RANK: 60, MEMBER: 61/64
61: Initializing distributed: GLOBAL_RANK: 61, MEMBER: 62/64
59: Initializing distributed: GLOBAL_RANK: 59, MEMBER: 60/64
63: Initializing distributed: GLOBAL_RANK: 63, MEMBER: 64/64
35: Initializing distributed: GLOBAL_RANK: 35, MEMBER: 36/64
56: Initializing distributed: GLOBAL_RANK: 56, MEMBER: 57/64
57: Initializing distributed: GLOBAL_RANK: 57, MEMBER: 58/64
34: Initializing distributed: GLOBAL_RANK: 34, MEMBER: 35/64
58: Initializing distributed: GLOBAL_RANK: 58, MEMBER: 59/64
36: Initializing distributed: GLOBAL_RANK: 36, MEMBER: 37/64
32: Initializing distributed: GLOBAL_RANK: 32, MEMBER: 33/64
37: Initializing distributed: GLOBAL_RANK: 37, MEMBER: 38/64
33: Initializing distributed: GLOBAL_RANK: 33, MEMBER: 34/64
23: Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/64
20: Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/64
22: Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/64
39: Initializing distributed: GLOBAL_RANK: 39, MEMBER: 40/64
38: Initializing distributed: GLOBAL_RANK: 38, MEMBER: 39/64
16: Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/64
18: Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/64
17: Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/64
 2: NCCL version 2.22.3+cuda12.6
19: Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/64
 3: NCCL version 2.22.3+cuda12.6
21: Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/64
 0: ----------------------------------------------------------------------------------------------------
 0: distributed_backend=nccl
 0: All distributed processes registered. Starting with 64 processes
 0: ----------------------------------------------------------------------------------------------------
 0: 
 0: The number of process groups to use SHARP with depends on the type of the network switch. Nvidia QM1 switch supports SAHRP up to 8 process groups and QM2 supports up to 256 process groups. We apply SHARP to the communications of the data-parallel domain. If the number of data-parallel process groups is larger than the max process groups that the network switch supports, the communication will fall back to non-SHARP operators. To enable SHARP, `#SBATCH_NETWORK=sharp` should be set in the sbatch script.
 1: NCCL version 2.22.3+cuda12.6
 0: NCCL version 2.22.3+cuda12.6
 0: Loading distributed checkpoint with TensorStoreLoadShardedStrategy
 0: Loading distributed checkpoint directly on the GPU
40: make: Entering directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
 8: make: Entering directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
16: make: Entering directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
48: make: Entering directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
32: make: Entering directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
24: make: Entering directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
56: make: Entering directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
 0: make: Entering directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
16: g++ -O3 -Wall -shared -std=c++11 -fPIC -fdiagnostics-color -I/usr/include/python3.10 -I/usr/local/lib/python3.10/dist-packages/pybind11/include helpers.cpp -o helpers.cpython-310-x86_64-linux-gnu.so
32: g++ -O3 -Wall -shared -std=c++11 -fPIC -fdiagnostics-color -I/usr/include/python3.10 -I/usr/local/lib/python3.10/dist-packages/pybind11/include helpers.cpp -o helpers.cpython-310-x86_64-linux-gnu.so
 8: g++ -O3 -Wall -shared -std=c++11 -fPIC -fdiagnostics-color -I/usr/include/python3.10 -I/usr/local/lib/python3.10/dist-packages/pybind11/include helpers.cpp -o helpers.cpython-310-x86_64-linux-gnu.so
40: g++ -O3 -Wall -shared -std=c++11 -fPIC -fdiagnostics-color -I/usr/include/python3.10 -I/usr/local/lib/python3.10/dist-packages/pybind11/include helpers.cpp -o helpers.cpython-310-x86_64-linux-gnu.so
24: g++ -O3 -Wall -shared -std=c++11 -fPIC -fdiagnostics-color -I/usr/include/python3.10 -I/usr/local/lib/python3.10/dist-packages/pybind11/include helpers.cpp -o helpers.cpython-310-x86_64-linux-gnu.so
56: g++ -O3 -Wall -shared -std=c++11 -fPIC -fdiagnostics-color -I/usr/include/python3.10 -I/usr/local/lib/python3.10/dist-packages/pybind11/include helpers.cpp -o helpers.cpython-310-x86_64-linux-gnu.so
48: g++ -O3 -Wall -shared -std=c++11 -fPIC -fdiagnostics-color -I/usr/include/python3.10 -I/usr/local/lib/python3.10/dist-packages/pybind11/include helpers.cpp -o helpers.cpython-310-x86_64-linux-gnu.so
 0: g++ -O3 -Wall -shared -std=c++11 -fPIC -fdiagnostics-color -I/usr/include/python3.10 -I/usr/local/lib/python3.10/dist-packages/pybind11/include helpers.cpp -o helpers.cpython-310-x86_64-linux-gnu.so
16: make: Leaving directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
32: make: Leaving directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
40: make: Leaving directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
 8: make: Leaving directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
24: make: Leaving directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
56: make: Leaving directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
48: make: Leaving directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
 0: make: Leaving directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
 0: > building indices for blendable datasets ...
 0:  > sample ratios:
 0:    dataset 0, input: 1, achieved: 1
48: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
24: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
16: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
40: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
56: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
49: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
26: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 8: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
17: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
41: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
57: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
50: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
27: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
32: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 9: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
18: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 1: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
43: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
58: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
51: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
30: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
33: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
10: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
19: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 2: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
42: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
59: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
52: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
31: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
34: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
11: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
20: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 3: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
44: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
61: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
53: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
25: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
35: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
12: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
21: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 4: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
45: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
62: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
54: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
28: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
36: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
13: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
22: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 5: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
46: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
60: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
55: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
29: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
37: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
15: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
23: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 6: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
47: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
63: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
38: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
14: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 7: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
39: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
 0: Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=True, use_distributed_optimizer=True, check_for_nan_in_grad=False, bucket_size=40000000, average_in_collective=False)
 0: Number of buckets for gradient all-reduce / reduce-scatter: 1
 0: Params for bucket 1 (11141120 elements):
 0: 	module.decoder.layers.42.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.31.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.26.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.79.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.72.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.55.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.38.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.13.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.18.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.54.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.47.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.40.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.3.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.1.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.52.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.17.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.69.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.20.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.12.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.71.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.35.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.20.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.66.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.68.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.27.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.9.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.4.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.19.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.17.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.42.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.74.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.73.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.57.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.53.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.49.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.8.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.7.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.38.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.46.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.23.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.61.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.52.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.31.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.79.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.60.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.45.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.42.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.14.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.62.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.34.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.33.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.23.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.20.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.10.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.5.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.48.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.34.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.7.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.69.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.68.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.48.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.65.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.56.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.48.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.0.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.55.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.37.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.28.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.13.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.63.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.62.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.75.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.26.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.8.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.16.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.44.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.42.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.18.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.78.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.60.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.22.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.64.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.61.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.50.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.78.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.49.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.63.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.74.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.68.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.45.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.45.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.58.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.12.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.41.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.15.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.51.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.18.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.15.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.43.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.36.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.11.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.76.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.33.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.28.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.0.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.77.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.21.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.59.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.46.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.76.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.29.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.17.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.8.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.2.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.67.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.57.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.53.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.23.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.38.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.24.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.23.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.2.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.63.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.66.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.53.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.35.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.11.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.36.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.55.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.48.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.70.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.61.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.24.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.75.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.64.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.14.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.79.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.21.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.43.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.27.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.74.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.26.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.11.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.72.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.70.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.34.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.17.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.79.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.67.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.75.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.33.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.28.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.4.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.78.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.29.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.31.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.19.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.44.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.4.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.55.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.49.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.69.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.9.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.71.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.39.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.5.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.10.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.0.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.41.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.40.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.27.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.0.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.37.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.77.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.51.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.30.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.29.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.28.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.15.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.57.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.10.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.54.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.65.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.64.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.36.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.22.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.21.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.15.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.3.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.19.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.14.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.71.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.54.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.32.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.78.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.51.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.40.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.14.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.13.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.20.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.3.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.58.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.43.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.73.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.53.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.27.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.37.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.9.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.16.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.66.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.77.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.29.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.22.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.71.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.47.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.31.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.25.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.54.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.6.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.65.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.18.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.50.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.24.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.3.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.5.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.65.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.57.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.46.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.37.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.36.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.73.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.35.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.9.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.47.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.77.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.76.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.59.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.39.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.12.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.34.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.24.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.16.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.6.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.70.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.60.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.49.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.68.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.60.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.44.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.69.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.32.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.30.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.10.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.39.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.1.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.13.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.72.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.58.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.35.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.21.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.74.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.50.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.45.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.56.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.50.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.16.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.67.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.11.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.76.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.22.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.56.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.52.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.12.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.1.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.51.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.7.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.7.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.73.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.52.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.41.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.30.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.44.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.32.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.26.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.43.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.63.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.67.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.58.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.46.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.41.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.1.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.25.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.19.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.6.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.39.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.62.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.59.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.40.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.2.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.62.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.72.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.64.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.6.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.25.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.61.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.4.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.25.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.8.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.70.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: 	module.decoder.layers.47.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.33.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.30.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.56.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.5.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.2.self_attention.adapter_layer.lora_kqv_adapter.linear_out.weight
 0: 	module.decoder.layers.38.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.75.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.66.self_attention.adapter_layer.lora_dense_attention_adapter.linear_out.weight
 0: 	module.decoder.layers.59.self_attention.adapter_layer.lora_kqv_adapter.linear_in.weight
 0: 	module.decoder.layers.32.self_attention.adapter_layer.lora_dense_attention_adapter.linear_in.weight
 0: Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0004, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.0001, fp16=False, bf16=True, params_dtype=torch.bfloat16, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_grad_reduce=True, overlap_param_gather=True, overlap_param_gather_with_optimizer_step=False, align_param_gather=False, clip_grad=0.3, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')
 0: 
 0:   | Name         | Type | Params | Mode
 0: ---------------------------------------------
 0:   | other params | n/a  | 17.3 B | n/a 
 0: ---------------------------------------------
 0: 11.1 M    Trainable params
 0: 17.2 B    Non-trainable params
 0: 17.3 B    Total params
 0: 69,029.364Total estimated model params size (MB)
 0: 0         Modules in train mode
 0: 0         Modules in eval mode
 0: :::MLLOG {"namespace": "", "time_ms": 1728673098333, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 332}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673098333, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 333}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673098333, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "llama2_70b_lora", "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 334}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673098333, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "SUBMISSION_ORG_PLACEHOLDER", "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 334}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673098334, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 334}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673098334, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 334}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673098334, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 334}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673098334, "event_type": "POINT_IN_TIME", "key": "seed", "value": 6979, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 335}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673098334, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 8, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 341}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673099029, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 3901, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 346}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673099057, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 173, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 350}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673099057, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.0, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 354}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673099057, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.0001, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 358}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673099058, "event_type": "POINT_IN_TIME", "key": "opt_gradient_clip_norm", "value": 0.3, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 362}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673099058, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 367}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673099058, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 1024, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 368}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673099058, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0004, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 369}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673099058, "event_type": "POINT_IN_TIME", "key": "lora_rank", "value": 16, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 370}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673099058, "event_type": "POINT_IN_TIME", "key": "lora_alpha", "value": 32, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 371}}
 0: SLURM auto-requeueing enabled. Setting signal handlers.
24: SLURM auto-requeueing enabled. Setting signal handlers.
16: SLURM auto-requeueing enabled. Setting signal handlers.
40: SLURM auto-requeueing enabled. Setting signal handlers.
56: SLURM auto-requeueing enabled. Setting signal handlers.
48: SLURM auto-requeueing enabled. Setting signal handlers.
25: SLURM auto-requeueing enabled. Setting signal handlers.
32: SLURM auto-requeueing enabled. Setting signal handlers.
18: SLURM auto-requeueing enabled. Setting signal handlers.
59: SLURM auto-requeueing enabled. Setting signal handlers.
26: SLURM auto-requeueing enabled. Setting signal handlers.
19: SLURM auto-requeueing enabled. Setting signal handlers.
41: SLURM auto-requeueing enabled. Setting signal handlers.
60: SLURM auto-requeueing enabled. Setting signal handlers.
27: SLURM auto-requeueing enabled. Setting signal handlers.
33: SLURM auto-requeueing enabled. Setting signal handlers.
20: SLURM auto-requeueing enabled. Setting signal handlers.
 4: SLURM auto-requeueing enabled. Setting signal handlers.
42: SLURM auto-requeueing enabled. Setting signal handlers.
62: SLURM auto-requeueing enabled. Setting signal handlers.
49: SLURM auto-requeueing enabled. Setting signal handlers.
28: SLURM auto-requeueing enabled. Setting signal handlers.
34: SLURM auto-requeueing enabled. Setting signal handlers.
17: SLURM auto-requeueing enabled. Setting signal handlers.
43: SLURM auto-requeueing enabled. Setting signal handlers.
63: SLURM auto-requeueing enabled. Setting signal handlers.
50: SLURM auto-requeueing enabled. Setting signal handlers.
29: SLURM auto-requeueing enabled. Setting signal handlers.
35: SLURM auto-requeueing enabled. Setting signal handlers.
10: SLURM auto-requeueing enabled. Setting signal handlers.
21: SLURM auto-requeueing enabled. Setting signal handlers.
 5: SLURM auto-requeueing enabled. Setting signal handlers.
44: SLURM auto-requeueing enabled. Setting signal handlers.
57: SLURM auto-requeueing enabled. Setting signal handlers.
51: SLURM auto-requeueing enabled. Setting signal handlers.
30: SLURM auto-requeueing enabled. Setting signal handlers.
36: SLURM auto-requeueing enabled. Setting signal handlers.
11: SLURM auto-requeueing enabled. Setting signal handlers.
22: SLURM auto-requeueing enabled. Setting signal handlers.
 6: SLURM auto-requeueing enabled. Setting signal handlers.
45: SLURM auto-requeueing enabled. Setting signal handlers.
58: SLURM auto-requeueing enabled. Setting signal handlers.
53: SLURM auto-requeueing enabled. Setting signal handlers.
31: SLURM auto-requeueing enabled. Setting signal handlers.
37: SLURM auto-requeueing enabled. Setting signal handlers.
12: SLURM auto-requeueing enabled. Setting signal handlers.
23: SLURM auto-requeueing enabled. Setting signal handlers.
 7: SLURM auto-requeueing enabled. Setting signal handlers.
46: SLURM auto-requeueing enabled. Setting signal handlers.
61: SLURM auto-requeueing enabled. Setting signal handlers.
54: SLURM auto-requeueing enabled. Setting signal handlers.
38: SLURM auto-requeueing enabled. Setting signal handlers.
13: SLURM auto-requeueing enabled. Setting signal handlers.
 1: SLURM auto-requeueing enabled. Setting signal handlers.
47: SLURM auto-requeueing enabled. Setting signal handlers.
55: SLURM auto-requeueing enabled. Setting signal handlers.
39: SLURM auto-requeueing enabled. Setting signal handlers.
14: SLURM auto-requeueing enabled. Setting signal handlers.
 2: SLURM auto-requeueing enabled. Setting signal handlers.
52: SLURM auto-requeueing enabled. Setting signal handlers.
15: SLURM auto-requeueing enabled. Setting signal handlers.
 3: SLURM auto-requeueing enabled. Setting signal handlers.
 8: SLURM auto-requeueing enabled. Setting signal handlers.
 9: SLURM auto-requeueing enabled. Setting signal handlers.
55: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
54: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
52: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 1: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 4: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 7: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
33: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
53: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
48: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
49: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
50: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 5: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
35: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 6: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 3: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
32: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 2: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 0: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 8: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
44: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
51: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
22: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
46: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
34: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
41: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
37: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
16: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
36: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
38: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
39: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
17: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
18: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
10: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 9: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
45: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
19: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
12: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
20: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
11: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
25: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
42: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
14: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
47: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
40: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
23: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
13: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
43: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
15: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
21: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
30: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
28: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
24: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
57: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
31: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
29: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
27: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
56: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
61: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
26: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
63: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
60: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
62: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
58: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
59: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
16: !!! [UB] Global ranks on node 2: [16, 17, 18, 19, 20, 21, 22, 23]
40: !!! [UB] Global ranks on node 5: [40, 41, 42, 43, 44, 45, 46, 47]
 0: !!! [UB] Number of physical nodes: 8
 0: !!! [UB] Global ranks on node 0: [0, 1, 2, 3, 4, 5, 6, 7]
48: !!! [UB] Global ranks on node 6: [48, 49, 50, 51, 52, 53, 54, 55]
 8: !!! [UB] Global ranks on node 1: [8, 9, 10, 11, 12, 13, 14, 15]
56: !!! [UB] Global ranks on node 7: [56, 57, 58, 59, 60, 61, 62, 63]
 0: !!! [UB] Create Userbuffers Communicator
 0: UB_TIMEOUT is set to 110 sec, 217800000000 cycles, freq: 1980000khz
32: !!! [UB] Global ranks on node 4: [32, 33, 34, 35, 36, 37, 38, 39]
24: !!! [UB] Global ranks on node 3: [24, 25, 26, 27, 28, 29, 30, 31]
 0: MC initialized succesfully, window size = 549755813888
 0: !!! [UBP2P] Register UBuf 1
 0: !!! [UBP2P] Register UBuf 2
 0: !!! [UBP2P] Register UBuf 3
 0: !!! [UBP2P] Register UBuf 4
 0: !!! [UBP2P] Register UBuf 5
 0: !!! [UB] Register UBuf 6
 0: !!! [UB] Register UBuf 7
 0: !!! [UB] Register UBuf 8
 0: !!! [UB] Register UBuf 9
 0: !!! [UB] Register UBuf 10
48: NCCL version 2.22.3+cuda12.6
52: NCCL version 2.22.3+cuda12.6
 4: NCCL version 2.22.3+cuda12.6
16: NCCL version 2.22.3+cuda12.6
20: NCCL version 2.22.3+cuda12.6
 8: NCCL version 2.22.3+cuda12.6
12: NCCL version 2.22.3+cuda12.6
60: NCCL version 2.22.3+cuda12.6
56: NCCL version 2.22.3+cuda12.6
24: NCCL version 2.22.3+cuda12.6
32: NCCL version 2.22.3+cuda12.6
44: NCCL version 2.22.3+cuda12.6
28: NCCL version 2.22.3+cuda12.6
36: NCCL version 2.22.3+cuda12.6
40: NCCL version 2.22.3+cuda12.6
49: NCCL version 2.22.3+cuda12.6
50: NCCL version 2.22.3+cuda12.6
51: NCCL version 2.22.3+cuda12.6
11: NCCL version 2.22.3+cuda12.6
10: NCCL version 2.22.3+cuda12.6
 9: NCCL version 2.22.3+cuda12.6
17: NCCL version 2.22.3+cuda12.6
18: NCCL version 2.22.3+cuda12.6
19: NCCL version 2.22.3+cuda12.6
25: NCCL version 2.22.3+cuda12.6
26: NCCL version 2.22.3+cuda12.6
27: NCCL version 2.22.3+cuda12.6
59: NCCL version 2.22.3+cuda12.6
57: NCCL version 2.22.3+cuda12.6
58: NCCL version 2.22.3+cuda12.6
34: NCCL version 2.22.3+cuda12.6
33: NCCL version 2.22.3+cuda12.6
35: NCCL version 2.22.3+cuda12.6
42: NCCL version 2.22.3+cuda12.6
41: NCCL version 2.22.3+cuda12.6
43: NCCL version 2.22.3+cuda12.6
 5: NCCL version 2.22.3+cuda12.6
 7: NCCL version 2.22.3+cuda12.6
 6: NCCL version 2.22.3+cuda12.6
 0: :::MLLOG {"namespace": "", "time_ms": 1728673209637, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 271}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673209637, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 271}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673209637, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 272, "samples_count": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673215146, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 2.172919273376465, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 80, "lr": 0.00039990588350021866}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673220644, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.397352933883667, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 160, "lr": 0.00039962362258002984}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673226142, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2881649732589722, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 240, "lr": 0.000399153482893532}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673231648, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3971680402755737, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 320, "lr": 0.000398495906919742}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673237163, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3093165159225464, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 400, "lr": 0.0003976515135461499}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673242691, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.315916895866394, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 480, "lr": 0.0003966210974862433}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673248223, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.247778296470642, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 560, "lr": 0.0003954056285315509}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673253773, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.316312313079834, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 640, "lr": 0.00039400625063890885}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673259329, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2952642440795898, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 720, "lr": 0.00039242428085380836}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673264882, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.329268455505371, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 800, "lr": 0.00039066120807083876}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673270436, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.274300456047058, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 880, "lr": 0.00038871869163239207}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673275992, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3017854690551758, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 960, "lr": 0.0003865985597669478}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673281554, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3200379610061646, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 1040, "lr": 0.0003843028078684084}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673287114, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3606668710708618, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 1120, "lr": 0.0003818335966181045}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673292662, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3524527549743652, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 1200, "lr": 0.00037919324995123706}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673298216, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.289283275604248, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 1280, "lr": 0.000376384252869671}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673303765, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2105656862258911, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 1360, "lr": 0.00037340924910313856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673309305, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.372492790222168, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 1440, "lr": 0.00037027103862105306}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673314835, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2499969005584717, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 1520, "lr": 0.000366972574997276}}
55: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
20: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
30: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
41: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
45: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
18: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
40: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
19: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
17: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
44: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
47: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
46: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
43: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
42: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
36: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
22: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
23: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
38: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
34: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
33: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
35: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
32: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
62: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
63: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
60: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 1: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 3: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
16: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
39: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
57: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
58: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
59: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
21: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
61: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
25: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
37: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
56: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
31: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
12: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 4: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 9: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
49: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 7: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
29: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 8: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
10: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
14: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
15: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
28: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
13: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 0: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 5: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
24: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
11: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 2: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
26: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 6: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
52: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
48: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
53: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
27: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
51: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
50: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
54: `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).
 0: :::MLLOG {"namespace": "", "time_ms": 1728673325572, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 14.456053299242711}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 287, "step": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673325572, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 236, "samples_count": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673325572, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 241, "samples_count": 1536}}
 0: setting number of microbatches to constant 1
 0: setting number of microbatches to constant 1
 0: :::MLLOG {"namespace": "", "time_ms": 1728673335489, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9396336674690247, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 307, "samples_count": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673335489, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 312, "samples_count": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673335489, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 253, "samples_count": 1536}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673339915, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3370096683502197, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 1600, "lr": 0.00036351696263031675}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673345460, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.391549825668335, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 1680, "lr": 0.00035990745382158103}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673351012, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2565371990203857, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 1760, "lr": 0.0003561474457144189}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673356566, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2826430797576904, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 1840, "lr": 0.0003522404770968524}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673362113, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2899227142333984, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 1920, "lr": 0.00034819022507099186}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673362119, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 14.429728280671243}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 287, "step": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673362119, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 236, "samples_count": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673362120, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 241, "samples_count": 1920}}
 0: setting number of microbatches to constant 1
 0: setting number of microbatches to constant 1
 0: :::MLLOG {"namespace": "", "time_ms": 1728673371915, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9350014328956604, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 307, "samples_count": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673371915, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 312, "samples_count": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673371915, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 253, "samples_count": 1920}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673377448, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.238018274307251, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 2000, "lr": 0.00034400050159227635}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673382988, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3644357919692993, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 2080, "lr": 0.0003396752498817946}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673388523, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3824188709259033, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 2160, "lr": 0.0003352185407150632}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673394055, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2366971969604492, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 2240, "lr": 0.0003306345685907553}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673398487, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 14.461615757889792}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 287, "step": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673398487, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 236, "samples_count": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673398487, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 241, "samples_count": 2304}}
 0: setting number of microbatches to constant 1
 0: setting number of microbatches to constant 1
 0: :::MLLOG {"namespace": "", "time_ms": 1728673408185, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9295991063117981, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 307, "samples_count": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673408186, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 312, "samples_count": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673408186, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 253, "samples_count": 2304}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673409289, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2384982109069824, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 2320, "lr": 0.00032592764778298545}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673414827, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3681262731552124, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 2400, "lr": 0.00032110220828086513}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673420371, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3411619663238525, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 2480, "lr": 0.0003161627916191529}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673425901, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.219067096710205, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 2560, "lr": 0.00031111404660392046}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673431461, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3504557609558105, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 2640, "lr": 0.000305960724937259}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673434789, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 14.444653482399854}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 287, "step": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673434789, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 236, "samples_count": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673434789, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 241, "samples_count": 2688}}
 0: setting number of microbatches to constant 1
 0: setting number of microbatches to constant 1
 0: :::MLLOG {"namespace": "", "time_ms": 1728673444225, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9315811991691589, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 307, "samples_count": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673444225, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 312, "samples_count": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673444225, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 253, "samples_count": 2688}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673446432, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2560577392578125, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 2720, "lr": 0.00030070767674514353}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673451966, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2585535049438477, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 2800, "lr": 0.00029535984601266447}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673457504, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2820922136306763, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 2880, "lr": 0.00028992226593092135}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673463038, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2724602222442627, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 2960, "lr": 0.00028440005415995997}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673468563, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2760276794433594, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 3040, "lr": 0.00027879840801220965}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673470780, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 14.470905488950923}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 287, "step": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673470780, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 236, "samples_count": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673470780, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 241, "samples_count": 3072}}
 0: setting number of microbatches to constant 1
 0: setting number of microbatches to constant 1
 0: :::MLLOG {"namespace": "", "time_ms": 1728673480383, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9254415035247803, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 307, "samples_count": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673480383, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 312, "samples_count": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673480383, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 253, "samples_count": 3072}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673483704, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.262168288230896, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 3120, "lr": 0.0002731225995609548}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673489247, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2765939235687256, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 3200, "lr": 0.000267377970678444}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673494787, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2480125427246094, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 3280, "lr": 0.000261569928008307}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673500323, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3061022758483887, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 3360, "lr": 0.0002557039378770106}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673505853, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.392062783241272, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 223, "samples_count": 3440, "lr": 0.0002497855211491441}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673506965, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 14.456075097325074}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 287, "step": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673506966, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 236, "samples_count": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673506966, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 241, "samples_count": 3456}}
 0: setting number of microbatches to constant 1
 0: setting number of microbatches to constant 1
 0: :::MLLOG {"namespace": "", "time_ms": 1728673516660, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9207051992416382, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 307, "samples_count": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673516661, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 312, "samples_count": 3456}}
 0: :::MLLOG {"namespace": "", "time_ms": 1728673516661, "event_type": "INTERVAL_END", "key": "run_stop", "value": 0.9207051992416382, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 321, "samples_count": 3456, "status": "success"}}
63: [rank63]:[W1011 19:05:21.058389322 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
41: [rank41]:[W1011 19:05:21.824982891 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
55: [rank55]:[W1011 19:05:21.704197064 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 7: [rank7]:[W1011 19:05:21.556045853 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
30: [rank30]:[W1011 19:05:21.430843166 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
20: [rank20]:[W1011 19:05:21.052476744 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
22: [rank22]:[W1011 19:05:21.063215849 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
28: [rank28]:[W1011 19:05:21.475569863 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
59: [rank59]:[W1011 19:05:21.131222642 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
23: [rank23]:[W1011 19:05:21.068897408 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
21: [rank21]:[W1011 19:05:21.069305257 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
29: [rank29]:[W1011 19:05:21.477391129 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
43: [rank43]:[W1011 19:05:21.899422510 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
31: [rank31]:[W1011 19:05:21.487099934 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
47: [rank47]:[W1011 19:05:21.900111884 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 5: [rank5]:[W1011 19:05:21.627842386 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
46: [rank46]:[W1011 19:05:21.904426837 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 6: [rank6]:[W1011 19:05:21.630945612 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
61: [rank61]:[W1011 19:05:21.152456773 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
32: [rank32]:[W1011 19:05:21.095816061 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 4: [rank4]:[W1011 19:05:21.640615288 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
62: [rank62]:[W1011 19:05:21.156388251 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
42: [rank42]:[W1011 19:05:21.914523436 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
40: [rank40]:[W1011 19:05:21.914737103 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
26: [rank26]:[W1011 19:05:21.501595524 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
24: [rank24]:[W1011 19:05:21.501761493 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 0: [rank0]:[W1011 19:05:21.641414512 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
60: [rank60]:[W1011 19:05:21.160644042 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
44: [rank44]:[W1011 19:05:21.918795347 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 3: [rank3]:[W1011 19:05:21.646176784 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
16: [rank16]:[W1011 19:05:21.099982355 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
38: [rank38]:[W1011 19:05:21.109658631 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
56: [rank56]:[W1011 19:05:21.166819797 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 8: [rank8]:[W1011 19:05:21.572067217 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 9: [rank9]:[W1011 19:05:21.572665442 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 1: [rank1]:[W1011 19:05:21.652241570 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
36: [rank36]:[W1011 19:05:21.113890276 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
27: [rank27]:[W1011 19:05:21.516592027 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
11: [rank11]:[W1011 19:05:21.576648088 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
19: [rank19]:[W1011 19:05:21.108616180 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
35: [rank35]:[W1011 19:05:21.114720243 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
39: [rank39]:[W1011 19:05:21.115393396 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
15: [rank15]:[W1011 19:05:21.577497133 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
13: [rank13]:[W1011 19:05:21.577687768 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
48: [rank48]:[W1011 19:05:21.808800857 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
18: [rank18]:[W1011 19:05:21.113688628 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
34: [rank34]:[W1011 19:05:21.119782082 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
14: [rank14]:[W1011 19:05:21.581794968 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
54: [rank54]:[W1011 19:05:21.812396830 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 2: [rank2]:[W1011 19:05:21.661366788 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
10: [rank10]:[W1011 19:05:21.581848767 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
17: [rank17]:[W1011 19:05:21.114620887 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
52: [rank52]:[W1011 19:05:21.816537907 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
12: [rank12]:[W1011 19:05:21.586018455 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
51: [rank51]:[W1011 19:05:21.817346264 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
58: [rank58]:[W1011 19:05:21.186769503 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
50: [rank50]:[W1011 19:05:21.822532285 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
57: [rank57]:[W1011 19:05:21.187708397 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
33: [rank33]:[W1011 19:05:21.130747558 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
25: [rank25]:[W1011 19:05:21.532774511 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
49: [rank49]:[W1011 19:05:21.823403277 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
45: [rank45]:[W1011 19:05:21.950770045 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
53: [rank53]:[W1011 19:05:21.828329286 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
37: [rank37]:[W1011 19:05:21.135740768 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 1, retcode 3
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1521 NCCL WARN [Proxy Service 0] Failed to execute operation Close from rank 0, retcode 3
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 0, retcode 3
 2: 
 2: GPU-993:1824018:1825753 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1521 NCCL WARN [Proxy Service 0] Failed to execute operation Close from rank 2, retcode 3
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 2, retcode 3
 2: 
 2: GPU-993:1824018:1825753 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 2: 
 2: GPU-993:1824018:1825753 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 2, retcode 3
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 8, retcode 3
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 9, retcode 3
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 9, retcode 3
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 8, retcode 3
 3: 
 3: GPU-993:1823970:1825755 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1521 NCCL WARN [Proxy Service 0] Failed to execute operation Close from rank 3, retcode 3
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 3, retcode 3
 2: 
 2: GPU-993:1824018:1825753 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 2: 
 2: GPU-993:1824018:1825753 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 3, retcode 3
 3: 
 3: GPU-993:1823970:1825755 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 3: 
 3: GPU-993:1823970:1825755 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 3, retcode 3
 4: 
 4: GPU-993:1824002:1825759 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1521 NCCL WARN [Proxy Service 0] Failed to execute operation Close from rank 4, retcode 3
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 4, retcode 3
 2: 
 2: GPU-993:1824018:1825753 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
 2: 
 2: GPU-993:1824018:1825753 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 4, retcode 3
 3: 
 3: GPU-993:1823970:1825755 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
 3: 
 3: GPU-993:1823970:1825755 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 4, retcode 3
 4: 
 4: GPU-993:1824002:1825759 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
 4: 
 4: GPU-993:1824002:1825759 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 4, retcode 3
10: 
10: GPU-130:3701588:3712024 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 10, retcode 3
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 10, retcode 3
10: 
10: GPU-130:3701588:3712024 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
10: 
10: GPU-130:3701588:3712024 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 10, retcode 3
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 16, retcode 3
11: 
11: GPU-130:3701536:3712023 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 11, retcode 3
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 11, retcode 3
10: 
10: GPU-130:3701588:3712024 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
10: 
10: GPU-130:3701588:3712024 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 11, retcode 3
11: 
11: GPU-130:3701536:3712023 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
11: 
11: GPU-130:3701536:3712023 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 11, retcode 3
 5: 
 5: GPU-993:1823986:1825757 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1521 NCCL WARN [Proxy Service 0] Failed to execute operation Close from rank 5, retcode 3
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 5, retcode 3
 2: 
 2: GPU-993:1824018:1825753 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
 2: 
 2: GPU-993:1824018:1825753 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 5, retcode 3
 3: 
 3: GPU-993:1823970:1825755 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
 3: 
 3: GPU-993:1823970:1825755 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 5, retcode 3
 4: 
 4: GPU-993:1824002:1825759 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
 4: 
 4: GPU-993:1824002:1825759 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 5, retcode 3
 5: 
 5: GPU-993:1823986:1825757 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
 5: 
 5: GPU-993:1823986:1825757 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 5, retcode 3
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 17, retcode 3
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 17, retcode 3
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 6: 
 6: GPU-993:1824049:1825758 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 24, retcode 3
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1521 NCCL WARN [Proxy Service 0] Failed to execute operation Close from rank 6, retcode 3
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 6, retcode 3
 2: 
 2: GPU-993:1824018:1825753 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
 2: 
 2: GPU-993:1824018:1825753 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 6, retcode 3
 3: 
 3: GPU-993:1823970:1825755 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
 3: 
 3: GPU-993:1823970:1825755 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 6, retcode 3
 4: 
 4: GPU-993:1824002:1825759 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
 4: 
 4: GPU-993:1824002:1825759 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 6, retcode 3
 5: 
 5: GPU-993:1823986:1825757 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
 5: 
 5: GPU-993:1823986:1825757 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 6, retcode 3
 6: 
 6: GPU-993:1824049:1825758 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
 6: 
 6: GPU-993:1824049:1825758 [6] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 6, retcode 3
12: 
12: GPU-130:3701561:3712022 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 12, retcode 3
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 12, retcode 3
10: 
10: GPU-130:3701588:3712024 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
10: 
10: GPU-130:3701588:3712024 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 12, retcode 3
11: 
11: GPU-130:3701536:3712023 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
11: 
11: GPU-130:3701536:3712023 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 12, retcode 3
12: 
12: GPU-130:3701561:3712022 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
12: 
12: GPU-130:3701561:3712022 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 12, retcode 3
 7: 
 7: GPU-993:1823953:1825756 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
 0: 
 0: GPU-993:1824058:1825760 [0] proxy.cc:1521 NCCL WARN [Proxy Service 0] Failed to execute operation Close from rank 7, retcode 3
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
 1: 
 1: GPU-993:1824048:1825754 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 7, retcode 3
 2: 
 2: GPU-993:1824018:1825753 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
 2: 
 2: GPU-993:1824018:1825753 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 7, retcode 3
 3: 
 3: GPU-993:1823970:1825755 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
 3: 
 3: GPU-993:1823970:1825755 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 7, retcode 3
 4: 
 4: GPU-993:1824002:1825759 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
 4: 
 4: GPU-993:1824002:1825759 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 7, retcode 3
 5: 
 5: GPU-993:1823986:1825757 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
 5: 
 5: GPU-993:1823986:1825757 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 7, retcode 3
 6: 
 6: GPU-993:1824049:1825758 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
 6: 
 6: GPU-993:1824049:1825758 [6] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 7, retcode 3
 7: 
 7: GPU-993:1823953:1825756 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
 7: 
 7: GPU-993:1823953:1825756 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 7, retcode 3
18: 
18: GPU-338:1834618:1836964 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 18, retcode 3
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 18, retcode 3
18: 
18: GPU-338:1834618:1836964 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
18: 
18: GPU-338:1834618:1836964 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 18, retcode 3
13: 
13: GPU-130:3701613:3712021 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 13, retcode 3
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 13, retcode 3
14: 
14: GPU-130:3701497:3712020 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
10: 
10: GPU-130:3701588:3712024 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
10: 
10: GPU-130:3701588:3712024 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 13, retcode 3
11: 
11: GPU-130:3701536:3712023 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
11: 
11: GPU-130:3701536:3712023 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 13, retcode 3
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 14, retcode 3
12: 
12: GPU-130:3701561:3712022 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
12: 
12: GPU-130:3701561:3712022 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 13, retcode 3
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 14, retcode 3
13: 
13: GPU-130:3701613:3712021 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
13: 
13: GPU-130:3701613:3712021 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 13, retcode 3
10: 
10: GPU-130:3701588:3712024 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
10: 
10: GPU-130:3701588:3712024 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 14, retcode 3
14: 
14: GPU-130:3701497:3712020 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
14: 
14: GPU-130:3701497:3712020 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 13, retcode 3
11: 
11: GPU-130:3701536:3712023 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
11: 
11: GPU-130:3701536:3712023 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 14, retcode 3
12: 
12: GPU-130:3701561:3712022 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
12: 
12: GPU-130:3701561:3712022 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 14, retcode 3
13: 
13: GPU-130:3701613:3712021 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
13: 
13: GPU-130:3701613:3712021 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 14, retcode 3
14: 
14: GPU-130:3701497:3712020 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
14: 
14: GPU-130:3701497:3712020 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 14, retcode 3
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 25, retcode 3
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 25, retcode 3
15: 
15: GPU-130:3701582:3712019 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
 8: 
 8: GPU-130:3701537:3712026 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 15, retcode 3
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
 9: 
 9: GPU-130:3701513:3712025 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 15, retcode 3
10: 
10: GPU-130:3701588:3712024 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
10: 
10: GPU-130:3701588:3712024 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 15, retcode 3
11: 
11: GPU-130:3701536:3712023 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
11: 
11: GPU-130:3701536:3712023 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 15, retcode 3
12: 
12: GPU-130:3701561:3712022 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
12: 
12: GPU-130:3701561:3712022 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 15, retcode 3
13: 
13: GPU-130:3701613:3712021 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
13: 
13: GPU-130:3701613:3712021 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 15, retcode 3
14: 
14: GPU-130:3701497:3712020 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
14: 
14: GPU-130:3701497:3712020 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 15, retcode 3
15: 
15: GPU-130:3701582:3712019 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
15: 
15: GPU-130:3701582:3712019 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 15, retcode 3
19: 
19: GPU-338:1834667:1836967 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
20: 
20: GPU-338:1834617:1836963 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 19, retcode 3
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 20, retcode 3
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 19, retcode 3
18: 
18: GPU-338:1834618:1836964 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
18: 
18: GPU-338:1834618:1836964 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 19, retcode 3
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 20, retcode 3
18: 
18: GPU-338:1834618:1836964 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
18: 
18: GPU-338:1834618:1836964 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 20, retcode 3
19: 
19: GPU-338:1834667:1836967 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
19: 
19: GPU-338:1834667:1836967 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 19, retcode 3
19: 
19: GPU-338:1834667:1836967 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
19: 
19: GPU-338:1834667:1836967 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 20, retcode 3
20: 
20: GPU-338:1834617:1836963 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
20: 
20: GPU-338:1834617:1836963 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 19, retcode 3
20: 
20: GPU-338:1834617:1836963 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
20: 
20: GPU-338:1834617:1836963 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 20, retcode 3
26: 
26: GPU-234:1878430:1880199 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 26, retcode 3
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 26, retcode 3
26: 
26: GPU-234:1878430:1880199 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
26: 
26: GPU-234:1878430:1880199 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 26, retcode 3
27: 
27: GPU-234:1878461:1880200 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
28: 
28: GPU-234:1878398:1880201 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
29: 
29: GPU-234:1878397:1880203 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 27, retcode 3
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 28, retcode 3
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 27, retcode 3
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 28, retcode 3
26: 
26: GPU-234:1878430:1880199 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
26: 
26: GPU-234:1878430:1880199 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 27, retcode 3
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 29, retcode 3
26: 
26: GPU-234:1878430:1880199 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
26: 
26: GPU-234:1878430:1880199 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 28, retcode 3
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 29, retcode 3
27: 
27: GPU-234:1878461:1880200 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
27: 
27: GPU-234:1878461:1880200 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 27, retcode 3
26: 
26: GPU-234:1878430:1880199 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
26: 
26: GPU-234:1878430:1880199 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 29, retcode 3
27: 
27: GPU-234:1878461:1880200 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
27: 
27: GPU-234:1878461:1880200 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 28, retcode 3
28: 
28: GPU-234:1878398:1880201 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
28: 
28: GPU-234:1878398:1880201 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 29, retcode 3
27: 
27: GPU-234:1878461:1880200 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
27: 
27: GPU-234:1878461:1880200 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 29, retcode 3
28: 
28: GPU-234:1878398:1880201 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
28: 
28: GPU-234:1878398:1880201 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 27, retcode 3
29: 
29: GPU-234:1878397:1880203 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
29: 
29: GPU-234:1878397:1880203 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 27, retcode 3
28: 
28: GPU-234:1878398:1880201 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
28: 
28: GPU-234:1878398:1880201 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 28, retcode 3
29: 
29: GPU-234:1878397:1880203 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
29: 
29: GPU-234:1878397:1880203 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 29, retcode 3
29: 
29: GPU-234:1878397:1880203 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
29: 
29: GPU-234:1878397:1880203 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 28, retcode 3
21: 
21: GPU-338:1834665:1836961 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 21, retcode 3
22: 
22: GPU-338:1834588:1836962 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 21, retcode 3
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 22, retcode 3
18: 
18: GPU-338:1834618:1836964 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
18: 
18: GPU-338:1834618:1836964 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 21, retcode 3
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 22, retcode 3
19: 
19: GPU-338:1834667:1836967 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
19: 
19: GPU-338:1834667:1836967 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 21, retcode 3
18: 
18: GPU-338:1834618:1836964 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
18: 
18: GPU-338:1834618:1836964 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 22, retcode 3
20: 
20: GPU-338:1834617:1836963 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
20: 
20: GPU-338:1834617:1836963 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 21, retcode 3
19: 
19: GPU-338:1834667:1836967 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
19: 
19: GPU-338:1834667:1836967 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 22, retcode 3
21: 
21: GPU-338:1834665:1836961 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
21: 
21: GPU-338:1834665:1836961 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 21, retcode 3
20: 
20: GPU-338:1834617:1836963 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
20: 
20: GPU-338:1834617:1836963 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 22, retcode 3
22: 
22: GPU-338:1834588:1836962 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
22: 
22: GPU-338:1834588:1836962 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 21, retcode 3
21: 
21: GPU-338:1834665:1836961 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
21: 
21: GPU-338:1834665:1836961 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 22, retcode 3
22: 
22: GPU-338:1834588:1836962 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
22: 
22: GPU-338:1834588:1836962 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 22, retcode 3
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 32, retcode 3
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 32, retcode 3
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 33, retcode 3
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 33, retcode 3
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 41, retcode 3
31: 
31: GPU-234:1878462:1880205 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 31, retcode 3
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 31, retcode 3
26: 
26: GPU-234:1878430:1880199 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
26: 
26: GPU-234:1878430:1880199 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 31, retcode 3
27: 
27: GPU-234:1878461:1880200 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
27: 
27: GPU-234:1878461:1880200 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 31, retcode 3
28: 
28: GPU-234:1878398:1880201 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
28: 
28: GPU-234:1878398:1880201 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 31, retcode 3
30: 
30: GPU-234:1878429:1880202 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
29: 
29: GPU-234:1878397:1880203 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
29: 
29: GPU-234:1878397:1880203 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 31, retcode 3
30: 
30: GPU-234:1878429:1880202 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
30: 
30: GPU-234:1878429:1880202 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 31, retcode 3
24: 
24: GPU-234:1878358:1880213 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 30, retcode 3
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
25: 
25: GPU-234:1878374:1880211 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 30, retcode 3
31: 
31: GPU-234:1878462:1880205 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
31: 
31: GPU-234:1878462:1880205 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 31, retcode 3
26: 
26: GPU-234:1878430:1880199 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
26: 
26: GPU-234:1878430:1880199 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 30, retcode 3
27: 
27: GPU-234:1878461:1880200 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
27: 
27: GPU-234:1878461:1880200 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 30, retcode 3
28: 
28: GPU-234:1878398:1880201 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
28: 
28: GPU-234:1878398:1880201 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 30, retcode 3
29: 
29: GPU-234:1878397:1880203 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
29: 
29: GPU-234:1878397:1880203 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 30, retcode 3
30: 
30: GPU-234:1878429:1880202 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
30: 
30: GPU-234:1878429:1880202 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 30, retcode 3
31: 
31: GPU-234:1878462:1880205 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
31: 
31: GPU-234:1878462:1880205 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 30, retcode 3
23: 
23: GPU-338:1834671:1836959 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
16: 
16: GPU-338:1834572:1836965 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 23, retcode 3
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
17: 
17: GPU-338:1834626:1836966 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 23, retcode 3
18: 
18: GPU-338:1834618:1836964 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
18: 
18: GPU-338:1834618:1836964 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 23, retcode 3
19: 
19: GPU-338:1834667:1836967 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
19: 
19: GPU-338:1834667:1836967 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 23, retcode 3
20: 
20: GPU-338:1834617:1836963 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
20: 
20: GPU-338:1834617:1836963 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 23, retcode 3
21: 
21: GPU-338:1834665:1836961 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
21: 
21: GPU-338:1834665:1836961 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 23, retcode 3
22: 
22: GPU-338:1834588:1836962 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
22: 
22: GPU-338:1834588:1836962 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 23, retcode 3
23: 
23: GPU-338:1834671:1836959 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
23: 
23: GPU-338:1834671:1836959 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 23, retcode 3
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 40, retcode 3
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 40, retcode 3
43: 
43: GPU-186:1818731:1820641 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 43, retcode 3
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 43, retcode 3
43: 
43: GPU-186:1818731:1820641 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
43: 
43: GPU-186:1818731:1820641 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 43, retcode 3
35: 
35: GPU-245:1853834:1855949 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 35, retcode 3
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 35, retcode 3
35: 
35: GPU-245:1853834:1855949 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
35: 
35: GPU-245:1853834:1855949 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 35, retcode 3
34: 
34: GPU-245:1853791:1855960 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 34, retcode 3
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 34, retcode 3
34: 
34: GPU-245:1853791:1855960 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
34: 
34: GPU-245:1853791:1855960 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 34, retcode 3
35: 
35: GPU-245:1853834:1855949 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
35: 
35: GPU-245:1853834:1855949 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 34, retcode 3
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 55, retcode 3
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 51, retcode 3
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 55, retcode 3
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 51, retcode 3
42: 
42: GPU-186:1818814:1820642 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 42, retcode 3
44: 
44: GPU-186:1818843:1820645 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 42, retcode 3
42: 
42: GPU-186:1818814:1820642 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
42: 
42: GPU-186:1818814:1820642 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 42, retcode 3
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 44, retcode 3
43: 
43: GPU-186:1818731:1820641 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
43: 
43: GPU-186:1818731:1820641 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 42, retcode 3
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 44, retcode 3
44: 
44: GPU-186:1818843:1820645 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
44: 
44: GPU-186:1818843:1820645 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 42, retcode 3
42: 
42: GPU-186:1818814:1820642 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
42: 
42: GPU-186:1818814:1820642 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 44, retcode 3
43: 
43: GPU-186:1818731:1820641 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
43: 
43: GPU-186:1818731:1820641 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 44, retcode 3
44: 
44: GPU-186:1818843:1820645 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
44: 
44: GPU-186:1818843:1820645 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 44, retcode 3
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 63, retcode 3
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 59, retcode 3
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 63, retcode 3
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 59, retcode 3
58: 
58: GPU-332:1856340:1858127 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
58: 
58: GPU-332:1856340:1858127 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
58: 
58: GPU-332:1856340:1858127 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 58, retcode 3
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 58, retcode 3
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 58, retcode 3
39: 
39: GPU-245:1853748:1855954 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 39, retcode 3
36: 
36: GPU-245:1853786:1855952 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
37: 
37: GPU-245:1853764:1855953 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 39, retcode 3
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 37, retcode 3
34: 
34: GPU-245:1853791:1855960 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
34: 
34: GPU-245:1853791:1855960 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 39, retcode 3
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 36, retcode 3
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 36, retcode 3
38: 
38: GPU-245:1853833:1855951 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
35: 
35: GPU-245:1853834:1855949 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
35: 
35: GPU-245:1853834:1855949 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 39, retcode 3
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 37, retcode 3
34: 
34: GPU-245:1853791:1855960 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
34: 
34: GPU-245:1853791:1855960 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 37, retcode 3
36: 
36: GPU-245:1853786:1855952 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
36: 
36: GPU-245:1853786:1855952 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 39, retcode 3
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
32: 
32: GPU-245:1853832:1855946 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 38, retcode 3
34: 
34: GPU-245:1853791:1855960 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
34: 
34: GPU-245:1853791:1855960 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 36, retcode 3
35: 
35: GPU-245:1853834:1855949 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
35: 
35: GPU-245:1853834:1855949 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 37, retcode 3
35: 
35: GPU-245:1853834:1855949 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
35: 
35: GPU-245:1853834:1855949 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 36, retcode 3
36: 
36: GPU-245:1853786:1855952 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
36: 
36: GPU-245:1853786:1855952 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 37, retcode 3
36: 
36: GPU-245:1853786:1855952 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
37: 
37: GPU-245:1853764:1855953 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
37: 
37: GPU-245:1853764:1855953 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 39, retcode 3
37: 
37: GPU-245:1853764:1855953 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
37: 
37: GPU-245:1853764:1855953 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 37, retcode 3
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
33: 
33: GPU-245:1853840:1855947 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 38, retcode 3
34: 
34: GPU-245:1853791:1855960 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
34: 
34: GPU-245:1853791:1855960 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 38, retcode 3
36: 
36: GPU-245:1853786:1855952 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 36, retcode 3
38: 
38: GPU-245:1853833:1855951 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
38: 
38: GPU-245:1853833:1855951 [6] proxy.cc:1521 NCCL WARN [Proxy Service 38] Failed to execute operation Close from rank 39, retcode 3
38: 
38: GPU-245:1853833:1855951 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
38: 
38: GPU-245:1853833:1855951 [6] proxy.cc:1521 NCCL WARN [Proxy Service 38] Failed to execute operation Close from rank 36, retcode 3
39: 
39: GPU-245:1853748:1855954 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
39: 
39: GPU-245:1853748:1855954 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 39, retcode 3
35: 
35: GPU-245:1853834:1855949 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
35: 
35: GPU-245:1853834:1855949 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 38, retcode 3
36: 
36: GPU-245:1853786:1855952 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
36: 
36: GPU-245:1853786:1855952 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 38, retcode 3
37: 
37: GPU-245:1853764:1855953 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
37: 
37: GPU-245:1853764:1855953 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 36, retcode 3
37: 
37: GPU-245:1853764:1855953 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
37: 
37: GPU-245:1853764:1855953 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 38, retcode 3
38: 
38: GPU-245:1853833:1855951 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
38: 
38: GPU-245:1853833:1855951 [6] proxy.cc:1521 NCCL WARN [Proxy Service 38] Failed to execute operation Close from rank 37, retcode 3
39: 
39: GPU-245:1853748:1855954 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
39: 
39: GPU-245:1853748:1855954 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 36, retcode 3
39: 
39: GPU-245:1853748:1855954 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
39: 
39: GPU-245:1853748:1855954 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 37, retcode 3
38: 
38: GPU-245:1853833:1855951 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
38: 
38: GPU-245:1853833:1855951 [6] proxy.cc:1521 NCCL WARN [Proxy Service 38] Failed to execute operation Close from rank 38, retcode 3
39: 
39: GPU-245:1853748:1855954 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
39: 
39: GPU-245:1853748:1855954 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 38, retcode 3
48: 
48: GPU-792:1843865:1845646 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
50: 
50: GPU-792:1843922:1845647 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
48: 
48: GPU-792:1843865:1845646 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
48: 
48: GPU-792:1843865:1845646 [0] proxy.cc:1521 NCCL WARN [Proxy Service 48] Failed to execute operation Close from rank 50, retcode 3
48: 
48: GPU-792:1843865:1845646 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
48: 
48: GPU-792:1843865:1845646 [0] proxy.cc:1521 NCCL WARN [Proxy Service 48] Failed to execute operation Close from rank 48, retcode 3
50: 
50: GPU-792:1843922:1845647 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
50: 
50: GPU-792:1843922:1845647 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 50, retcode 3
50: 
50: GPU-792:1843922:1845647 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
50: 
50: GPU-792:1843922:1845647 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 48, retcode 3
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 50, retcode 3
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 48, retcode 3
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 50, retcode 3
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 48, retcode 3
52: 
52: GPU-792:1843957:1845650 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
48: 
48: GPU-792:1843865:1845646 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
48: 
48: GPU-792:1843865:1845646 [0] proxy.cc:1521 NCCL WARN [Proxy Service 48] Failed to execute operation Close from rank 52, retcode 3
50: 
50: GPU-792:1843922:1845647 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
50: 
50: GPU-792:1843922:1845647 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 52, retcode 3
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 52, retcode 3
52: 
52: GPU-792:1843957:1845650 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
52: 
52: GPU-792:1843957:1845650 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 52, retcode 3
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 52, retcode 3
45: 
45: GPU-186:1818800:1820639 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 45, retcode 3
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 45, retcode 3
42: 
42: GPU-186:1818814:1820642 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
42: 
42: GPU-186:1818814:1820642 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 45, retcode 3
43: 
43: GPU-186:1818731:1820641 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
43: 
43: GPU-186:1818731:1820641 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 45, retcode 3
44: 
44: GPU-186:1818843:1820645 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
44: 
44: GPU-186:1818843:1820645 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 45, retcode 3
45: 
45: GPU-186:1818800:1820639 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
45: 
45: GPU-186:1818800:1820639 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 45, retcode 3
49: 
49: GPU-792:1843864:1845649 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
48: 
48: GPU-792:1843865:1845646 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
48: 
48: GPU-792:1843865:1845646 [0] proxy.cc:1521 NCCL WARN [Proxy Service 48] Failed to execute operation Close from rank 49, retcode 3
49: 
49: GPU-792:1843864:1845649 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
49: 
49: GPU-792:1843864:1845649 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 49, retcode 3
50: 
50: GPU-792:1843922:1845647 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
50: 
50: GPU-792:1843922:1845647 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 49, retcode 3
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 49, retcode 3
52: 
52: GPU-792:1843957:1845650 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
52: 
52: GPU-792:1843957:1845650 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 49, retcode 3
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 49, retcode 3
54: 
54: GPU-792:1843908:1845643 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
48: 
48: GPU-792:1843865:1845646 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
48: 
48: GPU-792:1843865:1845646 [0] proxy.cc:1521 NCCL WARN [Proxy Service 48] Failed to execute operation Close from rank 54, retcode 3
49: 
49: GPU-792:1843864:1845649 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
49: 
49: GPU-792:1843864:1845649 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 54, retcode 3
50: 
50: GPU-792:1843922:1845647 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
50: 
50: GPU-792:1843922:1845647 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 54, retcode 3
53: 
53: GPU-792:1843893:1845645 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 54, retcode 3
48: 
48: GPU-792:1843865:1845646 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
48: 
48: GPU-792:1843865:1845646 [0] proxy.cc:1521 NCCL WARN [Proxy Service 48] Failed to execute operation Close from rank 53, retcode 3
52: 
52: GPU-792:1843957:1845650 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
52: 
52: GPU-792:1843957:1845650 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 54, retcode 3
49: 
49: GPU-792:1843864:1845649 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
49: 
49: GPU-792:1843864:1845649 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 53, retcode 3
53: 
53: GPU-792:1843893:1845645 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
53: 
53: GPU-792:1843893:1845645 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 54, retcode 3
50: 
50: GPU-792:1843922:1845647 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
50: 
50: GPU-792:1843922:1845647 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 53, retcode 3
54: 
54: GPU-792:1843908:1845643 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
54: 
54: GPU-792:1843908:1845643 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 54, retcode 3
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
51: 
51: GPU-792:1843950:1845648 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 53, retcode 3
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 54, retcode 3
52: 
52: GPU-792:1843957:1845650 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
52: 
52: GPU-792:1843957:1845650 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 53, retcode 3
53: 
53: GPU-792:1843893:1845645 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
53: 
53: GPU-792:1843893:1845645 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 53, retcode 3
54: 
54: GPU-792:1843908:1845643 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
54: 
54: GPU-792:1843908:1845643 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 53, retcode 3
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
55: 
55: GPU-792:1843956:1845644 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 53, retcode 3
47: 
47: GPU-186:1818747:1820644 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 47, retcode 3
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 47, retcode 3
42: 
42: GPU-186:1818814:1820642 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
42: 
42: GPU-186:1818814:1820642 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 47, retcode 3
43: 
43: GPU-186:1818731:1820641 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
43: 
43: GPU-186:1818731:1820641 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 47, retcode 3
44: 
44: GPU-186:1818843:1820645 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
44: 
44: GPU-186:1818843:1820645 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 47, retcode 3
45: 
45: GPU-186:1818800:1820639 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
45: 
45: GPU-186:1818800:1820639 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 47, retcode 3
46: 
46: GPU-186:1818813:1820638 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
46: 
46: GPU-186:1818813:1820638 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
46: 
46: GPU-186:1818813:1820638 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 47, retcode 3
47: 
47: GPU-186:1818747:1820644 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0
47: 
47: GPU-186:1818747:1820644 [7] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 47, retcode 3
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
40: 
40: GPU-186:1818784:1820640 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 46, retcode 3
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
41: 
41: GPU-186:1818763:1820643 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 46, retcode 3
42: 
42: GPU-186:1818814:1820642 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
42: 
42: GPU-186:1818814:1820642 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 46, retcode 3
43: 
43: GPU-186:1818731:1820641 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
43: 
43: GPU-186:1818731:1820641 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 46, retcode 3
44: 
44: GPU-186:1818843:1820645 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
44: 
44: GPU-186:1818843:1820645 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 46, retcode 3
45: 
45: GPU-186:1818800:1820639 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
45: 
45: GPU-186:1818800:1820639 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 46, retcode 3
46: 
46: GPU-186:1818813:1820638 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
46: 
46: GPU-186:1818813:1820638 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 46, retcode 3
47: 
47: GPU-186:1818747:1820644 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
47: 
47: GPU-186:1818747:1820644 [7] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 46, retcode 3
62: 
62: GPU-332:1856443:1858136 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
60: 
60: GPU-332:1856385:1858133 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
56: 
56: GPU-332:1856395:1858128 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
56: 
56: GPU-332:1856395:1858128 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
56: 
56: GPU-332:1856395:1858128 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 62, retcode 3
61: 
61: GPU-332:1856384:1858135 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
57: 
57: GPU-332:1856420:1858126 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
57: 
57: GPU-332:1856420:1858126 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 62, retcode 3
58: 
58: GPU-332:1856340:1858127 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
58: 
58: GPU-332:1856340:1858127 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 62, retcode 3
56: 
56: GPU-332:1856395:1858128 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
56: 
56: GPU-332:1856395:1858128 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 56, retcode 3
58: 
58: GPU-332:1856340:1858127 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
58: 
58: GPU-332:1856340:1858127 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 60, retcode 3
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 62, retcode 3
56: 
56: GPU-332:1856395:1858128 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
56: 
56: GPU-332:1856395:1858128 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 60, retcode 3
57: 
57: GPU-332:1856420:1858126 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
57: 
57: GPU-332:1856420:1858126 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
57: 
57: GPU-332:1856420:1858126 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 60, retcode 3
58: 
58: GPU-332:1856340:1858127 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 60, retcode 3
60: 
60: GPU-332:1856385:1858133 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
60: 
60: GPU-332:1856385:1858133 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 62, retcode 3
56: 
56: GPU-332:1856395:1858128 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
56: 
56: GPU-332:1856395:1858128 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 61, retcode 3
57: 
57: GPU-332:1856420:1858126 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
57: 
57: GPU-332:1856420:1858126 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 61, retcode 3
58: 
58: GPU-332:1856340:1858127 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 61, retcode 3
58: 
58: GPU-332:1856340:1858127 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 61, retcode 3
60: 
60: GPU-332:1856385:1858133 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
60: 
60: GPU-332:1856385:1858133 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 60, retcode 3
61: 
61: GPU-332:1856384:1858135 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
61: 
61: GPU-332:1856384:1858135 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 62, retcode 3
56: 
56: GPU-332:1856395:1858128 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
56: 
56: GPU-332:1856395:1858128 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 57, retcode 3
57: 
57: GPU-332:1856420:1858126 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
57: 
57: GPU-332:1856420:1858126 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 56, retcode 3
57: 
57: GPU-332:1856420:1858126 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
57: 
57: GPU-332:1856420:1858126 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 57, retcode 3
58: 
58: GPU-332:1856340:1858127 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 56, retcode 3
58: 
58: GPU-332:1856340:1858127 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
58: 
58: GPU-332:1856340:1858127 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 57, retcode 3
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 56, retcode 3
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
60: 
60: GPU-332:1856385:1858133 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
60: 
60: GPU-332:1856385:1858133 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 61, retcode 3
60: 
60: GPU-332:1856385:1858133 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
60: 
60: GPU-332:1856385:1858133 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 56, retcode 3
61: 
61: GPU-332:1856384:1858135 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
61: 
61: GPU-332:1856384:1858135 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 60, retcode 3
61: 
61: GPU-332:1856384:1858135 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
61: 
61: GPU-332:1856384:1858135 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 61, retcode 3
62: 
62: GPU-332:1856443:1858136 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
62: 
62: GPU-332:1856443:1858136 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 62, retcode 3
62: 
62: GPU-332:1856443:1858136 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
62: 
62: GPU-332:1856443:1858136 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 60, retcode 3
59: 
59: GPU-332:1856356:1858132 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 57, retcode 3
60: 
60: GPU-332:1856385:1858133 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
60: 
60: GPU-332:1856385:1858133 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 57, retcode 3
61: 
61: GPU-332:1856384:1858135 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
61: 
61: GPU-332:1856384:1858135 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 56, retcode 3
62: 
62: GPU-332:1856443:1858136 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
62: 
62: GPU-332:1856443:1858136 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 61, retcode 3
62: 
62: GPU-332:1856443:1858136 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
62: 
62: GPU-332:1856443:1858136 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 56, retcode 3
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 62, retcode 3
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 60, retcode 3
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 61, retcode 3
61: 
61: GPU-332:1856384:1858135 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
61: 
61: GPU-332:1856384:1858135 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 57, retcode 3
62: 
62: GPU-332:1856443:1858136 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
62: 
62: GPU-332:1856443:1858136 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 57, retcode 3
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 56, retcode 3
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
63: 
63: GPU-332:1856444:1858134 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 57, retcode 3
 0: ENDING TIMING RUN AT 2024-10-11 07:05:29 PM
 0: RESULT,LLM_FINETUNING,,716,nvidia,2024-10-11 06:53:33 PM
++ date +%s
+ echo 'RUNANDTIME_STOP 1728673549'
RUNANDTIME_STOP 1728673549
+ set -e
